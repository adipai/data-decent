{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adipai/statistical-data-pruning-analysis/blob/main/churn_sampling_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pmlb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAJ8lflEvuaA",
        "outputId": "e02369d9-ac4d-43b6-9b1d-5b30930daea5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pmlb\n",
            "  Downloading pmlb-1.0.1.post3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from pmlb) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from pmlb) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from pmlb) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->pmlb) (1.16.0)\n",
            "Installing collected packages: pmlb\n",
            "Successfully installed pmlb-1.0.1.post3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sdv"
      ],
      "metadata": {
        "id": "COAFe5iG-02V",
        "outputId": "a96e72f6-f802-4917-a73d-d09f9d622d76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sdv\n",
            "  Downloading sdv-1.11.0-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2,>=1.15.0 (from sdv)\n",
            "  Downloading boto3-1.34.80-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<2,>=1.18 (from sdv)\n",
            "  Downloading botocore-1.34.80-py3-none-any.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<3.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (2.2.1)\n",
            "Requirement already satisfied: graphviz<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from sdv) (0.20.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.15 in /usr/local/lib/python3.10/dist-packages (from sdv) (4.66.2)\n",
            "Collecting copulas<0.10,>=0.9.0 (from sdv)\n",
            "  Downloading copulas-0.9.2-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctgan<0.10,>=0.9.0 (from sdv)\n",
            "  Downloading ctgan-0.9.1-py3-none-any.whl (24 kB)\n",
            "Collecting deepecho<0.6,>=0.5 (from sdv)\n",
            "  Downloading deepecho-0.5.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting rdt<2,>=1.10.0 (from sdv)\n",
            "  Downloading rdt-1.10.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sdmetrics<0.14,>=0.13.0 (from sdv)\n",
            "  Downloading sdmetrics-0.13.1-py3-none-any.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.8/169.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1.23.3 in /usr/local/lib/python3.10/dist-packages (from sdv) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.3.4 in /usr/local/lib/python3.10/dist-packages (from sdv) (2.0.3)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.15.0->sdv)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.15.0->sdv)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<2,>=1.18->sdv) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<2,>=1.18->sdv) (2.0.7)\n",
            "Requirement already satisfied: matplotlib<4,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from copulas<0.10,>=0.9.0->sdv) (3.7.1)\n",
            "Requirement already satisfied: scipy<2,>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from copulas<0.10,>=0.9.0->sdv) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from ctgan<0.10,>=0.9.0->sdv) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from ctgan<0.10,>=0.9.0->sdv) (2.2.1+cu121)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.4->sdv) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.4->sdv) (2024.1)\n",
            "Collecting Faker<20,>=17 (from rdt<2,>=1.10.0->sdv)\n",
            "  Downloading Faker-19.13.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of sdmetrics to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sdmetrics<0.14,>=0.13.0 (from sdv)\n",
            "  Downloading sdmetrics-0.13.0-py2.py3-none-any.whl (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.7/170.7 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: plotly<6,>=5.10.0 in /usr/local/lib/python3.10/dist-packages (from sdmetrics<0.14,>=0.13.0->sdv) (5.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly<6,>=5.10.0->sdmetrics<0.14,>=0.13.0->sdv) (8.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<2,>=1.18->sdv) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.3->ctgan<0.10,>=0.9.0->sdv) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.3->ctgan<0.10,>=0.9.0->sdv) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m658.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, nvidia-cusparse-cu12, nvidia-cudnn-cu12, Faker, botocore, s3transfer, rdt, nvidia-cusolver-cu12, copulas, sdmetrics, boto3, deepecho, ctgan, sdv\n",
            "Successfully installed Faker-19.13.0 boto3-1.34.80 botocore-1.34.80 copulas-0.9.2 ctgan-0.9.1 deepecho-0.5.0 jmespath-1.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 rdt-1.10.1 s3transfer-0.10.1 sdmetrics-0.13.0 sdv-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install DataSynthesizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBcGtW-pIGJ4",
        "outputId": "64735b30-e53f-40a6-b709-d010621964ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting DataSynthesizer\n",
            "  Downloading DataSynthesizer-0.1.13-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (3.7.1)\n",
            "Requirement already satisfied: seaborn>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (0.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->DataSynthesizer) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->DataSynthesizer) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->DataSynthesizer) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (3.4.0)\n",
            "Installing collected packages: DataSynthesizer\n",
            "Successfully installed DataSynthesizer-0.1.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All imports here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pmlb import fetch_data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import time\n",
        "\n",
        "from sdv.datasets.local import load_csvs\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sdv.single_table import GaussianCopulaSynthesizer\n",
        "from DataSynthesizer.DataDescriber import DataDescriber\n",
        "from DataSynthesizer.DataGenerator import DataGenerator\n",
        "from DataSynthesizer.lib.utils import display_bayesian_network\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix"
      ],
      "metadata": {
        "id": "Lza8MeLYchI2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "KH_s6WhMv_Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data_train(X_train):\n",
        "\n",
        "    # Normalize numeric columns\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "    return X_train, scaler\n",
        "\n",
        "def preprocess_data_test(X_test, scaler):\n",
        "\n",
        "    # Normalize numeric columns\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_test"
      ],
      "metadata": {
        "id": "A9ept3j9vmUy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "3Rjlt8zr4vyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset 1: Churn"
      ],
      "metadata": {
        "id": "p22RSGg043d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "churn = fetch_data('churn')\n",
        "churn.rename(columns={'state':'X'}, inplace=True)\n",
        "churn.drop(columns=['phone number', 'voice mail plan'], inplace=True)\n",
        "churn.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "wyi4iWJFwIhU",
        "outputId": "f36456d1-5bd3-40ef-97eb-93fb8ea997bf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                X  account length    area code  international plan  \\\n",
              "count  5000.00000      5000.00000  5000.000000         5000.000000   \n",
              "mean     25.99840       100.25860   436.911400            0.094600   \n",
              "std      14.80348        39.69456    42.209182            0.292691   \n",
              "min       0.00000         1.00000   408.000000            0.000000   \n",
              "25%      13.00000        73.00000   408.000000            0.000000   \n",
              "50%      26.00000       100.00000   415.000000            0.000000   \n",
              "75%      39.00000       127.00000   415.000000            0.000000   \n",
              "max      50.00000       243.00000   510.000000            1.000000   \n",
              "\n",
              "       number vmail messages  total day minutes  total day calls  \\\n",
              "count            5000.000000        5000.000000      5000.000000   \n",
              "mean                7.755200         180.288900       100.029400   \n",
              "std                13.546393          53.894699        19.831197   \n",
              "min                 0.000000           0.000000         0.000000   \n",
              "25%                 0.000000         143.700000        87.000000   \n",
              "50%                 0.000000         180.100000       100.000000   \n",
              "75%                17.000000         216.200000       113.000000   \n",
              "max                52.000000         351.500000       165.000000   \n",
              "\n",
              "       total day charge  total eve minutes  total eve calls  total eve charge  \\\n",
              "count       5000.000000        5000.000000      5000.000000       5000.000000   \n",
              "mean          30.649668         200.636560       100.191000         17.054322   \n",
              "std            9.162069          50.551309        19.826496          4.296843   \n",
              "min            0.000000           0.000000         0.000000          0.000000   \n",
              "25%           24.430000         166.375000        87.000000         14.140000   \n",
              "50%           30.620000         201.000000       100.000000         17.090000   \n",
              "75%           36.750000         234.100000       114.000000         19.900000   \n",
              "max           59.760000         363.700000       170.000000         30.910000   \n",
              "\n",
              "       total night minutes  total night calls  total night charge  \\\n",
              "count          5000.000000        5000.000000         5000.000000   \n",
              "mean            200.391620          99.919200            9.017732   \n",
              "std              50.527789          19.958686            2.273763   \n",
              "min               0.000000           0.000000            0.000000   \n",
              "25%             166.900000          87.000000            7.510000   \n",
              "50%             200.400000         100.000000            9.020000   \n",
              "75%             234.700000         113.000000           10.560000   \n",
              "max             395.000000         175.000000           17.770000   \n",
              "\n",
              "       total intl minutes  total intl calls  total intl charge  \\\n",
              "count         5000.000000       5000.000000        5000.000000   \n",
              "mean            10.261780          4.435200           2.771196   \n",
              "std              2.761396          2.456788           0.745514   \n",
              "min              0.000000          0.000000           0.000000   \n",
              "25%              8.500000          3.000000           2.300000   \n",
              "50%             10.300000          4.000000           2.780000   \n",
              "75%             12.000000          6.000000           3.240000   \n",
              "max             20.000000         20.000000           5.400000   \n",
              "\n",
              "       number customer service calls       target  \n",
              "count                    5000.000000  5000.000000  \n",
              "mean                        1.570400     0.141400  \n",
              "std                         1.306363     0.348469  \n",
              "min                         0.000000     0.000000  \n",
              "25%                         1.000000     0.000000  \n",
              "50%                         1.000000     0.000000  \n",
              "75%                         2.000000     0.000000  \n",
              "max                         9.000000     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f3ed707-04a8-4977-94b5-23f6419a6c9e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>account length</th>\n",
              "      <th>area code</th>\n",
              "      <th>international plan</th>\n",
              "      <th>number vmail messages</th>\n",
              "      <th>total day minutes</th>\n",
              "      <th>total day calls</th>\n",
              "      <th>total day charge</th>\n",
              "      <th>total eve minutes</th>\n",
              "      <th>total eve calls</th>\n",
              "      <th>total eve charge</th>\n",
              "      <th>total night minutes</th>\n",
              "      <th>total night calls</th>\n",
              "      <th>total night charge</th>\n",
              "      <th>total intl minutes</th>\n",
              "      <th>total intl calls</th>\n",
              "      <th>total intl charge</th>\n",
              "      <th>number customer service calls</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.00000</td>\n",
              "      <td>5000.00000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>25.99840</td>\n",
              "      <td>100.25860</td>\n",
              "      <td>436.911400</td>\n",
              "      <td>0.094600</td>\n",
              "      <td>7.755200</td>\n",
              "      <td>180.288900</td>\n",
              "      <td>100.029400</td>\n",
              "      <td>30.649668</td>\n",
              "      <td>200.636560</td>\n",
              "      <td>100.191000</td>\n",
              "      <td>17.054322</td>\n",
              "      <td>200.391620</td>\n",
              "      <td>99.919200</td>\n",
              "      <td>9.017732</td>\n",
              "      <td>10.261780</td>\n",
              "      <td>4.435200</td>\n",
              "      <td>2.771196</td>\n",
              "      <td>1.570400</td>\n",
              "      <td>0.141400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14.80348</td>\n",
              "      <td>39.69456</td>\n",
              "      <td>42.209182</td>\n",
              "      <td>0.292691</td>\n",
              "      <td>13.546393</td>\n",
              "      <td>53.894699</td>\n",
              "      <td>19.831197</td>\n",
              "      <td>9.162069</td>\n",
              "      <td>50.551309</td>\n",
              "      <td>19.826496</td>\n",
              "      <td>4.296843</td>\n",
              "      <td>50.527789</td>\n",
              "      <td>19.958686</td>\n",
              "      <td>2.273763</td>\n",
              "      <td>2.761396</td>\n",
              "      <td>2.456788</td>\n",
              "      <td>0.745514</td>\n",
              "      <td>1.306363</td>\n",
              "      <td>0.348469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>408.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>13.00000</td>\n",
              "      <td>73.00000</td>\n",
              "      <td>408.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>143.700000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>24.430000</td>\n",
              "      <td>166.375000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>14.140000</td>\n",
              "      <td>166.900000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>7.510000</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>26.00000</td>\n",
              "      <td>100.00000</td>\n",
              "      <td>415.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>180.100000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>30.620000</td>\n",
              "      <td>201.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>17.090000</td>\n",
              "      <td>200.400000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>9.020000</td>\n",
              "      <td>10.300000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.780000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>39.00000</td>\n",
              "      <td>127.00000</td>\n",
              "      <td>415.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>216.200000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>36.750000</td>\n",
              "      <td>234.100000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>19.900000</td>\n",
              "      <td>234.700000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>10.560000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.240000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>50.00000</td>\n",
              "      <td>243.00000</td>\n",
              "      <td>510.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>351.500000</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>59.760000</td>\n",
              "      <td>363.700000</td>\n",
              "      <td>170.000000</td>\n",
              "      <td>30.910000</td>\n",
              "      <td>395.000000</td>\n",
              "      <td>175.000000</td>\n",
              "      <td>17.770000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f3ed707-04a8-4977-94b5-23f6419a6c9e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f3ed707-04a8-4977-94b5-23f6419a6c9e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f3ed707-04a8-4977-94b5-23f6419a6c9e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9d7957c1-fc95-44cf-9e68-a8378be76c77\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d7957c1-fc95-44cf-9e68-a8378be76c77')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9d7957c1-fc95-44cf-9e68-a8378be76c77 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"churn\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"X\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1759.3098058302435,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          25.9984,\n          26.0,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"account length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1734.6765859515917,\n        \"min\": 1.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          100.2586,\n          100.0,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1640.6996720990337,\n        \"min\": 42.209182331035635,\n        \"max\": 5000.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5000.0,\n          436.9114,\n          510.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"international plan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1767.6969173151092,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0946,\n          1.0,\n          0.2926909181965148\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number vmail messages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1763.289959095966,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5000.0,\n          7.7552,\n          52.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total day minutes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1714.154900961021,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          180.2889,\n          180.1,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total day calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1739.0115694466565,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          100.0294,\n          100.0,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total day charge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1758.1925382735747,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          30.649668,\n          30.62,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total eve minutes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1709.9530774613647,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          200.63656,\n          201.0,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total eve calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1738.7377090694333,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          100.191,\n          100.0,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total eve charge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1762.5702654809165,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          17.054322,\n          17.09,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total night minutes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1708.8957420669171,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          200.39162000000002,\n          200.4,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total night calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1738.5754791109719,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          99.9192,\n          100.0,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total night charge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1764.939013287635,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          9.017732,\n          9.02,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total intl minutes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1764.5536515776432,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          10.261779999999998,\n          10.3,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total intl calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1765.7625952809108,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4.4352,\n          4.0,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total intl charge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1766.8971142398468,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2.7711959999999998,\n          2.78,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number customer service calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1766.9672852345343,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          5000.0,\n          1.5704,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1767.691736550438,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.1414,\n          1.0,\n          0.3484685438676109\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and testing using ML models"
      ],
      "metadata": {
        "id": "gGu1Qxej4WAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic function to test synthetic data using LR, SVM, DT\n",
        "\n",
        "def evaluate_models(X_train, X_test, y_train, y_test, random_state=42):\n",
        "\n",
        "    # Initialize classifiers\n",
        "    classifiers = {\n",
        "        \"Logistic Regression\": LogisticRegression(random_state=random_state),\n",
        "        \"SVM\": SVC(random_state=random_state),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(random_state=random_state)\n",
        "    }\n",
        "\n",
        "    # Results dictionary to store evaluation metrics\n",
        "    results = {}\n",
        "\n",
        "    # Iterate over classifiers\n",
        "    for name, clf in classifiers.items():\n",
        "        # Fit classifier\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Predictions\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Evaluation metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        # AUC-ROC\n",
        "        if hasattr(clf, \"predict_proba\"):\n",
        "            y_prob = clf.predict_proba(X_test)[:,1]\n",
        "        else:\n",
        "            y_prob = clf.decision_function(X_test)\n",
        "        fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Store results\n",
        "        results[name] = {\n",
        "            \"Accuracy\": accuracy,\n",
        "            \"Precision\": precision,\n",
        "            \"Recall\": recall,\n",
        "            \"F1 Score\": f1,\n",
        "            \"ROC AUC\": roc_auc,\n",
        "            \"Confusion Matrix\": cm\n",
        "        }\n",
        "\n",
        "        # Plot AUC-ROC curve\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'{name} - AUC-ROC Curve')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.savefig(f'{name}_auc_roc_curve.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title(f'{name} - Confusion Matrix')\n",
        "        plt.savefig(f'{name}_confusion_matrix.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "SULk39gP2SUj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y = churn['target']\n",
        "X = churn.drop('target', axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n"
      ],
      "metadata": {
        "id": "2aBR2GZH2bb_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate_models(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "adNKyUsSLi6r",
        "outputId": "3e03d21d-b62d-4b62-ca15-c2bbb77d63ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAAzoxMlLpjk",
        "outputId": "05223e81-55f8-4547-b8b4-a72276d20edb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.864, 'Precision': 0.56, 'Recall': 0.10071942446043165, 'F1 Score': 0.17073170731707316, 'ROC AUC': 0.7499561326548517, 'Confusion Matrix': array([[850,  11],\n",
            "       [125,  14]])}, 'SVM': {'Accuracy': 0.861, 'Precision': 0.0, 'Recall': 0.0, 'F1 Score': 0.0, 'ROC AUC': 0.7722992337837047, 'Confusion Matrix': array([[861,   0],\n",
            "       [139,   0]])}, 'Decision Tree': {'Accuracy': 0.922, 'Precision': 0.7132867132867133, 'Recall': 0.7338129496402878, 'F1 Score': 0.7234042553191491, 'ROC AUC': 0.84309695101062, 'Confusion Matrix': array([[820,  41],\n",
            "       [ 37, 102]])}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SDV - Oversampling"
      ],
      "metadata": {
        "id": "_NaC7Ymj90QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def do_sdv(X_train, y_train):\n",
        "  train_df = pd.concat([X_train, y_train], axis=1)\n",
        "  class_counts = y_train.value_counts()\n",
        "\n",
        "  # Find minority class label\n",
        "  minority_class_label = class_counts.idxmin()\n",
        "\n",
        "  # Filter rows with minority class label\n",
        "  minority_df = train_df[train_df.iloc[:, -1] == minority_class_label]\n",
        "\n",
        "  # Calculate counts of majority and minority classes\n",
        "  majority_count = class_counts.max()\n",
        "  minority_count = class_counts.min()\n",
        "\n",
        "  metadata_data = SingleTableMetadata()\n",
        "  metadata_data.detect_from_dataframe(minority_df)\n",
        "  metadata_data.remove_primary_key()\n",
        "  # Generate synthetic data using GaussianCopulaSynthesizer\n",
        "  synthesizer_breast_data = GaussianCopulaSynthesizer(metadata_data)\n",
        "  synthesizer_breast_data.fit(minority_df)\n",
        "\n",
        "  # Print sample synthetic data\n",
        "  synthesizer_breast_data.reset_sampling()\n",
        "  sd1 = synthesizer_breast_data.sample(num_rows=majority_count-minority_count)\n",
        "  return sd1, train_df\n",
        "\n",
        "# Function to add synthetic data to the main DataFrame based on percentage\n",
        "def add_synthetic_data(main_df, synthetic_df, percentage, seed=42):\n",
        "    # Calculate number of rows to sample\n",
        "    num_rows = int(len(synthetic_df) * percentage)\n",
        "\n",
        "    # Sample the specified percentage of synthetic data\n",
        "    sampled_synthetic_data = synthetic_df.sample(n=num_rows, replace=False, random_state=seed)\n",
        "    # print(sampled_synthetic_data)\n",
        "\n",
        "    # Concatenate sampled synthetic data with main DataFrame\n",
        "    combined_df = pd.concat([main_df, sampled_synthetic_data], ignore_index=True)\n",
        "    # print(combined_df)\n",
        "    return combined_df"
      ],
      "metadata": {
        "id": "o9yiYbcN93gn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Over-Sampling"
      ],
      "metadata": {
        "id": "A3BmbGRgJ5Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def random_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = RandomOverSampler(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "bF2pvEGDJ704"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "TGGkRAzG15Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def smote_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = SMOTE(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "cF6biXPn125o"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM-SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "QutsbBwdMujq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def svm_smote_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = SVMSMOTE(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "XwF74E6XMzG4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intelligent Pruning"
      ],
      "metadata": {
        "id": "x7qohyP7L0DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_majority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    max_label = max(zip(counts, labels))[1]\n",
        "    indices_with_max_label = np.where(y == max_label)[0]\n",
        "    X_maj, y_maj = X[indices_with_max_label], y[indices_with_max_label]\n",
        "\n",
        "    # Exclude majority class samples\n",
        "    indices_without_max_label = np.where(y != max_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_max_label], y[indices_without_max_label]\n",
        "\n",
        "    return X_maj, y_maj, X_remaining, y_remaining, min(counts)\n",
        "\n",
        "def do_clustering(X, y, labels):\n",
        "  clustered_X = defaultdict(list)\n",
        "  clustered_y = defaultdict(list)\n",
        "\n",
        "  for i, label in enumerate(labels):\n",
        "      clustered_X[label].append(X[i])\n",
        "      clustered_y[label].append(y[i])\n",
        "\n",
        "  # Sort clustered_X and clustered_y in descending order based on the length of values in each dictionary\n",
        "  sorted_clustered_X = dict(sorted(clustered_X.items(), key=lambda x: -len(x[1])))\n",
        "  sorted_clustered_y = dict(sorted(clustered_y.items(), key=lambda x: -len(x[1])))\n",
        "\n",
        "  return sorted_clustered_X, sorted_clustered_y\n",
        "\n",
        "\n",
        "def intelligent_prune_data(pruning_samps, pruning_ratios, clustered_X, clustered_y, per_cluster_pruning_ratio=0.7, seed=42):\n",
        "  random.seed(seed)\n",
        "  pruning_ratios_X_maj, pruning_ratios_y_maj = defaultdict(list), defaultdict(list)\n",
        "  for pruning_samp, pruning_ratio in zip(pruning_samps, pruning_ratios):\n",
        "    samps = 0\n",
        "    # print(\"For Pruning samps: \", pruning_samp)\n",
        "    prune_samps = pruning_samp\n",
        "    # print(prune_samps)\n",
        "    clustered_X_new = defaultdict(list)\n",
        "    clustered_y_new = defaultdict(list)\n",
        "    # Iterate over the sorted dictionaries\n",
        "    for label, values_X in clustered_X.items():\n",
        "        # Calculate the number of samples to prune\n",
        "        num_samples_to_prune = int(prune_samps * per_cluster_pruning_ratio)\n",
        "        if(num_samples_to_prune > len(values_X)):\n",
        "          num_samples_to_prune = len(values_X)//2\n",
        "          prune_samps -= num_samples_to_prune\n",
        "        else:\n",
        "          prune_samps -= num_samples_to_prune\n",
        "\n",
        "        # Randomly choose samples to prune\n",
        "        indices_to_prune = random.sample(range(len(values_X)), num_samples_to_prune)\n",
        "\n",
        "        # Prune the samples from clustered_X and clustered_y\n",
        "        clustered_X_new[label] = [values_X[i] for i in range(len(values_X)) if i not in indices_to_prune]\n",
        "        clustered_y_new[label] = [clustered_y[label][i] for i in range(len(clustered_y[label])) if i not in indices_to_prune]\n",
        "\n",
        "    iter = 0\n",
        "    while(prune_samps > 0):\n",
        "        if(iter>=100):\n",
        "          break\n",
        "        for label, values_X in clustered_X_new.items():\n",
        "          if(prune_samps <=0 or len(values_X) <= 0):\n",
        "            break\n",
        "          # print(len(values_X))\n",
        "          index_to_prune = random.sample(range(len(values_X)), 1)\n",
        "          clustered_X_new[label] = [values_X[i] for i in range(len(values_X)) if i not in index_to_prune]\n",
        "          clustered_y_new[label] = [clustered_y_new[label][i] for i in range(len(clustered_y_new[label])) if i not in index_to_prune]\n",
        "\n",
        "          prune_samps -= 1\n",
        "        iter += 1\n",
        "\n",
        "    for label in clustered_X_new:\n",
        "        pruning_ratios_X_maj[pruning_ratio].extend(clustered_X_new[label])\n",
        "        pruning_ratios_y_maj[pruning_ratio].extend(clustered_y_new[label])\n",
        "\n",
        "  return pruning_ratios_X_maj, pruning_ratios_y_maj\n",
        "\n",
        "def combine_data(pruning_ratios, pruning_ratios_X_maj, pruning_ratios_y_maj, X_remaining, y_remaining):\n",
        "\n",
        "  pruning_ratios_X, pruning_ratios_y = defaultdict(list), defaultdict(list)\n",
        "  for pruning_ratio in pruning_ratios:\n",
        "    pruning_ratios_X[pruning_ratio].extend(pruning_ratios_X_maj[pruning_ratio])\n",
        "    pruning_ratios_X[pruning_ratio].extend(X_remaining)\n",
        "\n",
        "    pruning_ratios_y[pruning_ratio].extend(pruning_ratios_y_maj[pruning_ratio])\n",
        "    pruning_ratios_y[pruning_ratio].extend(y_remaining)\n",
        "\n",
        "  return pruning_ratios_X, pruning_ratios_y\n",
        "\n",
        "def do_intelligent_pruning(X, y, ratio, per_cluster_pruning_ratio=0.7, seed=42):\n",
        "\n",
        "  X_maj, y_maj, X_remaining, y_remaining, min_class_samples = find_majority_data(X, y)\n",
        "  kmeans = KMeans(n_clusters=3, random_state = 42)\n",
        "  kmeans.fit(X_maj)\n",
        "  labels = kmeans.labels_\n",
        "  clustered_X, clustered_y = do_clustering(X_maj, y_maj, labels)\n",
        "\n",
        "  pruning_best = len(X_maj)-min_class_samples\n",
        "  pruning_samps = [int(pruning_best * ratio)]\n",
        "  pruning_ratios = [ratio]\n",
        "\n",
        "  pruning_ratios_X_maj, pruning_ratios_y_maj = intelligent_prune_data(pruning_samps, pruning_ratios, clustered_X, clustered_y, \\\n",
        "                                                                      per_cluster_pruning_ratio=per_cluster_pruning_ratio, seed=seed)\n",
        "\n",
        "  pruning_ratios_X, pruning_ratios_y = combine_data(pruning_ratios, pruning_ratios_X_maj, pruning_ratios_y_maj, X_remaining, y_remaining)\n",
        "\n",
        "  return list(pruning_ratios_X.values()), list(pruning_ratios_y.values())\n"
      ],
      "metadata": {
        "id": "w9_Pj009Lxp9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Pruning"
      ],
      "metadata": {
        "id": "yky--qnU6rg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "inputs:\n",
        "X: np.array\n",
        "y: np.array\n",
        "percentage: from 0% upto 100%, enter int value\n",
        "\"\"\"\n",
        "def random_prune_data(X, y, ratio, seed = 42):\n",
        "  # preprocessed_X, scaler, imputer = preprocess_data_train(X)\n",
        "  # preprocessed_X_test = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "  # X_train, y_train = preprocessed_X_train.to_numpy(), y_train.to_numpy()\n",
        "  # X_test, y_test = preprocessed_X_test.to_numpy(), y_test.to_numpy()\n",
        "  np.random.seed(seed)\n",
        "  labels_count = {}\n",
        "  labels = np.unique(y)\n",
        "  for label in labels:\n",
        "    labels_count[label] = np.count_nonzero(y == label)\n",
        "  max_label = min_label = labels[0]\n",
        "  for label in labels_count:\n",
        "    if labels_count[label] > labels_count[max_label]:\n",
        "      max_label = label\n",
        "    if labels_count[label] < labels_count[min_label]:\n",
        "      min_label = label\n",
        "\n",
        "  # print(\"Max\", max_label, labels_count[max_label])\n",
        "  # print(\"Min\", min_label, labels_count[min_label])\n",
        "\n",
        "  prune_counts = {}\n",
        "  prune_indexes = {}\n",
        "  for label in labels_count:\n",
        "    prune_counts[label] = labels_count[label] - labels_count[min_label]\n",
        "    prune_indexes[label] = np.where(y == label)[0]\n",
        "\n",
        "  prune_amount = int(ratio * sum(map(lambda x: x[1], prune_counts.items())))\n",
        "  prune_it = {}\n",
        "\n",
        "  while prune_amount > 0:\n",
        "    for label in labels:\n",
        "      if (len(prune_indexes[label]) - labels_count[min_label]) > 0 and prune_amount > 0:\n",
        "        random_index = np.random.choice(len(prune_indexes[label]))\n",
        "        random_item = prune_indexes[label][random_index]\n",
        "        prune_indexes[label] = np.delete(prune_indexes[label], random_index)\n",
        "        if prune_it.get(label, None) is None:\n",
        "          prune_it[label] = np.array([])\n",
        "        prune_it[label] = np.append(prune_it[label], [random_item])\n",
        "        prune_amount -= 1\n",
        "\n",
        "\n",
        "\n",
        "  formatted_indexes = np.array([])\n",
        "  for label in prune_indexes:\n",
        "    formatted_indexes = np.append(formatted_indexes, prune_indexes[label])\n",
        "  formatted_indexes = np.sort(formatted_indexes)\n",
        "  new_arr = np.array([np.int64(i) for i in formatted_indexes])\n",
        "\n",
        "  return X[new_arr], y[new_arr]"
      ],
      "metadata": {
        "id": "BtB6jqhZtRD0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratios = [ratio for ratio in np.arange(0.2, 1.1, 0.2)]"
      ],
      "metadata": {
        "id": "z0A-h4iX3J8p"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Intelligent Pruning"
      ],
      "metadata": {
        "id": "UY6hAjLw9fy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_intelligent_pruning = dict()\n",
        "per_cluster_pruning_ratios = [0.5, 0.7, 0.9, 1]\n",
        "\n",
        "for per_cluster_pruning_ratio in per_cluster_pruning_ratios:\n",
        "  print(f'For per-cluster pruning ratio {per_cluster_pruning_ratio}')\n",
        "  for ratio in ratios:\n",
        "    X_train_copy, y_train_copy = X_train.copy(), y_train.copy()\n",
        "\n",
        "    intelligent_pruned_X_train, intelligent_pruned_y_train = do_intelligent_pruning(X_train_copy.to_numpy(), y_train_copy.to_numpy(), ratio, per_cluster_pruning_ratio=per_cluster_pruning_ratio)\n",
        "\n",
        "    print(len(intelligent_pruned_X_train[0]))\n",
        "    preprocessed_intelligent_pruned_X_train, scaler = preprocess_data_train((np.array(intelligent_pruned_X_train))[0])\n",
        "    preprocessed_X_test = preprocess_data_test(X_test, scaler)\n",
        "\n",
        "    intelligent_pruned_X_train, intelligent_pruned_y_train = preprocessed_intelligent_pruned_X_train, (np.array(intelligent_pruned_y_train))[0]\n",
        "    intelligent_pruned_X_test, intelligent_pruned_y_test = preprocessed_X_test, y_test.to_numpy()\n",
        "    print(f\"Train data pruned intelligently at {ratio * 100}% :\")\n",
        "    results = evaluate_models(intelligent_pruned_X_train, intelligent_pruned_X_test, intelligent_pruned_y_train, intelligent_pruned_y_test)\n",
        "    print(results)\n",
        "    results_intelligent_pruning[ratio] = results\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRV_KrPy9is0",
        "outputId": "780068a0-05b6-4ca8-e579-7a0b35bc27f0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For per-cluster pruning ratio 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3428\n",
            "Train data pruned intelligently at 20.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.868, 'Precision': 0.547945205479452, 'Recall': 0.28776978417266186, 'F1 Score': 0.37735849056603776, 'ROC AUC': 0.8276974239423792, 'Confusion Matrix': array([[828,  33],\n",
            "       [ 99,  40]])}, 'SVM': {'Accuracy': 0.927, 'Precision': 0.8666666666666667, 'Recall': 0.5611510791366906, 'F1 Score': 0.6812227074235807, 'ROC AUC': 0.9093073972877447, 'Confusion Matrix': array([[849,  12],\n",
            "       [ 61,  78]])}, 'Decision Tree': {'Accuracy': 0.917, 'Precision': 0.6818181818181818, 'Recall': 0.7553956834532374, 'F1 Score': 0.7167235494880545, 'ROC AUC': 0.8492425571737732, 'Confusion Matrix': array([[812,  49],\n",
            "       [ 34, 105]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2855\n",
            "Train data pruned intelligently at 40.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.864, 'Precision': 0.5142857142857142, 'Recall': 0.38848920863309355, 'F1 Score': 0.4426229508196722, 'ROC AUC': 0.8271292373766493, 'Confusion Matrix': array([[810,  51],\n",
            "       [ 85,  54]])}, 'SVM': {'Accuracy': 0.933, 'Precision': 0.8529411764705882, 'Recall': 0.6258992805755396, 'F1 Score': 0.7219917012448133, 'ROC AUC': 0.9061573041218594, 'Confusion Matrix': array([[846,  15],\n",
            "       [ 52,  87]])}, 'Decision Tree': {'Accuracy': 0.914, 'Precision': 0.6666666666666666, 'Recall': 0.762589928057554, 'F1 Score': 0.7114093959731543, 'ROC AUC': 0.8505167991042706, 'Confusion Matrix': array([[808,  53],\n",
            "       [ 33, 106]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2282\n",
            "Train data pruned intelligently at 60.00000000000001% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.845, 'Precision': 0.44366197183098594, 'Recall': 0.45323741007194246, 'F1 Score': 0.4483985765124555, 'ROC AUC': 0.8221408935569313, 'Confusion Matrix': array([[782,  79],\n",
            "       [ 76,  63]])}, 'SVM': {'Accuracy': 0.925, 'Precision': 0.7461538461538462, 'Recall': 0.697841726618705, 'F1 Score': 0.7211895910780669, 'ROC AUC': 0.89994067463799, 'Confusion Matrix': array([[828,  33],\n",
            "       [ 42,  97]])}, 'Decision Tree': {'Accuracy': 0.888, 'Precision': 0.5721925133689839, 'Recall': 0.7697841726618705, 'F1 Score': 0.6564417177914109, 'ROC AUC': 0.838434478897718, 'Confusion Matrix': array([[781,  80],\n",
            "       [ 32, 107]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1709\n",
            "Train data pruned intelligently at 80.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.778, 'Precision': 0.33976833976833976, 'Recall': 0.6330935251798561, 'F1 Score': 0.4422110552763819, 'ROC AUC': 0.7928375069978859, 'Confusion Matrix': array([[690, 171],\n",
            "       [ 51,  88]])}, 'SVM': {'Accuracy': 0.871, 'Precision': 0.5242718446601942, 'Recall': 0.7769784172661871, 'F1 Score': 0.6260869565217391, 'ROC AUC': 0.8809482031099859, 'Confusion Matrix': array([[763,  98],\n",
            "       [ 31, 108]])}, 'Decision Tree': {'Accuracy': 0.824, 'Precision': 0.4312267657992565, 'Recall': 0.8345323741007195, 'F1 Score': 0.5686274509803921, 'ROC AUC': 0.828416012834332, 'Confusion Matrix': array([[708, 153],\n",
            "       [ 23, 116]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1389\n",
            "Train data pruned intelligently at 100.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.78, 'Precision': 0.34600760456273766, 'Recall': 0.6546762589928058, 'F1 Score': 0.4527363184079602, 'ROC AUC': 0.8093650515127968, 'Confusion Matrix': array([[689, 172],\n",
            "       [ 48,  91]])}, 'SVM': {'Accuracy': 0.85, 'Precision': 0.4765957446808511, 'Recall': 0.8057553956834532, 'F1 Score': 0.5989304812834224, 'ROC AUC': 0.8815999465236173, 'Confusion Matrix': array([[738, 123],\n",
            "       [ 27, 112]])}, 'Decision Tree': {'Accuracy': 0.807, 'Precision': 0.40425531914893614, 'Recall': 0.8201438848920863, 'F1 Score': 0.5415676959619953, 'ROC AUC': 0.8125109668362871, 'Confusion Matrix': array([[693, 168],\n",
            "       [ 25, 114]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3428\n",
            "Train data pruned intelligently at 20.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.868, 'Precision': 0.5466666666666666, 'Recall': 0.2949640287769784, 'F1 Score': 0.38317757009345793, 'ROC AUC': 0.8258006834950157, 'Confusion Matrix': array([[827,  34],\n",
            "       [ 98,  41]])}, 'SVM': {'Accuracy': 0.932, 'Precision': 0.9080459770114943, 'Recall': 0.5683453237410072, 'F1 Score': 0.6991150442477876, 'ROC AUC': 0.9095914905706097, 'Confusion Matrix': array([[853,   8],\n",
            "       [ 60,  79]])}, 'Decision Tree': {'Accuracy': 0.916, 'Precision': 0.6729559748427673, 'Recall': 0.7697841726618705, 'F1 Score': 0.7181208053691275, 'ROC AUC': 0.8546946414993442, 'Confusion Matrix': array([[809,  52],\n",
            "       [ 32, 107]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2855\n",
            "Train data pruned intelligently at 40.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.854, 'Precision': 0.4690265486725664, 'Recall': 0.381294964028777, 'F1 Score': 0.42063492063492064, 'ROC AUC': 0.81921640388038, 'Confusion Matrix': array([[801,  60],\n",
            "       [ 86,  53]])}, 'SVM': {'Accuracy': 0.924, 'Precision': 0.7837837837837838, 'Recall': 0.6258992805755396, 'F1 Score': 0.696, 'ROC AUC': 0.9028902313689118, 'Confusion Matrix': array([[837,  24],\n",
            "       [ 52,  87]])}, 'Decision Tree': {'Accuracy': 0.89, 'Precision': 0.5792349726775956, 'Recall': 0.762589928057554, 'F1 Score': 0.658385093167702, 'ROC AUC': 0.8365795168743055, 'Confusion Matrix': array([[784,  77],\n",
            "       [ 33, 106]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2282\n",
            "Train data pruned intelligently at 60.00000000000001% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.817, 'Precision': 0.3910891089108911, 'Recall': 0.5683453237410072, 'F1 Score': 0.4633431085043988, 'ROC AUC': 0.7901469764954587, 'Confusion Matrix': array([[738, 123],\n",
            "       [ 60,  79]])}, 'SVM': {'Accuracy': 0.883, 'Precision': 0.5647058823529412, 'Recall': 0.6906474820143885, 'F1 Score': 0.6213592233009709, 'ROC AUC': 0.8844325236674773, 'Confusion Matrix': array([[787,  74],\n",
            "       [ 43,  96]])}, 'Decision Tree': {'Accuracy': 0.848, 'Precision': 0.47280334728033474, 'Recall': 0.8129496402877698, 'F1 Score': 0.5978835978835979, 'ROC AUC': 0.8333040884365678, 'Confusion Matrix': array([[735, 126],\n",
            "       [ 26, 113]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1709\n",
            "Train data pruned intelligently at 80.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.37185929648241206, 'Recall': 0.5323741007194245, 'F1 Score': 0.4378698224852071, 'ROC AUC': 0.7938485448574939, 'Confusion Matrix': array([[736, 125],\n",
            "       [ 65,  74]])}, 'SVM': {'Accuracy': 0.887, 'Precision': 0.5730337078651685, 'Recall': 0.7338129496402878, 'F1 Score': 0.6435331230283912, 'ROC AUC': 0.8830204129379422, 'Confusion Matrix': array([[785,  76],\n",
            "       [ 37, 102]])}, 'Decision Tree': {'Accuracy': 0.83, 'Precision': 0.4396887159533074, 'Recall': 0.8129496402877698, 'F1 Score': 0.5707070707070707, 'ROC AUC': 0.822851126764094, 'Confusion Matrix': array([[717, 144],\n",
            "       [ 26, 113]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1985\n",
            "Train data pruned intelligently at 100.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.836, 'Precision': 0.4251497005988024, 'Recall': 0.5107913669064749, 'F1 Score': 0.46405228758169936, 'ROC AUC': 0.8335798260346426, 'Confusion Matrix': array([[765,  96],\n",
            "       [ 68,  71]])}, 'SVM': {'Accuracy': 0.909, 'Precision': 0.6538461538461539, 'Recall': 0.7338129496402878, 'F1 Score': 0.6915254237288135, 'ROC AUC': 0.8988043015065299, 'Confusion Matrix': array([[807,  54],\n",
            "       [ 37, 102]])}, 'Decision Tree': {'Accuracy': 0.892, 'Precision': 0.5828877005347594, 'Recall': 0.7841726618705036, 'F1 Score': 0.6687116564417177, 'ROC AUC': 0.846790163687865, 'Confusion Matrix': array([[783,  78],\n",
            "       [ 30, 109]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3428\n",
            "Train data pruned intelligently at 20.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.868, 'Precision': 0.5443037974683544, 'Recall': 0.30935251798561153, 'F1 Score': 0.3944954128440367, 'ROC AUC': 0.8237034066126889, 'Confusion Matrix': array([[825,  36],\n",
            "       [ 96,  43]])}, 'SVM': {'Accuracy': 0.93, 'Precision': 0.8791208791208791, 'Recall': 0.5755395683453237, 'F1 Score': 0.6956521739130435, 'ROC AUC': 0.9098755838534747, 'Confusion Matrix': array([[850,  11],\n",
            "       [ 59,  80]])}, 'Decision Tree': {'Accuracy': 0.917, 'Precision': 0.675, 'Recall': 0.7769784172661871, 'F1 Score': 0.7224080267558529, 'ROC AUC': 0.8582917638015024, 'Confusion Matrix': array([[809,  52],\n",
            "       [ 31, 108]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2855\n",
            "Train data pruned intelligently at 40.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.85, 'Precision': 0.456, 'Recall': 0.41007194244604317, 'F1 Score': 0.4318181818181818, 'ROC AUC': 0.805864019585725, 'Confusion Matrix': array([[793,  68],\n",
            "       [ 82,  57]])}, 'SVM': {'Accuracy': 0.917, 'Precision': 0.7222222222222222, 'Recall': 0.6546762589928058, 'F1 Score': 0.6867924528301887, 'ROC AUC': 0.8973587680378344, 'Confusion Matrix': array([[826,  35],\n",
            "       [ 48,  91]])}, 'Decision Tree': {'Accuracy': 0.907, 'Precision': 0.6263736263736264, 'Recall': 0.8201438848920863, 'F1 Score': 0.7102803738317757, 'ROC AUC': 0.8705829761278085, 'Confusion Matrix': array([[793,  68],\n",
            "       [ 25, 114]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2282\n",
            "Train data pruned intelligently at 60.00000000000001% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.841, 'Precision': 0.4295774647887324, 'Recall': 0.43884892086330934, 'F1 Score': 0.4341637010676156, 'ROC AUC': 0.8047777805630061, 'Confusion Matrix': array([[780,  81],\n",
            "       [ 78,  61]])}, 'SVM': {'Accuracy': 0.905, 'Precision': 0.6549295774647887, 'Recall': 0.6690647482014388, 'F1 Score': 0.6619217081850532, 'ROC AUC': 0.8898637187810726, 'Confusion Matrix': array([[812,  49],\n",
            "       [ 46,  93]])}, 'Decision Tree': {'Accuracy': 0.885, 'Precision': 0.5612244897959183, 'Recall': 0.7913669064748201, 'F1 Score': 0.6567164179104478, 'ROC AUC': 0.8457415252467017, 'Confusion Matrix': array([[775,  86],\n",
            "       [ 29, 110]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1985\n",
            "Train data pruned intelligently at 80.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.836, 'Precision': 0.4251497005988024, 'Recall': 0.5107913669064749, 'F1 Score': 0.46405228758169936, 'ROC AUC': 0.8335798260346426, 'Confusion Matrix': array([[765,  96],\n",
            "       [ 68,  71]])}, 'SVM': {'Accuracy': 0.909, 'Precision': 0.6538461538461539, 'Recall': 0.7338129496402878, 'F1 Score': 0.6915254237288135, 'ROC AUC': 0.8988043015065299, 'Confusion Matrix': array([[807,  54],\n",
            "       [ 37, 102]])}, 'Decision Tree': {'Accuracy': 0.892, 'Precision': 0.5828877005347594, 'Recall': 0.7841726618705036, 'F1 Score': 0.6687116564417177, 'ROC AUC': 0.846790163687865, 'Confusion Matrix': array([[783,  78],\n",
            "       [ 30, 109]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1985\n",
            "Train data pruned intelligently at 100.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.836, 'Precision': 0.4251497005988024, 'Recall': 0.5107913669064749, 'F1 Score': 0.46405228758169936, 'ROC AUC': 0.8335798260346426, 'Confusion Matrix': array([[765,  96],\n",
            "       [ 68,  71]])}, 'SVM': {'Accuracy': 0.909, 'Precision': 0.6538461538461539, 'Recall': 0.7338129496402878, 'F1 Score': 0.6915254237288135, 'ROC AUC': 0.8988043015065299, 'Confusion Matrix': array([[807,  54],\n",
            "       [ 37, 102]])}, 'Decision Tree': {'Accuracy': 0.892, 'Precision': 0.5828877005347594, 'Recall': 0.7841726618705036, 'F1 Score': 0.6687116564417177, 'ROC AUC': 0.846790163687865, 'Confusion Matrix': array([[783,  78],\n",
            "       [ 30, 109]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3428\n",
            "Train data pruned intelligently at 20.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.868, 'Precision': 0.5411764705882353, 'Recall': 0.33093525179856115, 'F1 Score': 0.4107142857142857, 'ROC AUC': 0.8231853541556998, 'Confusion Matrix': array([[822,  39],\n",
            "       [ 93,  46]])}, 'SVM': {'Accuracy': 0.93, 'Precision': 0.8791208791208791, 'Recall': 0.5755395683453237, 'F1 Score': 0.6956521739130435, 'ROC AUC': 0.909892295223055, 'Confusion Matrix': array([[850,  11],\n",
            "       [ 59,  80]])}, 'Decision Tree': {'Accuracy': 0.923, 'Precision': 0.6962025316455697, 'Recall': 0.7913669064748201, 'F1 Score': 0.7407407407407407, 'ROC AUC': 0.8678088887774797, 'Confusion Matrix': array([[813,  48],\n",
            "       [ 29, 110]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2855\n",
            "Train data pruned intelligently at 40.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.839, 'Precision': 0.42567567567567566, 'Recall': 0.45323741007194246, 'F1 Score': 0.4390243902439024, 'ROC AUC': 0.7963803173489084, 'Confusion Matrix': array([[776,  85],\n",
            "       [ 76,  63]])}, 'SVM': {'Accuracy': 0.909, 'Precision': 0.6846153846153846, 'Recall': 0.6402877697841727, 'F1 Score': 0.6617100371747212, 'ROC AUC': 0.8955038060144219, 'Confusion Matrix': array([[820,  41],\n",
            "       [ 50,  89]])}, 'Decision Tree': {'Accuracy': 0.882, 'Precision': 0.551219512195122, 'Recall': 0.8129496402877698, 'F1 Score': 0.6569767441860466, 'ROC AUC': 0.8530485715956851, 'Confusion Matrix': array([[769,  92],\n",
            "       [ 26, 113]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2282\n",
            "Train data pruned intelligently at 60.00000000000001% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.836, 'Precision': 0.41830065359477125, 'Recall': 0.460431654676259, 'F1 Score': 0.4383561643835616, 'ROC AUC': 0.7909491222353128, 'Confusion Matrix': array([[772,  89],\n",
            "       [ 75,  64]])}, 'SVM': {'Accuracy': 0.906, 'Precision': 0.6551724137931034, 'Recall': 0.6834532374100719, 'F1 Score': 0.6690140845070423, 'ROC AUC': 0.8850007102332073, 'Confusion Matrix': array([[811,  50],\n",
            "       [ 44,  95]])}, 'Decision Tree': {'Accuracy': 0.885, 'Precision': 0.5588235294117647, 'Recall': 0.8201438848920863, 'F1 Score': 0.6647230320699709, 'ROC AUC': 0.8578071340836738, 'Confusion Matrix': array([[771,  90],\n",
            "       [ 25, 114]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1985\n",
            "Train data pruned intelligently at 80.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.836, 'Precision': 0.4251497005988024, 'Recall': 0.5107913669064749, 'F1 Score': 0.46405228758169936, 'ROC AUC': 0.8335798260346426, 'Confusion Matrix': array([[765,  96],\n",
            "       [ 68,  71]])}, 'SVM': {'Accuracy': 0.909, 'Precision': 0.6538461538461539, 'Recall': 0.7338129496402878, 'F1 Score': 0.6915254237288135, 'ROC AUC': 0.8988043015065299, 'Confusion Matrix': array([[807,  54],\n",
            "       [ 37, 102]])}, 'Decision Tree': {'Accuracy': 0.892, 'Precision': 0.5828877005347594, 'Recall': 0.7841726618705036, 'F1 Score': 0.6687116564417177, 'ROC AUC': 0.846790163687865, 'Confusion Matrix': array([[783,  78],\n",
            "       [ 30, 109]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1985\n",
            "Train data pruned intelligently at 100.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.836, 'Precision': 0.4251497005988024, 'Recall': 0.5107913669064749, 'F1 Score': 0.46405228758169936, 'ROC AUC': 0.8335798260346426, 'Confusion Matrix': array([[765,  96],\n",
            "       [ 68,  71]])}, 'SVM': {'Accuracy': 0.909, 'Precision': 0.6538461538461539, 'Recall': 0.7338129496402878, 'F1 Score': 0.6915254237288135, 'ROC AUC': 0.8988043015065299, 'Confusion Matrix': array([[807,  54],\n",
            "       [ 37, 102]])}, 'Decision Tree': {'Accuracy': 0.892, 'Precision': 0.5828877005347594, 'Recall': 0.7841726618705036, 'F1 Score': 0.6687116564417177, 'ROC AUC': 0.846790163687865, 'Confusion Matrix': array([[783,  78],\n",
            "       [ 30, 109]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calling Random Pruning"
      ],
      "metadata": {
        "id": "uGrS3yXb-RYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_random_pruning = dict()\n",
        "for ratio in ratios:\n",
        "  random_pruned_X_train, random_pruned_y_train = random_prune_data(X_train.to_numpy(), y_train.to_numpy(), ratio)\n",
        "  preprocessed_random_pruned_X_train, scaler = preprocess_data_train(random_pruned_X_train)\n",
        "  preprocessed_X_test = preprocess_data_test(X_test, scaler)\n",
        "\n",
        "  random_pruned_X_train, random_pruned_y_train = preprocessed_random_pruned_X_train, random_pruned_y_train\n",
        "  random_pruned_X_test, random_pruned_y_test = preprocessed_X_test, y_test.to_numpy()\n",
        "\n",
        "  print(f\"Train data pruned randomly at {ratio * 100}% :\")\n",
        "  results = evaluate_models(random_pruned_X_train, random_pruned_X_test, random_pruned_y_train, random_pruned_y_test)\n",
        "  print(results)\n",
        "  results_random_pruning[ratio] = results\n",
        "  print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "4od9tUcU-QI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61b2361-cc8a-4464-906f-6f33275ffc7b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned randomly at 20.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.865, 'Precision': 0.5277777777777778, 'Recall': 0.2733812949640288, 'F1 Score': 0.3601895734597157, 'ROC AUC': 0.8284160128343319, 'Confusion Matrix': array([[827,  34],\n",
            "       [101,  38]])}, 'SVM': {'Accuracy': 0.931, 'Precision': 0.8888888888888888, 'Recall': 0.5755395683453237, 'F1 Score': 0.6986899563318778, 'ROC AUC': 0.9096416246793507, 'Confusion Matrix': array([[851,  10],\n",
            "       [ 59,  80]])}, 'Decision Tree': {'Accuracy': 0.904, 'Precision': 0.6335403726708074, 'Recall': 0.7338129496402878, 'F1 Score': 0.68, 'ROC AUC': 0.8326439893381461, 'Confusion Matrix': array([[802,  59],\n",
            "       [ 37, 102]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 40.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.866, 'Precision': 0.5257731958762887, 'Recall': 0.3669064748201439, 'F1 Score': 0.43220338983050843, 'ROC AUC': 0.8291346017262845, 'Confusion Matrix': array([[815,  46],\n",
            "       [ 88,  51]])}, 'SVM': {'Accuracy': 0.931, 'Precision': 0.8301886792452831, 'Recall': 0.6330935251798561, 'F1 Score': 0.7183673469387756, 'ROC AUC': 0.9074691466339123, 'Confusion Matrix': array([[843,  18],\n",
            "       [ 51,  88]])}, 'Decision Tree': {'Accuracy': 0.887, 'Precision': 0.5691489361702128, 'Recall': 0.7697841726618705, 'F1 Score': 0.654434250764526, 'ROC AUC': 0.837853758804803, 'Confusion Matrix': array([[780,  81],\n",
            "       [ 32, 107]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 60.00000000000001% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.856, 'Precision': 0.4796747967479675, 'Recall': 0.4244604316546763, 'F1 Score': 0.45038167938931295, 'ROC AUC': 0.8296526541832736, 'Confusion Matrix': array([[797,  64],\n",
            "       [ 80,  59]])}, 'SVM': {'Accuracy': 0.921, 'Precision': 0.7307692307692307, 'Recall': 0.6834532374100719, 'F1 Score': 0.7063197026022305, 'ROC AUC': 0.9009099340736472, 'Confusion Matrix': array([[826,  35],\n",
            "       [ 44,  95]])}, 'Decision Tree': {'Accuracy': 0.883, 'Precision': 0.5555555555555556, 'Recall': 0.7913669064748201, 'F1 Score': 0.6528189910979229, 'ROC AUC': 0.844580085060871, 'Confusion Matrix': array([[773,  88],\n",
            "       [ 29, 110]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 80.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.835, 'Precision': 0.42696629213483145, 'Recall': 0.5467625899280576, 'F1 Score': 0.4794952681388012, 'ROC AUC': 0.8316830855872793, 'Confusion Matrix': array([[759, 102],\n",
            "       [ 63,  76]])}, 'SVM': {'Accuracy': 0.902, 'Precision': 0.6227544910179641, 'Recall': 0.7482014388489209, 'F1 Score': 0.6797385620915033, 'ROC AUC': 0.8946682375354073, 'Confusion Matrix': array([[798,  63],\n",
            "       [ 35, 104]])}, 'Decision Tree': {'Accuracy': 0.864, 'Precision': 0.5071090047393365, 'Recall': 0.7697841726618705, 'F1 Score': 0.6114285714285714, 'ROC AUC': 0.8244971966677529, 'Confusion Matrix': array([[757, 104],\n",
            "       [ 32, 107]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 100.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.766, 'Precision': 0.34824281150159747, 'Recall': 0.7841726618705036, 'F1 Score': 0.4823008849557523, 'ROC AUC': 0.8308224500538942, 'Confusion Matrix': array([[657, 204],\n",
            "       [ 30, 109]])}, 'SVM': {'Accuracy': 0.846, 'Precision': 0.4701195219123506, 'Recall': 0.8489208633093526, 'F1 Score': 0.6051282051282052, 'ROC AUC': 0.8875241270398315, 'Confusion Matrix': array([[728, 133],\n",
            "       [ 21, 118]])}, 'Decision Tree': {'Accuracy': 0.83, 'Precision': 0.44106463878326996, 'Recall': 0.8345323741007195, 'F1 Score': 0.5771144278606966, 'ROC AUC': 0.8319003333918231, 'Confusion Matrix': array([[714, 147],\n",
            "       [ 23, 116]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SDV-Oversampling"
      ],
      "metadata": {
        "id": "f_VUTRHBBVDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sd1, train_df = do_sdv(X_train, y_train)\n",
        "results_syn_sdv = dict()\n",
        "\n",
        "# Add synthetic data at different percentages to the main DataFrame\n",
        "for ratio in ratios:\n",
        "    combined_df = add_synthetic_data(train_df, sd1, ratio)\n",
        "    y_train_sdv = combined_df['target']\n",
        "    X_train_sdv = combined_df.drop('target', axis=1)\n",
        "\n",
        "    X_train_sdv.to_csv(\"sdv.csv\")\n",
        "    preprocessed_X_train_sdv, scaler = preprocess_data_train(X_train_sdv)\n",
        "    preprocessed_X_test_sdv = preprocess_data_test(X_test, scaler)\n",
        "\n",
        "    X_train_sdv, y_train_sdv = preprocessed_X_train_sdv, y_train_sdv.to_numpy()\n",
        "    X_test_sdv, y_test_sdv = preprocessed_X_test_sdv, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    results = evaluate_models(X_train_sdv, X_test_sdv, y_train_sdv, y_test_sdv)\n",
        "    results_syn_sdv[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "g4V6WxpY9kbd",
        "outputId": "af49040c-0506-41d0-a0fc-b19f4fcbc235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sdv/metadata/single_table.py:676: UserWarning: No primary key exists to remove.\n",
            "  warnings.warn('No primary key exists to remove.')\n",
            "/usr/local/lib/python3.10/dist-packages/sdv/single_table/base.py:80: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "{'Logistic Regression': {'Accuracy': 0.861, 'Precision': 0.5, 'Recall': 0.3237410071942446, 'F1 Score': 0.3930131004366812, 'ROC AUC': 0.7564067213128451, 'Confusion Matrix': array([[816,  45],\n",
            "       [ 94,  45]])}, 'SVM': {'Accuracy': 0.913, 'Precision': 0.7131147540983607, 'Recall': 0.6258992805755396, 'F1 Score': 0.6666666666666666, 'ROC AUC': 0.9010185579759189, 'Confusion Matrix': array([[826,  35],\n",
            "       [ 52,  87]])}, 'Decision Tree': {'Accuracy': 0.916, 'Precision': 0.697841726618705, 'Recall': 0.697841726618705, 'F1 Score': 0.697841726618705, 'ROC AUC': 0.8245306194069135, 'Confusion Matrix': array([[819,  42],\n",
            "       [ 42,  97]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "{'Logistic Regression': {'Accuracy': 0.847, 'Precision': 0.43137254901960786, 'Recall': 0.31654676258992803, 'F1 Score': 0.3651452282157676, 'ROC AUC': 0.7231427401632701, 'Confusion Matrix': array([[803,  58],\n",
            "       [ 95,  44]])}, 'SVM': {'Accuracy': 0.903, 'Precision': 0.6693548387096774, 'Recall': 0.5971223021582733, 'F1 Score': 0.6311787072243346, 'ROC AUC': 0.8924790481203886, 'Confusion Matrix': array([[820,  41],\n",
            "       [ 56,  83]])}, 'Decision Tree': {'Accuracy': 0.92, 'Precision': 0.7185185185185186, 'Recall': 0.697841726618705, 'F1 Score': 0.7080291970802921, 'ROC AUC': 0.8268534997785745, 'Confusion Matrix': array([[823,  38],\n",
            "       [ 42,  97]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "{'Logistic Regression': {'Accuracy': 0.833, 'Precision': 0.37719298245614036, 'Recall': 0.30935251798561153, 'F1 Score': 0.3399209486166008, 'ROC AUC': 0.7030306068733865, 'Confusion Matrix': array([[790,  71],\n",
            "       [ 96,  43]])}, 'SVM': {'Accuracy': 0.904, 'Precision': 0.6747967479674797, 'Recall': 0.5971223021582733, 'F1 Score': 0.633587786259542, 'ROC AUC': 0.8885685876385999, 'Confusion Matrix': array([[821,  40],\n",
            "       [ 56,  83]])}, 'Decision Tree': {'Accuracy': 0.92, 'Precision': 0.7218045112781954, 'Recall': 0.6906474820143885, 'F1 Score': 0.7058823529411764, 'ROC AUC': 0.8238370975693314, 'Confusion Matrix': array([[824,  37],\n",
            "       [ 43,  96]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "{'Logistic Regression': {'Accuracy': 0.817, 'Precision': 0.328125, 'Recall': 0.302158273381295, 'F1 Score': 0.31460674157303375, 'ROC AUC': 0.6910569105691056, 'Confusion Matrix': array([[775,  86],\n",
            "       [ 97,  42]])}, 'SVM': {'Accuracy': 0.9, 'Precision': 0.6585365853658537, 'Recall': 0.5827338129496403, 'F1 Score': 0.6183206106870229, 'ROC AUC': 0.8844325236674772, 'Confusion Matrix': array([[819,  42],\n",
            "       [ 58,  81]])}, 'Decision Tree': {'Accuracy': 0.917, 'Precision': 0.7028985507246377, 'Recall': 0.697841726618705, 'F1 Score': 0.7003610108303249, 'ROC AUC': 0.8251113394998286, 'Confusion Matrix': array([[820,  41],\n",
            "       [ 42,  97]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "{'Logistic Regression': {'Accuracy': 0.812, 'Precision': 0.31851851851851853, 'Recall': 0.30935251798561153, 'F1 Score': 0.3138686131386862, 'ROC AUC': 0.6816985436041411, 'Confusion Matrix': array([[769,  92],\n",
            "       [ 96,  43]])}, 'SVM': {'Accuracy': 0.898, 'Precision': 0.648, 'Recall': 0.5827338129496403, 'F1 Score': 0.6136363636363636, 'ROC AUC': 0.8806306870879603, 'Confusion Matrix': array([[817,  44],\n",
            "       [ 58,  81]])}, 'Decision Tree': {'Accuracy': 0.92, 'Precision': 0.7153284671532847, 'Recall': 0.7050359712230215, 'F1 Score': 0.7101449275362319, 'ROC AUC': 0.8298699019878175, 'Confusion Matrix': array([[822,  39],\n",
            "       [ 41,  98]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SMOTE-Oversampling"
      ],
      "metadata": {
        "id": "l78jR_BuCw1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_smote = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_smote, y_train_smote = smote_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "    preprocessed_X_train_smote, scaler = preprocess_data_train((np.array(X_train_smote))[0])\n",
        "    preprocessed_X_test_smote = preprocess_data_test(X_test, scaler)\n",
        "\n",
        "    X_train_smote, y_train_smote = preprocessed_X_train_smote, (np.array(y_train_smote))[0]\n",
        "    X_test_smote, y_test_smote = preprocessed_X_test_smote, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_smote), len(y_train_smote))\n",
        "    results = evaluate_models(X_train_smote, X_test_smote, y_train_smote, y_test_smote)\n",
        "    results_smote[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7S78dnHC0bw",
        "outputId": "003987ab-b3ea-4e77-b278-dd78d08c8f87"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "4572 4572\n",
            "{'Logistic Regression': {'Accuracy': 0.85, 'Precision': 0.45985401459854014, 'Recall': 0.45323741007194246, 'F1 Score': 0.45652173913043476, 'ROC AUC': 0.8246058205700249, 'Confusion Matrix': array([[787,  74],\n",
            "       [ 76,  63]])}, 'SVM': {'Accuracy': 0.924, 'Precision': 0.7647058823529411, 'Recall': 0.6546762589928058, 'F1 Score': 0.7054263565891473, 'ROC AUC': 0.8963727972325972, 'Confusion Matrix': array([[833,  28],\n",
            "       [ 48,  91]])}, 'Decision Tree': {'Accuracy': 0.904, 'Precision': 0.6187845303867403, 'Recall': 0.8057553956834532, 'F1 Score': 0.7, 'ROC AUC': 0.8628080114305767, 'Confusion Matrix': array([[792,  69],\n",
            "       [ 27, 112]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "5145 5145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.822, 'Precision': 0.39790575916230364, 'Recall': 0.5467625899280576, 'F1 Score': 0.46060606060606063, 'ROC AUC': 0.8254246776794592, 'Confusion Matrix': array([[746, 115],\n",
            "       [ 63,  76]])}, 'SVM': {'Accuracy': 0.913, 'Precision': 0.6884057971014492, 'Recall': 0.6834532374100719, 'F1 Score': 0.6859205776173285, 'ROC AUC': 0.8857861446034809, 'Confusion Matrix': array([[818,  43],\n",
            "       [ 44,  95]])}, 'Decision Tree': {'Accuracy': 0.921, 'Precision': 0.6875, 'Recall': 0.7913669064748201, 'F1 Score': 0.7357859531772575, 'ROC AUC': 0.8666474485916493, 'Confusion Matrix': array([[811,  50],\n",
            "       [ 29, 110]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "5718 5718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8, 'Precision': 0.37130801687763715, 'Recall': 0.6330935251798561, 'F1 Score': 0.46808510638297873, 'ROC AUC': 0.8273799079203537, 'Confusion Matrix': array([[712, 149],\n",
            "       [ 51,  88]])}, 'SVM': {'Accuracy': 0.908, 'Precision': 0.6666666666666666, 'Recall': 0.6762589928057554, 'F1 Score': 0.6714285714285714, 'ROC AUC': 0.8791266638257338, 'Confusion Matrix': array([[814,  47],\n",
            "       [ 45,  94]])}, 'Decision Tree': {'Accuracy': 0.911, 'Precision': 0.6470588235294118, 'Recall': 0.7913669064748201, 'F1 Score': 0.7119741100323624, 'ROC AUC': 0.8608402476624971, 'Confusion Matrix': array([[801,  60],\n",
            "       [ 29, 110]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "6291 6291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.78, 'Precision': 0.3568904593639576, 'Recall': 0.7266187050359713, 'F1 Score': 0.47867298578199047, 'ROC AUC': 0.8273799079203535, 'Confusion Matrix': array([[679, 182],\n",
            "       [ 38, 101]])}, 'SVM': {'Accuracy': 0.903, 'Precision': 0.6381578947368421, 'Recall': 0.697841726618705, 'F1 Score': 0.6666666666666667, 'ROC AUC': 0.8747399293109067, 'Confusion Matrix': array([[806,  55],\n",
            "       [ 42,  97]])}, 'Decision Tree': {'Accuracy': 0.899, 'Precision': 0.6055555555555555, 'Recall': 0.7841726618705036, 'F1 Score': 0.683385579937304, 'ROC AUC': 0.8508552043382716, 'Confusion Matrix': array([[790,  71],\n",
            "       [ 30, 109]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "6864 6864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.765, 'Precision': 0.3431372549019608, 'Recall': 0.7553956834532374, 'F1 Score': 0.47191011235955055, 'ROC AUC': 0.8273214181268226, 'Confusion Matrix': array([[660, 201],\n",
            "       [ 34, 105]])}, 'SVM': {'Accuracy': 0.897, 'Precision': 0.6168831168831169, 'Recall': 0.6834532374100719, 'F1 Score': 0.6484641638225257, 'ROC AUC': 0.8710968507424025, 'Confusion Matrix': array([[802,  59],\n",
            "       [ 44,  95]])}, 'Decision Tree': {'Accuracy': 0.913, 'Precision': 0.6460674157303371, 'Recall': 0.8273381294964028, 'F1 Score': 0.725552050473186, 'ROC AUC': 0.877083698894543, 'Confusion Matrix': array([[798,  63],\n",
            "       [ 24, 115]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Random-Oversampling"
      ],
      "metadata": {
        "id": "KKwGBPjpKrJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_random = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_random, y_train_random = random_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "\n",
        "    preprocessed_X_train_random, scaler = preprocess_data_train((np.array(X_train_random)[0]))\n",
        "    preprocessed_X_test_random = preprocess_data_test(X_test, scaler)\n",
        "\n",
        "    X_train_random, y_train_random = preprocessed_X_train_random, (np.array(y_train_random))[0]\n",
        "    X_test_random, y_test_random = preprocessed_X_test_random, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_random), len(y_train_random))\n",
        "    results = evaluate_models(X_train_random, X_test_random, y_train_random, y_test_random)\n",
        "    results_random[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC2kVR1tKtFn",
        "outputId": "10e7bdee-35d9-47a5-81c7-48bd83555bd2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "4572 4572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.852, 'Precision': 0.4645669291338583, 'Recall': 0.4244604316546763, 'F1 Score': 0.443609022556391, 'ROC AUC': 0.8278311148990216, 'Confusion Matrix': array([[793,  68],\n",
            "       [ 80,  59]])}, 'SVM': {'Accuracy': 0.934, 'Precision': 0.8067226890756303, 'Recall': 0.6906474820143885, 'F1 Score': 0.7441860465116279, 'ROC AUC': 0.9044861671638299, 'Confusion Matrix': array([[838,  23],\n",
            "       [ 43,  96]])}, 'Decision Tree': {'Accuracy': 0.92, 'Precision': 0.7092198581560284, 'Recall': 0.7194244604316546, 'F1 Score': 0.7142857142857142, 'ROC AUC': 0.8359027064063035, 'Confusion Matrix': array([[820,  41],\n",
            "       [ 39, 100]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "5145 5145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.826, 'Precision': 0.40540540540540543, 'Recall': 0.539568345323741, 'F1 Score': 0.46296296296296297, 'ROC AUC': 0.8274467533986748, 'Confusion Matrix': array([[751, 110],\n",
            "       [ 64,  75]])}, 'SVM': {'Accuracy': 0.919, 'Precision': 0.704225352112676, 'Recall': 0.7194244604316546, 'F1 Score': 0.7117437722419928, 'ROC AUC': 0.8997150711486559, 'Confusion Matrix': array([[819,  42],\n",
            "       [ 39, 100]])}, 'Decision Tree': {'Accuracy': 0.917, 'Precision': 0.6707317073170732, 'Recall': 0.7913669064748201, 'F1 Score': 0.7260726072607261, 'ROC AUC': 0.8643245682199885, 'Confusion Matrix': array([[807,  54],\n",
            "       [ 29, 110]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "5718 5718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.807, 'Precision': 0.3855932203389831, 'Recall': 0.6546762589928058, 'F1 Score': 0.48533333333333345, 'ROC AUC': 0.8276723568880089, 'Confusion Matrix': array([[716, 145],\n",
            "       [ 48,  91]])}, 'SVM': {'Accuracy': 0.914, 'Precision': 0.6778523489932886, 'Recall': 0.7266187050359713, 'F1 Score': 0.701388888888889, 'ROC AUC': 0.894542902263555, 'Confusion Matrix': array([[813,  48],\n",
            "       [ 38, 101]])}, 'Decision Tree': {'Accuracy': 0.904, 'Precision': 0.6303030303030303, 'Recall': 0.7482014388489209, 'F1 Score': 0.6842105263157895, 'ROC AUC': 0.8386767937566323, 'Confusion Matrix': array([[800,  61],\n",
            "       [ 35, 104]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "6291 6291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.785, 'Precision': 0.36231884057971014, 'Recall': 0.7194244604316546, 'F1 Score': 0.48192771084337344, 'ROC AUC': 0.8278144035294412, 'Confusion Matrix': array([[685, 176],\n",
            "       [ 39, 100]])}, 'SVM': {'Accuracy': 0.902, 'Precision': 0.6289308176100629, 'Recall': 0.7194244604316546, 'F1 Score': 0.6711409395973155, 'ROC AUC': 0.8910836487604342, 'Confusion Matrix': array([[802,  59],\n",
            "       [ 39, 100]])}, 'Decision Tree': {'Accuracy': 0.924, 'Precision': 0.7114093959731543, 'Recall': 0.762589928057554, 'F1 Score': 0.736111111111111, 'ROC AUC': 0.8563240000334228, 'Confusion Matrix': array([[818,  43],\n",
            "       [ 33, 106]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "6864 6864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.764, 'Precision': 0.3450479233226837, 'Recall': 0.7769784172661871, 'F1 Score': 0.47787610619469023, 'ROC AUC': 0.8283324559864303, 'Confusion Matrix': array([[656, 205],\n",
            "       [ 31, 108]])}, 'SVM': {'Accuracy': 0.894, 'Precision': 0.5976331360946746, 'Recall': 0.7266187050359713, 'F1 Score': 0.6558441558441559, 'ROC AUC': 0.8857694332339007, 'Confusion Matrix': array([[793,  68],\n",
            "       [ 38, 101]])}, 'Decision Tree': {'Accuracy': 0.909, 'Precision': 0.6481481481481481, 'Recall': 0.7553956834532374, 'F1 Score': 0.6976744186046512, 'ROC AUC': 0.8445967964304514, 'Confusion Matrix': array([[804,  57],\n",
            "       [ 34, 105]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SVM-SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "28Pi8n0HM4vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_svm_smote = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_svm_smote, y_train_svm_smote = svm_smote_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "\n",
        "    preprocessed_X_train_svm_smote, scaler = preprocess_data_train((np.array(X_train_svm_smote))[0])\n",
        "    preprocessed_X_test_svm_smote = preprocess_data_test(X_test, scaler)\n",
        "\n",
        "    X_train_svm_smote, y_train_svm_smote = preprocessed_X_train_svm_smote, (np.array(y_train_svm_smote))[0]\n",
        "    X_test_svm_smote, y_test_svm_smote = preprocessed_X_test_svm_smote, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_svm_smote), len(y_train_svm_smote))\n",
        "    results = evaluate_models(X_train_svm_smote, X_test_svm_smote, y_train_svm_smote, y_test_svm_smote)\n",
        "    results_svm_smote[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vkEOubrM81F",
        "outputId": "b24e1256-cbba-412b-ca67-8ea03f4799fb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "4572 4572\n",
            "{'Logistic Regression': {'Accuracy': 0.853, 'Precision': 0.46875, 'Recall': 0.4316546762589928, 'F1 Score': 0.449438202247191, 'ROC AUC': 0.8184560365644765, 'Confusion Matrix': array([[793,  68],\n",
            "       [ 79,  60]])}, 'SVM': {'Accuracy': 0.926, 'Precision': 0.7927927927927928, 'Recall': 0.6330935251798561, 'F1 Score': 0.704, 'ROC AUC': 0.9014864763241671, 'Confusion Matrix': array([[838,  23],\n",
            "       [ 51,  88]])}, 'Decision Tree': {'Accuracy': 0.908, 'Precision': 0.6496815286624203, 'Recall': 0.7338129496402878, 'F1 Score': 0.6891891891891891, 'ROC AUC': 0.8349668697098069, 'Confusion Matrix': array([[806,  55],\n",
            "       [ 37, 102]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "5145 5145\n",
            "{'Logistic Regression': {'Accuracy': 0.841, 'Precision': 0.4444444444444444, 'Recall': 0.5755395683453237, 'F1 Score': 0.5015673981191223, 'ROC AUC': 0.8186983514233909, 'Confusion Matrix': array([[761, 100],\n",
            "       [ 59,  80]])}, 'SVM': {'Accuracy': 0.91, 'Precision': 0.6870229007633588, 'Recall': 0.6474820143884892, 'F1 Score': 0.6666666666666666, 'ROC AUC': 0.8955455844383726, 'Confusion Matrix': array([[820,  41],\n",
            "       [ 49,  90]])}, 'Decision Tree': {'Accuracy': 0.911, 'Precision': 0.6506024096385542, 'Recall': 0.7769784172661871, 'F1 Score': 0.7081967213114754, 'ROC AUC': 0.8548074432440111, 'Confusion Matrix': array([[803,  58],\n",
            "       [ 31, 108]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "5718 5718\n",
            "{'Logistic Regression': {'Accuracy': 0.82, 'Precision': 0.4080717488789238, 'Recall': 0.6546762589928058, 'F1 Score': 0.5027624309392266, 'ROC AUC': 0.8194921414784547, 'Confusion Matrix': array([[729, 132],\n",
            "       [ 48,  91]])}, 'SVM': {'Accuracy': 0.902, 'Precision': 0.6394557823129252, 'Recall': 0.6762589928057554, 'F1 Score': 0.6573426573426574, 'ROC AUC': 0.8933480393385639, 'Confusion Matrix': array([[808,  53],\n",
            "       [ 45,  94]])}, 'Decision Tree': {'Accuracy': 0.927, 'Precision': 0.7171052631578947, 'Recall': 0.7841726618705036, 'F1 Score': 0.7491408934707904, 'ROC AUC': 0.8671153669398975, 'Confusion Matrix': array([[818,  43],\n",
            "       [ 30, 109]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "6291 6291\n",
            "{'Logistic Regression': {'Accuracy': 0.799, 'Precision': 0.3798449612403101, 'Recall': 0.7050359712230215, 'F1 Score': 0.4937027707808565, 'ROC AUC': 0.8214975058280901, 'Confusion Matrix': array([[701, 160],\n",
            "       [ 41,  98]])}, 'SVM': {'Accuracy': 0.904, 'Precision': 0.6369426751592356, 'Recall': 0.7194244604316546, 'F1 Score': 0.6756756756756758, 'ROC AUC': 0.889487712965516, 'Confusion Matrix': array([[804,  57],\n",
            "       [ 39, 100]])}, 'Decision Tree': {'Accuracy': 0.911, 'Precision': 0.65625, 'Recall': 0.7553956834532374, 'F1 Score': 0.7023411371237458, 'ROC AUC': 0.8457582366162818, 'Confusion Matrix': array([[806,  55],\n",
            "       [ 34, 105]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "6864 6864\n",
            "{'Logistic Regression': {'Accuracy': 0.781, 'Precision': 0.3591549295774648, 'Recall': 0.7338129496402878, 'F1 Score': 0.48226950354609927, 'ROC AUC': 0.8227007244378713, 'Confusion Matrix': array([[679, 182],\n",
            "       [ 37, 102]])}, 'SVM': {'Accuracy': 0.899, 'Precision': 0.6217948717948718, 'Recall': 0.697841726618705, 'F1 Score': 0.6576271186440678, 'ROC AUC': 0.8874739929310907, 'Confusion Matrix': array([[802,  59],\n",
            "       [ 42,  97]])}, 'Decision Tree': {'Accuracy': 0.917, 'Precision': 0.6707317073170732, 'Recall': 0.7913669064748201, 'F1 Score': 0.7260726072607261, 'ROC AUC': 0.8643245682199885, 'Confusion Matrix': array([[807,  54],\n",
            "       [ 29, 110]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}
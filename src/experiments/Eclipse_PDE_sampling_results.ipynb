{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adipai/data-decent/blob/main/Eclipse_PDE_sampling_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pmlb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAJ8lflEvuaA",
        "outputId": "9c98c64c-ef5d-45f1-a5ba-1ce62280ba92"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pmlb\n",
            "  Downloading pmlb-1.0.1.post3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from pmlb) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from pmlb) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from pmlb) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->pmlb) (1.16.0)\n",
            "Installing collected packages: pmlb\n",
            "Successfully installed pmlb-1.0.1.post3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sdv"
      ],
      "metadata": {
        "id": "COAFe5iG-02V",
        "outputId": "a901bd1c-3dc4-4256-c0d4-4970f8c3862e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sdv\n",
            "  Downloading sdv-1.11.0-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2,>=1.15.0 (from sdv)\n",
            "  Downloading boto3-1.34.81-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<2,>=1.18 (from sdv)\n",
            "  Downloading botocore-1.34.81-py3-none-any.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<3.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (2.2.1)\n",
            "Requirement already satisfied: graphviz<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from sdv) (0.20.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.15 in /usr/local/lib/python3.10/dist-packages (from sdv) (4.66.2)\n",
            "Collecting copulas<0.10,>=0.9.0 (from sdv)\n",
            "  Downloading copulas-0.9.2-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctgan<0.10,>=0.9.0 (from sdv)\n",
            "  Downloading ctgan-0.9.1-py3-none-any.whl (24 kB)\n",
            "Collecting deepecho<0.6,>=0.5 (from sdv)\n",
            "  Downloading deepecho-0.5.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting rdt<2,>=1.10.0 (from sdv)\n",
            "  Downloading rdt-1.10.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sdmetrics<0.14,>=0.13.0 (from sdv)\n",
            "  Downloading sdmetrics-0.13.1-py3-none-any.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.8/169.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1.23.3 in /usr/local/lib/python3.10/dist-packages (from sdv) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.3.4 in /usr/local/lib/python3.10/dist-packages (from sdv) (2.0.3)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.15.0->sdv)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.15.0->sdv)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<2,>=1.18->sdv) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<2,>=1.18->sdv) (2.0.7)\n",
            "Requirement already satisfied: matplotlib<4,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from copulas<0.10,>=0.9.0->sdv) (3.7.1)\n",
            "Requirement already satisfied: scipy<2,>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from copulas<0.10,>=0.9.0->sdv) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from ctgan<0.10,>=0.9.0->sdv) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from ctgan<0.10,>=0.9.0->sdv) (2.2.1+cu121)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.4->sdv) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.4->sdv) (2024.1)\n",
            "Collecting Faker<20,>=17 (from rdt<2,>=1.10.0->sdv)\n",
            "  Downloading Faker-19.13.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of sdmetrics to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sdmetrics<0.14,>=0.13.0 (from sdv)\n",
            "  Downloading sdmetrics-0.13.0-py2.py3-none-any.whl (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.7/170.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: plotly<6,>=5.10.0 in /usr/local/lib/python3.10/dist-packages (from sdmetrics<0.14,>=0.13.0->sdv) (5.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly<6,>=5.10.0->sdmetrics<0.14,>=0.13.0->sdv) (8.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<2,>=1.18->sdv) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.3->ctgan<0.10,>=0.9.0->sdv) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.3->ctgan<0.10,>=0.9.0->sdv) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, nvidia-cusparse-cu12, nvidia-cudnn-cu12, Faker, botocore, s3transfer, rdt, nvidia-cusolver-cu12, copulas, sdmetrics, boto3, deepecho, ctgan, sdv\n",
            "Successfully installed Faker-19.13.0 boto3-1.34.81 botocore-1.34.81 copulas-0.9.2 ctgan-0.9.1 deepecho-0.5.0 jmespath-1.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 rdt-1.10.1 s3transfer-0.10.1 sdmetrics-0.13.0 sdv-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install DataSynthesizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBcGtW-pIGJ4",
        "outputId": "54e4ce33-3e14-4412-820f-3c28e7ed8382"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting DataSynthesizer\n",
            "  Downloading DataSynthesizer-0.1.13-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (3.7.1)\n",
            "Requirement already satisfied: seaborn>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (0.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->DataSynthesizer) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->DataSynthesizer) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->DataSynthesizer) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (3.4.0)\n",
            "Installing collected packages: DataSynthesizer\n",
            "Successfully installed DataSynthesizer-0.1.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWPFD1ycAEY1",
        "outputId": "914efdf1-a6d6-46e3-8dc5-6e2b16c1df4e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "   creating: data/imbalance_defects_prediction/\n",
            "   creating: data/project_health/\n",
            "  inflating: data/README.md          \n",
            "   creating: data/JavaScript_Vulnerability/\n",
            "   creating: data/Bug_Reports/\n",
            "   creating: data/Vulnerable_Files/\n",
            "   creating: data/defects_prediction/\n",
            "   creating: data/imbalance_defects_prediction/7_CK_NET_PROC/\n",
            "   creating: data/imbalance_defects_prediction/2_NET/\n",
            "   creating: data/imbalance_defects_prediction/4_CK_NET/\n",
            "   creating: data/imbalance_defects_prediction/3_PROC/\n",
            "   creating: data/imbalance_defects_prediction/6_NET_PROC/\n",
            "   creating: data/imbalance_defects_prediction/1_CK/\n",
            "   creating: data/imbalance_defects_prediction/5_CK_PROC/\n",
            "   creating: data/project_health/monthly_closed_PRs_2mo/\n",
            "   creating: data/project_health/monthly_commits_2mo/\n",
            "   creating: data/project_health/monthly_open_PRs_2mo/\n",
            "   creating: data/project_health/monthly_closed_issues_2mo/\n",
            "   creating: data/project_health/monthly_commits_12mo/\n",
            "   creating: data/project_health/monthly_open_issues_2mo/\n",
            "   creating: data/project_health/monthly_closed_issues_12mo/\n",
            "   creating: data/project_health/monthly_contributors_2mo/\n",
            "   creating: data/project_health/monthly_closed_PRs_12mo/\n",
            "  inflating: data/JavaScript_Vulnerability/JSVulnerabilityDataSet-1.0.csv  \n",
            "  inflating: data/Bug_Reports/ambari-train.csv  \n",
            "  inflating: data/Bug_Reports/ambari-test.csv  \n",
            "  inflating: data/Vulnerable_Files/moodle-2_0_0-metrics.arff  \n",
            "  inflating: data/Vulnerable_Files/moodle-2_0_0-tokens.arff  \n",
            "  inflating: data/defects_prediction/Droppy.csv  \n",
            "  inflating: data/defects_prediction/android-transcoder.csv  \n",
            "  inflating: data/defects_prediction/android-flowlayout.csv  \n",
            "   creating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/\n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/data_sets.txt  \n",
            "   creating: data/imbalance_defects_prediction/2_NET/input/\n",
            "  inflating: data/imbalance_defects_prediction/2_NET/data_sets.txt  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/reImbPUB0.jar  \n",
            "   creating: data/imbalance_defects_prediction/4_CK_NET/input/\n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/data_sets.txt  \n",
            "   creating: data/imbalance_defects_prediction/3_PROC/input/\n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/data_sets.txt  \n",
            "   creating: data/imbalance_defects_prediction/6_NET_PROC/input/\n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/data_sets.txt  \n",
            "   creating: data/imbalance_defects_prediction/1_CK/input/\n",
            "  inflating: data/imbalance_defects_prediction/1_CK/data_sets.txt  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/reImbPUB0.jar  \n",
            "   creating: data/imbalance_defects_prediction/5_CK_PROC/input/\n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/data_sets.txt  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0003.csv  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/jedit-4.0--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/Lucene--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/synapse-1.2--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/jedit-4.1--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/synapse-1.1--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/jedit-4.2--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/Equinox_Framework--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/xerces-1.2--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/velocity-1.6--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/synapse-1.0--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/jedit-4.3--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/xerces-1.3--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/jedit-3.2--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/ant-1.4--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/poi-2.0--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/camel-1.2--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/ant-1.5--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/camel-1.6--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/Eclipse_PDE_UI--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/ant-1.6--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/ant-1.3--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/Eclipse_JDT_Core--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/camel-1.0--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/Mylyn--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/camel-1.4--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/log4j-1.0--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/ivy-2.0--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/jedit-4.0--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/camel-1.4--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/Eclipse_PDE_UI--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/ant-1.6--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/camel-1.2--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/Equinox_Framework--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/Eclipse_JDT_Core--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/jedit-4.1--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/synapse-1.2--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/Mylyn--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/Lucene--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/jedit-3.2--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/poi-2.0--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/synapse-1.1--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/jedit-4.2--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/camel-1.6--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/velocity-1.6--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/xerces-1.3--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/ivy-2.0--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/ant-1.4--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/camel-1.0--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/jedit-4.3--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/synapse-1.0--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/ant-1.3--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/xerces-1.2--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/ant-1.5--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/log4j-1.0--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/synapse-1.2--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/jedit-3.2--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/camel-1.2--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/ant-1.6--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/velocity-1.6--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/jedit-4.2--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/xerces-1.2--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/camel-1.4--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/Lucene--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/xerces-1.3--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/jedit-4.3--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/Mylyn--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/log4j-1.0--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/Eclipse_JDT_Core--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/Equinox_Framework--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/poi-2.0--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/Eclipse_PDE_UI--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/ant-1.5--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/camel-1.6--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/synapse-1.1--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/jedit-4.1--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/synapse-1.0--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/ant-1.3--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/ivy-2.0--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/ant-1.4--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/camel-1.0--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/jedit-4.0--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/xerces-1.2--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/poi-2.0--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/camel-1.4--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/log4j-1.0--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/jedit-4.2--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/jedit-3.2--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/ant-1.5--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/camel-1.6--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/jedit-4.0--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/synapse-1.1--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/camel-1.0--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/jedit-4.3--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/ant-1.4--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/synapse-1.2--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/xerces-1.3--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/ivy-2.0--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/camel-1.2--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/jedit-4.1--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/Eclipse_PDE_UI--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/velocity-1.6--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/Mylyn--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/ant-1.6--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/Equinox_Framework--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/synapse-1.0--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/Eclipse_JDT_Core--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/Lucene--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/ant-1.3--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/log4j-1.0--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/Eclipse_PDE_UI--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/synapse-1.1--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/Equinox_Framework--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/synapse-1.0--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/synapse-1.2--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/jedit-3.2--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/xerces-1.2--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/jedit-4.3--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/Eclipse_JDT_Core--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/Mylyn--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/camel-1.0--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/ant-1.6--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/ivy-2.0--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/camel-1.6--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/jedit-4.2--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/xerces-1.3--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/ant-1.3--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/jedit-4.0--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/camel-1.4--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/ant-1.4--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/poi-2.0--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/ant-1.5--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/velocity-1.6--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/camel-1.2--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/jedit-4.1--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/Lucene--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/synapse-1.0--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/synapse-1.1--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/ant-1.3--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/Equinox_Framework--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/log4j-1.0--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/velocity-1.6--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/jedit-3.2--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/camel-1.6--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/camel-1.0--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/jedit-4.2--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/jedit-4.3--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/Eclipse_JDT_Core--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/ivy-2.0--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/ant-1.5--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/ant-1.4--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/xerces-1.2--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/xerces-1.3--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/camel-1.4--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/synapse-1.2--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/ant-1.6--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/poi-2.0--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/Eclipse_PDE_UI--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/jedit-4.1--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/jedit-4.0--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/Mylyn--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/Lucene--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/camel-1.2--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/synapse-1.1--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/velocity-1.6--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/ant-1.6--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/Mylyn--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/ant-1.5--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/ivy-2.0--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/synapse-1.2--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/Lucene--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/Eclipse_JDT_Core--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/Equinox_Framework--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/xerces-1.2--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/jedit-4.2--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/jedit-4.1--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/camel-1.0--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/jedit-3.2--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/camel-1.4--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/jedit-4.0--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/log4j-1.0--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/xerces-1.3--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/camel-1.6--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/jedit-4.3--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/camel-1.2--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/ant-1.4--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/Eclipse_PDE_UI--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/poi-2.0--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/synapse-1.0--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/ant-1.3--CK_PROC.arff  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All imports here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pmlb import fetch_data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import time\n",
        "\n",
        "from scipy.io import arff\n",
        "from sdv.datasets.local import load_csvs\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sdv.single_table import GaussianCopulaSynthesizer\n",
        "from DataSynthesizer.DataDescriber import DataDescriber\n",
        "from DataSynthesizer.DataGenerator import DataGenerator\n",
        "from DataSynthesizer.lib.utils import display_bayesian_network\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix"
      ],
      "metadata": {
        "id": "Lza8MeLYchI2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "KH_s6WhMv_Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data_train(X_train):\n",
        "    # Count missing values before handling missing data\n",
        "    missing_before = np.isnan(X_train).sum()\n",
        "\n",
        "    # Handle missing data\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "\n",
        "    # Count missing values after handling missing data\n",
        "    missing_after = np.isnan(X_train).sum()\n",
        "\n",
        "    # Normalize numeric columns\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "    return X_train, scaler, imputer\n",
        "\n",
        "def preprocess_data_test(X_test, scaler, imputer):\n",
        "    # Count missing values before handling missing data\n",
        "    missing_before = np.isnan(X_test).sum()\n",
        "\n",
        "    # Handle missing data\n",
        "    X_test = imputer.transform(X_test)\n",
        "\n",
        "    # Count missing values after handling missing data\n",
        "    missing_after = np.isnan(X_test).sum()\n",
        "\n",
        "    # Normalize numeric columns\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_test"
      ],
      "metadata": {
        "id": "A9ept3j9vmUy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "3Rjlt8zr4vyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: Eclipse PDE"
      ],
      "metadata": {
        "id": "p22RSGg043d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project = \"Defect_Eclipse_PDE_UI\"\n",
        "fname = \"_\".join(project.split(\"_\")[1:])\n",
        "data_path = f\"data/imbalance_defects_prediction/7_CK_NET_PROC/input/{fname}--CK_NET_PROC.arff\"\n",
        "data = arff.loadarff(data_path)\n",
        "df = pd.DataFrame(data[0])\n",
        "df['isBug'] = df['isBug'].astype('str')\n",
        "d = {'YES': 1, 'NO': 0}  # Remove the byte string prefix 'b'\n",
        "df['isBug'] = df['isBug'].map(d).fillna(df['isBug'])\n",
        "print(df['isBug'])\n",
        "print(\"before drop duplicates\", df.shape[0])\n",
        "df = df.drop_duplicates()\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "print(\"after drop duplicates\", df.shape[0])\n",
        "\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "wyi4iWJFwIhU",
        "outputId": "46f01c31-6543-4061-b1fd-c48b9f0fe46f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       1\n",
            "1       0\n",
            "2       0\n",
            "3       1\n",
            "4       0\n",
            "       ..\n",
            "1492    0\n",
            "1493    0\n",
            "1494    0\n",
            "1495    0\n",
            "1496    0\n",
            "Name: isBug, Length: 1497, dtype: int64\n",
            "before drop duplicates 1497\n",
            "after drop duplicates 1497\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               wmc          dit          rfc          noc          cbo  \\\n",
              "count  1497.000000  1497.000000  1497.000000  1497.000000  1497.000000   \n",
              "mean     23.748831     2.280561    47.502338     0.595858    10.208417   \n",
              "std      31.414402     1.565026    63.113652     2.434228    14.831382   \n",
              "min       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
              "25%       6.000000     1.000000    11.000000     0.000000     3.000000   \n",
              "50%      13.000000     2.000000    25.000000     0.000000     7.000000   \n",
              "75%      28.000000     3.000000    57.000000     0.000000    13.000000   \n",
              "max     286.000000     9.000000   599.000000    46.000000   362.000000   \n",
              "\n",
              "              lcom          loc  revision_num   author_num  linesadd_sum  ...  \\\n",
              "count  1497.000000  1497.000000   1497.000000  1497.000000   1497.000000  ...   \n",
              "mean     82.175685    98.164329     13.512358     3.971276    211.704075  ...   \n",
              "std     210.815685   128.634872     18.884925     2.177879    384.246071  ...   \n",
              "min       0.000000     0.000000      0.000000     0.000000      0.000000  ...   \n",
              "25%       6.000000    24.000000      4.000000     2.000000     21.000000  ...   \n",
              "50%      21.000000    52.000000      8.000000     3.000000     78.000000  ...   \n",
              "75%      66.000000   116.000000     16.000000     6.000000    221.000000  ...   \n",
              "max    3321.000000  1326.000000    410.000000    10.000000   3644.000000  ...   \n",
              "\n",
              "         InFreeClo    OutValClo     InValClo  OutRecipClo   InRecipClo  \\\n",
              "count  1497.000000  1497.000000  1497.000000  1497.000000  1497.000000   \n",
              "mean      0.001132     0.257043     0.257043     0.054766     0.054766   \n",
              "std       0.000635     0.194478     0.293171     0.040618     0.067921   \n",
              "min       0.000668     0.000000     0.000000     0.000668     0.000668   \n",
              "25%       0.000669     0.016684     0.001337     0.007902     0.002004   \n",
              "50%       0.000678     0.436592     0.015344     0.062817     0.006151   \n",
              "75%       0.001361     0.438191     0.509428     0.088306     0.097933   \n",
              "max       0.003036     0.498919     0.780527     0.151869     0.443954   \n",
              "\n",
              "        OutdwReach    IndwReach  nOutdwReach   nIndwReach        isBug  \n",
              "count  1497.000000  1497.000000  1497.000000  1497.000000  1497.000000  \n",
              "mean     82.188384    82.188371     0.054902     0.054902     0.139613  \n",
              "std      60.948191   101.878414     0.040714     0.068055     0.346700  \n",
              "min       1.000000     1.000000     0.000668     0.000668     0.000000  \n",
              "25%      11.833334     3.000000     0.007905     0.002004     0.000000  \n",
              "50%      94.413429     9.219047     0.063068     0.006158     0.000000  \n",
              "75%     132.544647   147.026443     0.088540     0.098214     0.000000  \n",
              "max     227.633392   664.717651     0.152060     0.444033     1.000000  \n",
              "\n",
              "[8 rows x 82 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9417e6a1-07a1-40a3-9eca-b1557fb2c51e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wmc</th>\n",
              "      <th>dit</th>\n",
              "      <th>rfc</th>\n",
              "      <th>noc</th>\n",
              "      <th>cbo</th>\n",
              "      <th>lcom</th>\n",
              "      <th>loc</th>\n",
              "      <th>revision_num</th>\n",
              "      <th>author_num</th>\n",
              "      <th>linesadd_sum</th>\n",
              "      <th>...</th>\n",
              "      <th>InFreeClo</th>\n",
              "      <th>OutValClo</th>\n",
              "      <th>InValClo</th>\n",
              "      <th>OutRecipClo</th>\n",
              "      <th>InRecipClo</th>\n",
              "      <th>OutdwReach</th>\n",
              "      <th>IndwReach</th>\n",
              "      <th>nOutdwReach</th>\n",
              "      <th>nIndwReach</th>\n",
              "      <th>isBug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "      <td>1497.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>23.748831</td>\n",
              "      <td>2.280561</td>\n",
              "      <td>47.502338</td>\n",
              "      <td>0.595858</td>\n",
              "      <td>10.208417</td>\n",
              "      <td>82.175685</td>\n",
              "      <td>98.164329</td>\n",
              "      <td>13.512358</td>\n",
              "      <td>3.971276</td>\n",
              "      <td>211.704075</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001132</td>\n",
              "      <td>0.257043</td>\n",
              "      <td>0.257043</td>\n",
              "      <td>0.054766</td>\n",
              "      <td>0.054766</td>\n",
              "      <td>82.188384</td>\n",
              "      <td>82.188371</td>\n",
              "      <td>0.054902</td>\n",
              "      <td>0.054902</td>\n",
              "      <td>0.139613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>31.414402</td>\n",
              "      <td>1.565026</td>\n",
              "      <td>63.113652</td>\n",
              "      <td>2.434228</td>\n",
              "      <td>14.831382</td>\n",
              "      <td>210.815685</td>\n",
              "      <td>128.634872</td>\n",
              "      <td>18.884925</td>\n",
              "      <td>2.177879</td>\n",
              "      <td>384.246071</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000635</td>\n",
              "      <td>0.194478</td>\n",
              "      <td>0.293171</td>\n",
              "      <td>0.040618</td>\n",
              "      <td>0.067921</td>\n",
              "      <td>60.948191</td>\n",
              "      <td>101.878414</td>\n",
              "      <td>0.040714</td>\n",
              "      <td>0.068055</td>\n",
              "      <td>0.346700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000668</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000668</td>\n",
              "      <td>0.000668</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000668</td>\n",
              "      <td>0.000668</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000669</td>\n",
              "      <td>0.016684</td>\n",
              "      <td>0.001337</td>\n",
              "      <td>0.007902</td>\n",
              "      <td>0.002004</td>\n",
              "      <td>11.833334</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.007905</td>\n",
              "      <td>0.002004</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000678</td>\n",
              "      <td>0.436592</td>\n",
              "      <td>0.015344</td>\n",
              "      <td>0.062817</td>\n",
              "      <td>0.006151</td>\n",
              "      <td>94.413429</td>\n",
              "      <td>9.219047</td>\n",
              "      <td>0.063068</td>\n",
              "      <td>0.006158</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>221.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001361</td>\n",
              "      <td>0.438191</td>\n",
              "      <td>0.509428</td>\n",
              "      <td>0.088306</td>\n",
              "      <td>0.097933</td>\n",
              "      <td>132.544647</td>\n",
              "      <td>147.026443</td>\n",
              "      <td>0.088540</td>\n",
              "      <td>0.098214</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>286.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>599.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>362.000000</td>\n",
              "      <td>3321.000000</td>\n",
              "      <td>1326.000000</td>\n",
              "      <td>410.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3644.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003036</td>\n",
              "      <td>0.498919</td>\n",
              "      <td>0.780527</td>\n",
              "      <td>0.151869</td>\n",
              "      <td>0.443954</td>\n",
              "      <td>227.633392</td>\n",
              "      <td>664.717651</td>\n",
              "      <td>0.152060</td>\n",
              "      <td>0.444033</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 82 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9417e6a1-07a1-40a3-9eca-b1557fb2c51e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9417e6a1-07a1-40a3-9eca-b1557fb2c51e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9417e6a1-07a1-40a3-9eca-b1557fb2c51e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cdf91294-fc66-4026-8811-caa62d0fbfa9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cdf91294-fc66-4026-8811-caa62d0fbfa9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cdf91294-fc66-4026-8811-caa62d0fbfa9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and testing using ML models"
      ],
      "metadata": {
        "id": "gGu1Qxej4WAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic function to test synthetic data using LR, SVM, DT\n",
        "\n",
        "def evaluate_models(X_train, X_test, y_train, y_test, random_state=42):\n",
        "\n",
        "    # Initialize classifiers\n",
        "    classifiers = {\n",
        "        \"Logistic Regression\": LogisticRegression(random_state=random_state),\n",
        "        \"SVM\": SVC(random_state=random_state),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(random_state=random_state)\n",
        "    }\n",
        "\n",
        "    # Results dictionary to store evaluation metrics\n",
        "    results = {}\n",
        "\n",
        "    # Iterate over classifiers\n",
        "    for name, clf in classifiers.items():\n",
        "        # Fit classifier\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Predictions\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Evaluation metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        # AUC-ROC\n",
        "        if hasattr(clf, \"predict_proba\"):\n",
        "            y_prob = clf.predict_proba(X_test)[:,1]\n",
        "        else:\n",
        "            y_prob = clf.decision_function(X_test)\n",
        "        fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Store results\n",
        "        results[name] = {\n",
        "            \"Accuracy\": accuracy,\n",
        "            \"Precision\": precision,\n",
        "            \"Recall\": recall,\n",
        "            \"F1 Score\": f1,\n",
        "            \"ROC AUC\": roc_auc,\n",
        "            \"Confusion Matrix\": cm\n",
        "        }\n",
        "\n",
        "        # Plot AUC-ROC curve\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'{name} - AUC-ROC Curve')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.savefig(f'{name}_auc_roc_curve.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title(f'{name} - Confusion Matrix')\n",
        "        plt.savefig(f'{name}_confusion_matrix.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "SULk39gP2SUj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n"
      ],
      "metadata": {
        "id": "2aBR2GZH2bb_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate_models(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "adNKyUsSLi6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff4bf92-fb22-4e4a-e856-4f839254d36e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAAzoxMlLpjk",
        "outputId": "5c4bfc92-9bd4-4188-e147-41b9ed2ed3a3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.87, 'Precision': 0.5714285714285714, 'Recall': 0.1951219512195122, 'F1 Score': 0.29090909090909095, 'ROC AUC': 0.6914492890102647, 'Confusion Matrix': array([[253,   6],\n",
            "       [ 33,   8]])}, 'SVM': {'Accuracy': 0.8633333333333333, 'Precision': 0.0, 'Recall': 0.0, 'F1 Score': 0.0, 'ROC AUC': 0.6644693473961766, 'Confusion Matrix': array([[259,   0],\n",
            "       [ 41,   0]])}, 'Decision Tree': {'Accuracy': 0.8466666666666667, 'Precision': 0.43902439024390244, 'Recall': 0.43902439024390244, 'F1 Score': 0.43902439024390244, 'ROC AUC': 0.6751106507204068, 'Confusion Matrix': array([[236,  23],\n",
            "       [ 23,  18]])}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SDV - Oversampling"
      ],
      "metadata": {
        "id": "_NaC7Ymj90QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def do_sdv(X_train, y_train):\n",
        "  train_df = pd.concat([X_train, y_train], axis=1)\n",
        "  class_counts = y_train.value_counts()\n",
        "\n",
        "  # Find minority class label\n",
        "  minority_class_label = class_counts.idxmin()\n",
        "\n",
        "  # Filter rows with minority class label\n",
        "  minority_df = train_df[train_df.iloc[:, -1] == minority_class_label]\n",
        "\n",
        "  # Calculate counts of majority and minority classes\n",
        "  majority_count = class_counts.max()\n",
        "  minority_count = class_counts.min()\n",
        "\n",
        "  metadata_data = SingleTableMetadata()\n",
        "  metadata_data.detect_from_dataframe(minority_df)\n",
        "  # print(metadata_data)\n",
        "  # Generate synthetic data using GaussianCopulaSynthesizer\n",
        "  synthesizer_breast_data = GaussianCopulaSynthesizer(metadata_data)\n",
        "  synthesizer_breast_data.fit(minority_df)\n",
        "\n",
        "  # Print sample synthetic data\n",
        "  synthesizer_breast_data.reset_sampling()\n",
        "  sd1 = synthesizer_breast_data.sample(num_rows=majority_count-minority_count)\n",
        "  return sd1, train_df\n",
        "\n",
        "# Function to add synthetic data to the main DataFrame based on percentage\n",
        "def add_synthetic_data(main_df, synthetic_df, percentage, seed=42):\n",
        "    # Calculate number of rows to sample\n",
        "    num_rows = int(len(synthetic_df) * percentage)\n",
        "\n",
        "    # Sample the specified percentage of synthetic data\n",
        "    sampled_synthetic_data = synthetic_df.sample(n=num_rows, replace=False, random_state=seed)\n",
        "    # print(sampled_synthetic_data)\n",
        "\n",
        "    # Concatenate sampled synthetic data with main DataFrame\n",
        "    combined_df = pd.concat([main_df, sampled_synthetic_data], ignore_index=True)\n",
        "    # print(combined_df)\n",
        "    return combined_df"
      ],
      "metadata": {
        "id": "o9yiYbcN93gn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Over-Sampling"
      ],
      "metadata": {
        "id": "A3BmbGRgJ5Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def random_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = RandomOverSampler(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "bF2pvEGDJ704"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "TGGkRAzG15Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def smote_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = SMOTE(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "cF6biXPn125o"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM-SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "QutsbBwdMujq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def svm_smote_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = SVMSMOTE(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "XwF74E6XMzG4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intelligent Pruning"
      ],
      "metadata": {
        "id": "x7qohyP7L0DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_majority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    max_label = max(zip(counts, labels))[1]\n",
        "    indices_with_max_label = np.where(y == max_label)[0]\n",
        "    X_maj, y_maj = X[indices_with_max_label], y[indices_with_max_label]\n",
        "\n",
        "    # Exclude majority class samples\n",
        "    indices_without_max_label = np.where(y != max_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_max_label], y[indices_without_max_label]\n",
        "\n",
        "    return X_maj, y_maj, X_remaining, y_remaining, min(counts)\n",
        "\n",
        "def do_clustering(X, y, labels):\n",
        "  clustered_X = defaultdict(list)\n",
        "  clustered_y = defaultdict(list)\n",
        "\n",
        "  for i, label in enumerate(labels):\n",
        "      clustered_X[label].append(X[i])\n",
        "      clustered_y[label].append(y[i])\n",
        "\n",
        "  # Sort clustered_X and clustered_y in descending order based on the length of values in each dictionary\n",
        "  sorted_clustered_X = dict(sorted(clustered_X.items(), key=lambda x: -len(x[1])))\n",
        "  sorted_clustered_y = dict(sorted(clustered_y.items(), key=lambda x: -len(x[1])))\n",
        "\n",
        "  return sorted_clustered_X, sorted_clustered_y\n",
        "\n",
        "\n",
        "def intelligent_prune_data(pruning_samps, pruning_ratios, clustered_X, clustered_y, per_cluster_pruning_ratio=0.7, seed=42):\n",
        "  random.seed(seed)\n",
        "  pruning_ratios_X_maj, pruning_ratios_y_maj = defaultdict(list), defaultdict(list)\n",
        "  for pruning_samp, pruning_ratio in zip(pruning_samps, pruning_ratios):\n",
        "    samps = 0\n",
        "    # print(\"For Pruning samps: \", pruning_samp)\n",
        "    prune_samps = pruning_samp\n",
        "    # print(prune_samps)\n",
        "    clustered_X_new = defaultdict(list)\n",
        "    clustered_y_new = defaultdict(list)\n",
        "    # Iterate over the sorted dictionaries\n",
        "    for label, values_X in clustered_X.items():\n",
        "        # Calculate the number of samples to prune\n",
        "        num_samples_to_prune = int(prune_samps * per_cluster_pruning_ratio)\n",
        "        if(num_samples_to_prune > len(values_X)):\n",
        "          num_samples_to_prune = len(values_X)//2\n",
        "          prune_samps -= num_samples_to_prune\n",
        "        else:\n",
        "          prune_samps -= num_samples_to_prune\n",
        "\n",
        "        # Randomly choose samples to prune\n",
        "        indices_to_prune = random.sample(range(len(values_X)), num_samples_to_prune)\n",
        "\n",
        "        # Prune the samples from clustered_X and clustered_y\n",
        "        clustered_X_new[label] = [values_X[i] for i in range(len(values_X)) if i not in indices_to_prune]\n",
        "        clustered_y_new[label] = [clustered_y[label][i] for i in range(len(clustered_y[label])) if i not in indices_to_prune]\n",
        "\n",
        "    iter = 0\n",
        "    while(prune_samps > 0):\n",
        "        if(iter>=100):\n",
        "          break\n",
        "        for label, values_X in clustered_X_new.items():\n",
        "          if(prune_samps <=0 or len(values_X) <= 0):\n",
        "            break\n",
        "          # print(len(values_X))\n",
        "          index_to_prune = random.sample(range(len(values_X)), 1)\n",
        "          clustered_X_new[label] = [values_X[i] for i in range(len(values_X)) if i not in index_to_prune]\n",
        "          clustered_y_new[label] = [clustered_y_new[label][i] for i in range(len(clustered_y_new[label])) if i not in index_to_prune]\n",
        "\n",
        "          prune_samps -= 1\n",
        "        iter += 1\n",
        "\n",
        "    for label in clustered_X_new:\n",
        "        pruning_ratios_X_maj[pruning_ratio].extend(clustered_X_new[label])\n",
        "        pruning_ratios_y_maj[pruning_ratio].extend(clustered_y_new[label])\n",
        "\n",
        "  return pruning_ratios_X_maj, pruning_ratios_y_maj\n",
        "\n",
        "def combine_data(pruning_ratios, pruning_ratios_X_maj, pruning_ratios_y_maj, X_remaining, y_remaining):\n",
        "\n",
        "  pruning_ratios_X, pruning_ratios_y = defaultdict(list), defaultdict(list)\n",
        "  for pruning_ratio in pruning_ratios:\n",
        "    pruning_ratios_X[pruning_ratio].extend(pruning_ratios_X_maj[pruning_ratio])\n",
        "    pruning_ratios_X[pruning_ratio].extend(X_remaining)\n",
        "\n",
        "    pruning_ratios_y[pruning_ratio].extend(pruning_ratios_y_maj[pruning_ratio])\n",
        "    pruning_ratios_y[pruning_ratio].extend(y_remaining)\n",
        "\n",
        "  return pruning_ratios_X, pruning_ratios_y\n",
        "\n",
        "def do_intelligent_pruning(X, y, ratio, per_cluster_pruning_ratio=0.7, seed=42):\n",
        "\n",
        "  X_maj, y_maj, X_remaining, y_remaining, min_class_samples = find_majority_data(X, y)\n",
        "  kmeans = KMeans(n_clusters=3, random_state = 42)\n",
        "  kmeans.fit(X_maj)\n",
        "  labels = kmeans.labels_\n",
        "  clustered_X, clustered_y = do_clustering(X_maj, y_maj, labels)\n",
        "\n",
        "  pruning_best = len(X_maj)-min_class_samples\n",
        "  pruning_samps = [int(pruning_best * ratio)]\n",
        "  pruning_ratios = [ratio]\n",
        "\n",
        "  pruning_ratios_X_maj, pruning_ratios_y_maj = intelligent_prune_data(pruning_samps, pruning_ratios, clustered_X, clustered_y, \\\n",
        "                                                                      per_cluster_pruning_ratio=per_cluster_pruning_ratio, seed=seed)\n",
        "\n",
        "  pruning_ratios_X, pruning_ratios_y = combine_data(pruning_ratios, pruning_ratios_X_maj, pruning_ratios_y_maj, X_remaining, y_remaining)\n",
        "\n",
        "  return list(pruning_ratios_X.values()), list(pruning_ratios_y.values())"
      ],
      "metadata": {
        "id": "w9_Pj009Lxp9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Pruning"
      ],
      "metadata": {
        "id": "yky--qnU6rg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "inputs:\n",
        "X: np.array\n",
        "y: np.array\n",
        "percentage: from 0% upto 100%, enter int value\n",
        "\"\"\"\n",
        "def random_prune_data(X, y, ratio, seed = 42):\n",
        "  # preprocessed_X, scaler, imputer = preprocess_data_train(X)\n",
        "  # preprocessed_X_test = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "  # X_train, y_train = preprocessed_X_train.to_numpy(), y_train.to_numpy()\n",
        "  # X_test, y_test = preprocessed_X_test.to_numpy(), y_test.to_numpy()\n",
        "  np.random.seed(seed)\n",
        "  labels_count = {}\n",
        "  labels = np.unique(y)\n",
        "  for label in labels:\n",
        "    labels_count[label] = np.count_nonzero(y == label)\n",
        "  max_label = min_label = labels[0]\n",
        "  for label in labels_count:\n",
        "    if labels_count[label] > labels_count[max_label]:\n",
        "      max_label = label\n",
        "    if labels_count[label] < labels_count[min_label]:\n",
        "      min_label = label\n",
        "\n",
        "  # print(\"Max\", max_label, labels_count[max_label])\n",
        "  # print(\"Min\", min_label, labels_count[min_label])\n",
        "\n",
        "  prune_counts = {}\n",
        "  prune_indexes = {}\n",
        "  for label in labels_count:\n",
        "    prune_counts[label] = labels_count[label] - labels_count[min_label]\n",
        "    prune_indexes[label] = np.where(y == label)[0]\n",
        "\n",
        "  prune_amount = int(ratio * sum(map(lambda x: x[1], prune_counts.items())))\n",
        "  prune_it = {}\n",
        "\n",
        "  while prune_amount > 0:\n",
        "    for label in labels:\n",
        "      if (len(prune_indexes[label]) - labels_count[min_label]) > 0 and prune_amount > 0:\n",
        "        random_index = np.random.choice(len(prune_indexes[label]))\n",
        "        random_item = prune_indexes[label][random_index]\n",
        "        prune_indexes[label] = np.delete(prune_indexes[label], random_index)\n",
        "        if prune_it.get(label, None) is None:\n",
        "          prune_it[label] = np.array([])\n",
        "        prune_it[label] = np.append(prune_it[label], [random_item])\n",
        "        prune_amount -= 1\n",
        "\n",
        "\n",
        "\n",
        "  formatted_indexes = np.array([])\n",
        "  for label in prune_indexes:\n",
        "    formatted_indexes = np.append(formatted_indexes, prune_indexes[label])\n",
        "  formatted_indexes = np.sort(formatted_indexes)\n",
        "  new_arr = np.array([np.int64(i) for i in formatted_indexes])\n",
        "\n",
        "  return X[new_arr], y[new_arr]"
      ],
      "metadata": {
        "id": "BtB6jqhZtRD0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratios = [ratio for ratio in np.arange(0.2, 1.1, 0.2)]"
      ],
      "metadata": {
        "id": "z0A-h4iX3J8p"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Intelligent Pruning"
      ],
      "metadata": {
        "id": "UY6hAjLw9fy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_intelligent_pruning = dict()\n",
        "per_cluster_pruning_ratios = [0.5, 0.7, 0.9, 1]\n",
        "\n",
        "for per_cluster_pruning_ratio in per_cluster_pruning_ratios:\n",
        "  print(f'For per-cluster pruning ratio {per_cluster_pruning_ratio}')\n",
        "  for ratio in ratios:\n",
        "    X_train_copy, y_train_copy = X_train.copy(), y_train.copy()\n",
        "\n",
        "    intelligent_pruned_X_train, intelligent_pruned_y_train = do_intelligent_pruning(X_train_copy.to_numpy(), y_train_copy.to_numpy(), ratio, per_cluster_pruning_ratio=per_cluster_pruning_ratio)\n",
        "\n",
        "    preprocessed_intelligent_pruned_X_train, scaler, imputer = preprocess_data_train((np.array(intelligent_pruned_X_train))[0])\n",
        "    preprocessed_X_test = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    intelligent_pruned_X_train, intelligent_pruned_y_train = preprocessed_intelligent_pruned_X_train, (np.array(intelligent_pruned_y_train))[0]\n",
        "    intelligent_pruned_X_test, intelligent_pruned_y_test = preprocessed_X_test, y_test.to_numpy()\n",
        "    print(f\"Train data pruned intelligently at {ratio * 100}% :\")\n",
        "    results = evaluate_models(intelligent_pruned_X_train, intelligent_pruned_X_test, intelligent_pruned_y_train, intelligent_pruned_y_test)\n",
        "    print(results)\n",
        "    results_intelligent_pruning[ratio] = results\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRV_KrPy9is0",
        "outputId": "fb3dc142-217b-421d-a2af-e7e44ba2059b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For per-cluster pruning ratio 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 20.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8566666666666667, 'Precision': 0.4583333333333333, 'Recall': 0.2682926829268293, 'F1 Score': 0.3384615384615385, 'ROC AUC': 0.7673509746680477, 'Confusion Matrix': array([[246,  13],\n",
            "       [ 30,  11]])}, 'SVM': {'Accuracy': 0.8666666666666667, 'Precision': 0.5714285714285714, 'Recall': 0.0975609756097561, 'F1 Score': 0.16666666666666669, 'ROC AUC': 0.7903286561823146, 'Confusion Matrix': array([[256,   3],\n",
            "       [ 37,   4]])}, 'Decision Tree': {'Accuracy': 0.8033333333333333, 'Precision': 0.32, 'Recall': 0.3902439024390244, 'F1 Score': 0.35164835164835173, 'ROC AUC': 0.6294848855824465, 'Confusion Matrix': array([[225,  34],\n",
            "       [ 25,  16]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 40.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.85, 'Precision': 0.4444444444444444, 'Recall': 0.3902439024390244, 'F1 Score': 0.4155844155844156, 'ROC AUC': 0.7724832846784067, 'Confusion Matrix': array([[239,  20],\n",
            "       [ 25,  16]])}, 'SVM': {'Accuracy': 0.8766666666666667, 'Precision': 0.625, 'Recall': 0.24390243902439024, 'F1 Score': 0.3508771929824561, 'ROC AUC': 0.8107637253978718, 'Confusion Matrix': array([[253,   6],\n",
            "       [ 31,  10]])}, 'Decision Tree': {'Accuracy': 0.7566666666666667, 'Precision': 0.25757575757575757, 'Recall': 0.4146341463414634, 'F1 Score': 0.31775700934579443, 'ROC AUC': 0.612722478576137, 'Confusion Matrix': array([[210,  49],\n",
            "       [ 24,  17]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 60.00000000000001% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8033333333333333, 'Precision': 0.3269230769230769, 'Recall': 0.4146341463414634, 'F1 Score': 0.3655913978494624, 'ROC AUC': 0.7524719841793013, 'Confusion Matrix': array([[224,  35],\n",
            "       [ 24,  17]])}, 'SVM': {'Accuracy': 0.8366666666666667, 'Precision': 0.4, 'Recall': 0.3902439024390244, 'F1 Score': 0.39506172839506176, 'ROC AUC': 0.7787456445993031, 'Confusion Matrix': array([[235,  24],\n",
            "       [ 25,  16]])}, 'Decision Tree': {'Accuracy': 0.8066666666666666, 'Precision': 0.373134328358209, 'Recall': 0.6097560975609756, 'F1 Score': 0.4629629629629629, 'ROC AUC': 0.7237969676994067, 'Confusion Matrix': array([[217,  42],\n",
            "       [ 16,  25]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 80.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.7466666666666667, 'Precision': 0.2891566265060241, 'Recall': 0.5853658536585366, 'F1 Score': 0.3870967741935484, 'ROC AUC': 0.7443262077408418, 'Confusion Matrix': array([[200,  59],\n",
            "       [ 17,  24]])}, 'SVM': {'Accuracy': 0.79, 'Precision': 0.3382352941176471, 'Recall': 0.5609756097560976, 'F1 Score': 0.4220183486238533, 'ROC AUC': 0.7422544495715228, 'Confusion Matrix': array([[214,  45],\n",
            "       [ 18,  23]])}, 'Decision Tree': {'Accuracy': 0.67, 'Precision': 0.24561403508771928, 'Recall': 0.6829268292682927, 'F1 Score': 0.36129032258064514, 'ROC AUC': 0.6754402486109803, 'Confusion Matrix': array([[173,  86],\n",
            "       [ 13,  28]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 100.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.7, 'Precision': 0.25742574257425743, 'Recall': 0.6341463414634146, 'F1 Score': 0.36619718309859156, 'ROC AUC': 0.7300122422073643, 'Confusion Matrix': array([[184,  75],\n",
            "       [ 15,  26]])}, 'SVM': {'Accuracy': 0.7533333333333333, 'Precision': 0.30120481927710846, 'Recall': 0.6097560975609756, 'F1 Score': 0.40322580645161293, 'ROC AUC': 0.7143798851115924, 'Confusion Matrix': array([[201,  58],\n",
            "       [ 16,  25]])}, 'Decision Tree': {'Accuracy': 0.72, 'Precision': 0.2828282828282828, 'Recall': 0.6829268292682927, 'F1 Score': 0.4, 'ROC AUC': 0.7043977775685093, 'Confusion Matrix': array([[188,  71],\n",
            "       [ 13,  28]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 20.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8633333333333333, 'Precision': 0.5, 'Recall': 0.34146341463414637, 'F1 Score': 0.40579710144927533, 'ROC AUC': 0.7577455504284774, 'Confusion Matrix': array([[245,  14],\n",
            "       [ 27,  14]])}, 'SVM': {'Accuracy': 0.8666666666666667, 'Precision': 0.5714285714285714, 'Recall': 0.0975609756097561, 'F1 Score': 0.16666666666666669, 'ROC AUC': 0.7861851398436764, 'Confusion Matrix': array([[256,   3],\n",
            "       [ 37,   4]])}, 'Decision Tree': {'Accuracy': 0.78, 'Precision': 0.2549019607843137, 'Recall': 0.3170731707317073, 'F1 Score': 0.28260869565217384, 'ROC AUC': 0.5851775120067803, 'Confusion Matrix': array([[221,  38],\n",
            "       [ 28,  13]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 40.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.85, 'Precision': 0.4375, 'Recall': 0.34146341463414637, 'F1 Score': 0.3835616438356165, 'ROC AUC': 0.7678218287974385, 'Confusion Matrix': array([[241,  18],\n",
            "       [ 27,  14]])}, 'SVM': {'Accuracy': 0.8666666666666667, 'Precision': 0.5454545454545454, 'Recall': 0.14634146341463414, 'F1 Score': 0.23076923076923073, 'ROC AUC': 0.7951313683021, 'Confusion Matrix': array([[254,   5],\n",
            "       [ 35,   6]])}, 'Decision Tree': {'Accuracy': 0.81, 'Precision': 0.32608695652173914, 'Recall': 0.36585365853658536, 'F1 Score': 0.3448275862068966, 'ROC AUC': 0.6230812694227328, 'Confusion Matrix': array([[228,  31],\n",
            "       [ 26,  15]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 60.00000000000001% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8433333333333334, 'Precision': 0.425, 'Recall': 0.4146341463414634, 'F1 Score': 0.41975308641975306, 'ROC AUC': 0.7682455975138903, 'Confusion Matrix': array([[236,  23],\n",
            "       [ 24,  17]])}, 'SVM': {'Accuracy': 0.8733333333333333, 'Precision': 0.5882352941176471, 'Recall': 0.24390243902439024, 'F1 Score': 0.3448275862068965, 'ROC AUC': 0.8134005085224597, 'Confusion Matrix': array([[252,   7],\n",
            "       [ 31,  10]])}, 'Decision Tree': {'Accuracy': 0.79, 'Precision': 0.31666666666666665, 'Recall': 0.4634146341463415, 'F1 Score': 0.3762376237623763, 'ROC AUC': 0.6525567379225916, 'Confusion Matrix': array([[218,  41],\n",
            "       [ 22,  19]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 80.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8033333333333333, 'Precision': 0.3392857142857143, 'Recall': 0.4634146341463415, 'F1 Score': 0.3917525773195876, 'ROC AUC': 0.7799227799227799, 'Confusion Matrix': array([[222,  37],\n",
            "       [ 22,  19]])}, 'SVM': {'Accuracy': 0.8333333333333334, 'Precision': 0.3902439024390244, 'Recall': 0.3902439024390244, 'F1 Score': 0.3902439024390244, 'ROC AUC': 0.7781335342310953, 'Confusion Matrix': array([[234,  25],\n",
            "       [ 25,  16]])}, 'Decision Tree': {'Accuracy': 0.71, 'Precision': 0.23863636363636365, 'Recall': 0.5121951219512195, 'F1 Score': 0.32558139534883723, 'ROC AUC': 0.6267539316319805, 'Confusion Matrix': array([[192,  67],\n",
            "       [ 20,  21]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 100.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.67, 'Precision': 0.25, 'Recall': 0.7073170731707317, 'F1 Score': 0.36942675159235666, 'ROC AUC': 0.7583576607966852, 'Confusion Matrix': array([[172,  87],\n",
            "       [ 12,  29]])}, 'SVM': {'Accuracy': 0.7166666666666667, 'Precision': 0.28, 'Recall': 0.6829268292682927, 'F1 Score': 0.3971631205673759, 'ROC AUC': 0.7394293247951783, 'Confusion Matrix': array([[187,  72],\n",
            "       [ 13,  28]])}, 'Decision Tree': {'Accuracy': 0.6033333333333334, 'Precision': 0.21739130434782608, 'Recall': 0.7317073170731707, 'F1 Score': 0.335195530726257, 'ROC AUC': 0.6573594500423768, 'Confusion Matrix': array([[151, 108],\n",
            "       [ 11,  30]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 20.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8733333333333333, 'Precision': 0.5652173913043478, 'Recall': 0.3170731707317073, 'F1 Score': 0.40625, 'ROC AUC': 0.7580751483190508, 'Confusion Matrix': array([[249,  10],\n",
            "       [ 28,  13]])}, 'SVM': {'Accuracy': 0.87, 'Precision': 0.75, 'Recall': 0.07317073170731707, 'F1 Score': 0.13333333333333333, 'ROC AUC': 0.7794048403804501, 'Confusion Matrix': array([[258,   1],\n",
            "       [ 38,   3]])}, 'Decision Tree': {'Accuracy': 0.7766666666666666, 'Precision': 0.25925925925925924, 'Recall': 0.34146341463414637, 'F1 Score': 0.29473684210526313, 'ROC AUC': 0.593511630096996, 'Confusion Matrix': array([[219,  40],\n",
            "       [ 27,  14]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 40.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8666666666666667, 'Precision': 0.5185185185185185, 'Recall': 0.34146341463414637, 'F1 Score': 0.411764705882353, 'ROC AUC': 0.7554854506074019, 'Confusion Matrix': array([[246,  13],\n",
            "       [ 27,  14]])}, 'SVM': {'Accuracy': 0.8766666666666667, 'Precision': 0.8333333333333334, 'Recall': 0.12195121951219512, 'F1 Score': 0.21276595744680848, 'ROC AUC': 0.7883510688388737, 'Confusion Matrix': array([[258,   1],\n",
            "       [ 36,   5]])}, 'Decision Tree': {'Accuracy': 0.8066666666666666, 'Precision': 0.3111111111111111, 'Recall': 0.34146341463414637, 'F1 Score': 0.3255813953488372, 'ROC AUC': 0.6108861474715134, 'Confusion Matrix': array([[228,  31],\n",
            "       [ 27,  14]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 60.00000000000001% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8466666666666667, 'Precision': 0.42424242424242425, 'Recall': 0.34146341463414637, 'F1 Score': 0.37837837837837834, 'ROC AUC': 0.7697523307279405, 'Confusion Matrix': array([[240,  19],\n",
            "       [ 27,  14]])}, 'SVM': {'Accuracy': 0.87, 'Precision': 0.6, 'Recall': 0.14634146341463414, 'F1 Score': 0.23529411764705882, 'ROC AUC': 0.8034184009793766, 'Confusion Matrix': array([[255,   4],\n",
            "       [ 35,   6]])}, 'Decision Tree': {'Accuracy': 0.7366666666666667, 'Precision': 0.2361111111111111, 'Recall': 0.4146341463414634, 'F1 Score': 0.30088495575221236, 'ROC AUC': 0.6011394669931255, 'Confusion Matrix': array([[204,  55],\n",
            "       [ 24,  17]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 80.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.7933333333333333, 'Precision': 0.3333333333333333, 'Recall': 0.5121951219512195, 'F1 Score': 0.40384615384615385, 'ROC AUC': 0.7381109332328846, 'Confusion Matrix': array([[217,  42],\n",
            "       [ 20,  21]])}, 'SVM': {'Accuracy': 0.8633333333333333, 'Precision': 0.5, 'Recall': 0.2926829268292683, 'F1 Score': 0.3692307692307692, 'ROC AUC': 0.7676805725586214, 'Confusion Matrix': array([[247,  12],\n",
            "       [ 29,  12]])}, 'Decision Tree': {'Accuracy': 0.7433333333333333, 'Precision': 0.25, 'Recall': 0.43902439024390244, 'F1 Score': 0.31858407079646023, 'ROC AUC': 0.6152650908748469, 'Confusion Matrix': array([[205,  54],\n",
            "       [ 23,  18]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 100.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.49, 'Precision': 0.18181818181818182, 'Recall': 0.7804878048780488, 'F1 Score': 0.29493087557603687, 'ROC AUC': 0.700254261229871, 'Confusion Matrix': array([[115, 144],\n",
            "       [  9,  32]])}, 'SVM': {'Accuracy': 0.38, 'Precision': 0.1497584541062802, 'Recall': 0.7560975609756098, 'F1 Score': 0.25, 'ROC AUC': 0.6133345889443451, 'Confusion Matrix': array([[ 83, 176],\n",
            "       [ 10,  31]])}, 'Decision Tree': {'Accuracy': 0.46, 'Precision': 0.15819209039548024, 'Recall': 0.6829268292682927, 'F1 Score': 0.25688073394495414, 'ROC AUC': 0.5538186269893588, 'Confusion Matrix': array([[110, 149],\n",
            "       [ 13,  28]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 20.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8766666666666667, 'Precision': 0.5909090909090909, 'Recall': 0.3170731707317073, 'F1 Score': 0.41269841269841273, 'ROC AUC': 0.7546849985874376, 'Confusion Matrix': array([[250,   9],\n",
            "       [ 28,  13]])}, 'SVM': {'Accuracy': 0.87, 'Precision': 0.75, 'Recall': 0.07317073170731707, 'F1 Score': 0.13333333333333333, 'ROC AUC': 0.7804407194651096, 'Confusion Matrix': array([[258,   1],\n",
            "       [ 38,   3]])}, 'Decision Tree': {'Accuracy': 0.7933333333333333, 'Precision': 0.3090909090909091, 'Recall': 0.4146341463414634, 'F1 Score': 0.3541666666666667, 'ROC AUC': 0.6339579998116583, 'Confusion Matrix': array([[221,  38],\n",
            "       [ 24,  17]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 40.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8566666666666667, 'Precision': 0.4666666666666667, 'Recall': 0.34146341463414637, 'F1 Score': 0.3943661971830986, 'ROC AUC': 0.7550145964780112, 'Confusion Matrix': array([[243,  16],\n",
            "       [ 27,  14]])}, 'SVM': {'Accuracy': 0.8766666666666667, 'Precision': 0.8333333333333334, 'Recall': 0.12195121951219512, 'F1 Score': 0.21276595744680848, 'ROC AUC': 0.7912703644410961, 'Confusion Matrix': array([[258,   1],\n",
            "       [ 36,   5]])}, 'Decision Tree': {'Accuracy': 0.7833333333333333, 'Precision': 0.29310344827586204, 'Recall': 0.4146341463414634, 'F1 Score': 0.34343434343434337, 'ROC AUC': 0.6281664940201526, 'Confusion Matrix': array([[218,  41],\n",
            "       [ 24,  17]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 60.00000000000001% :\n",
            "{'Logistic Regression': {'Accuracy': 0.85, 'Precision': 0.4411764705882353, 'Recall': 0.36585365853658536, 'F1 Score': 0.4, 'ROC AUC': 0.7495056031641398, 'Confusion Matrix': array([[240,  19],\n",
            "       [ 26,  15]])}, 'SVM': {'Accuracy': 0.87, 'Precision': 0.6, 'Recall': 0.14634146341463414, 'F1 Score': 0.23529411764705882, 'ROC AUC': 0.7735191637630662, 'Confusion Matrix': array([[255,   4],\n",
            "       [ 35,   6]])}, 'Decision Tree': {'Accuracy': 0.72, 'Precision': 0.1791044776119403, 'Recall': 0.2926829268292683, 'F1 Score': 0.2222222222222222, 'ROC AUC': 0.5401638572370279, 'Confusion Matrix': array([[204,  55],\n",
            "       [ 29,  12]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 80.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.7433333333333333, 'Precision': 0.29069767441860467, 'Recall': 0.6097560975609756, 'F1 Score': 0.3937007874015748, 'ROC AUC': 0.7159807891515209, 'Confusion Matrix': array([[198,  61],\n",
            "       [ 16,  25]])}, 'SVM': {'Accuracy': 0.8033333333333333, 'Precision': 0.3125, 'Recall': 0.36585365853658536, 'F1 Score': 0.33707865168539325, 'ROC AUC': 0.7124964685940296, 'Confusion Matrix': array([[226,  33],\n",
            "       [ 26,  15]])}, 'Decision Tree': {'Accuracy': 0.64, 'Precision': 0.18691588785046728, 'Recall': 0.4878048780487805, 'F1 Score': 0.27027027027027023, 'ROC AUC': 0.5759487710707223, 'Confusion Matrix': array([[172,  87],\n",
            "       [ 21,  20]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 100.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.7833333333333333, 'Precision': 0.3333333333333333, 'Recall': 0.5853658536585366, 'F1 Score': 0.42477876106194684, 'ROC AUC': 0.7613711272247857, 'Confusion Matrix': array([[211,  48],\n",
            "       [ 17,  24]])}, 'SVM': {'Accuracy': 0.8, 'Precision': 0.3582089552238806, 'Recall': 0.5853658536585366, 'F1 Score': 0.4444444444444444, 'ROC AUC': 0.7506356530746775, 'Confusion Matrix': array([[216,  43],\n",
            "       [ 17,  24]])}, 'Decision Tree': {'Accuracy': 0.7733333333333333, 'Precision': 0.3246753246753247, 'Recall': 0.6097560975609756, 'F1 Score': 0.423728813559322, 'ROC AUC': 0.7044919483943873, 'Confusion Matrix': array([[207,  52],\n",
            "       [ 16,  25]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calling Random Pruning"
      ],
      "metadata": {
        "id": "uGrS3yXb-RYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_random_pruning = dict()\n",
        "for ratio in ratios:\n",
        "  random_pruned_X_train, random_pruned_y_train = random_prune_data(X_train.to_numpy(), y_train.to_numpy(), ratio)\n",
        "  preprocessed_random_pruned_X_train, scaler, imputer = preprocess_data_train(random_pruned_X_train)\n",
        "  preprocessed_X_test = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "  random_pruned_X_train, random_pruned_y_train = preprocessed_random_pruned_X_train, random_pruned_y_train\n",
        "  random_pruned_X_test, random_pruned_y_test = preprocessed_X_test, y_test.to_numpy()\n",
        "\n",
        "  print(f\"Train data pruned randomly at {ratio * 100}% :\")\n",
        "  results = evaluate_models(random_pruned_X_train, random_pruned_X_test, random_pruned_y_train, random_pruned_y_test)\n",
        "  print(results)\n",
        "  results_random_pruning[ratio] = results\n",
        "  print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "4od9tUcU-QI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4960f66f-fd79-4800-a4c2-6f503b12d743"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned randomly at 20.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8766666666666667, 'Precision': 0.5833333333333334, 'Recall': 0.34146341463414637, 'F1 Score': 0.43076923076923085, 'ROC AUC': 0.7719182597231379, 'Confusion Matrix': array([[249,  10],\n",
            "       [ 27,  14]])}, 'SVM': {'Accuracy': 0.8666666666666667, 'Precision': 0.6666666666666666, 'Recall': 0.04878048780487805, 'F1 Score': 0.0909090909090909, 'ROC AUC': 0.8062435257557209, 'Confusion Matrix': array([[258,   1],\n",
            "       [ 39,   2]])}, 'Decision Tree': {'Accuracy': 0.8066666666666666, 'Precision': 0.3111111111111111, 'Recall': 0.34146341463414637, 'F1 Score': 0.3255813953488372, 'ROC AUC': 0.6108861474715134, 'Confusion Matrix': array([[228,  31],\n",
            "       [ 27,  14]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 40.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8633333333333333, 'Precision': 0.5, 'Recall': 0.34146341463414637, 'F1 Score': 0.40579710144927533, 'ROC AUC': 0.7725774555042849, 'Confusion Matrix': array([[245,  14],\n",
            "       [ 27,  14]])}, 'SVM': {'Accuracy': 0.8733333333333333, 'Precision': 0.7142857142857143, 'Recall': 0.12195121951219512, 'F1 Score': 0.20833333333333334, 'ROC AUC': 0.8053018174969394, 'Confusion Matrix': array([[257,   2],\n",
            "       [ 36,   5]])}, 'Decision Tree': {'Accuracy': 0.7866666666666666, 'Precision': 0.2909090909090909, 'Recall': 0.3902439024390244, 'F1 Score': 0.3333333333333333, 'ROC AUC': 0.6198323759299368, 'Confusion Matrix': array([[220,  39],\n",
            "       [ 25,  16]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 60.00000000000001% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.85, 'Precision': 0.4444444444444444, 'Recall': 0.3902439024390244, 'F1 Score': 0.4155844155844156, 'ROC AUC': 0.76673886429984, 'Confusion Matrix': array([[239,  20],\n",
            "       [ 25,  16]])}, 'SVM': {'Accuracy': 0.8666666666666667, 'Precision': 0.5294117647058824, 'Recall': 0.21951219512195122, 'F1 Score': 0.3103448275862069, 'ROC AUC': 0.7999811658348244, 'Confusion Matrix': array([[251,   8],\n",
            "       [ 32,   9]])}, 'Decision Tree': {'Accuracy': 0.7366666666666667, 'Precision': 0.2625, 'Recall': 0.5121951219512195, 'F1 Score': 0.34710743801652894, 'ROC AUC': 0.6421979470759959, 'Confusion Matrix': array([[200,  59],\n",
            "       [ 20,  21]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 80.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8033333333333333, 'Precision': 0.35, 'Recall': 0.5121951219512195, 'F1 Score': 0.4158415841584158, 'ROC AUC': 0.7747433844994821, 'Confusion Matrix': array([[220,  39],\n",
            "       [ 20,  21]])}, 'SVM': {'Accuracy': 0.8566666666666667, 'Precision': 0.4772727272727273, 'Recall': 0.5121951219512195, 'F1 Score': 0.49411764705882355, 'ROC AUC': 0.8174027686222808, 'Confusion Matrix': array([[236,  23],\n",
            "       [ 20,  21]])}, 'Decision Tree': {'Accuracy': 0.7266666666666667, 'Precision': 0.26436781609195403, 'Recall': 0.5609756097560976, 'F1 Score': 0.359375, 'ROC AUC': 0.6569356813259253, 'Confusion Matrix': array([[195,  64],\n",
            "       [ 18,  23]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 100.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.6933333333333334, 'Precision': 0.2571428571428571, 'Recall': 0.6585365853658537, 'F1 Score': 0.3698630136986301, 'ROC AUC': 0.7779451925793388, 'Confusion Matrix': array([[181,  78],\n",
            "       [ 14,  27]])}, 'SVM': {'Accuracy': 0.7033333333333334, 'Precision': 0.2777777777777778, 'Recall': 0.7317073170731707, 'F1 Score': 0.40268456375838924, 'ROC AUC': 0.7900932291176194, 'Confusion Matrix': array([[181,  78],\n",
            "       [ 11,  30]])}, 'Decision Tree': {'Accuracy': 0.6266666666666667, 'Precision': 0.2248062015503876, 'Recall': 0.7073170731707317, 'F1 Score': 0.34117647058823536, 'ROC AUC': 0.6606083435351728, 'Confusion Matrix': array([[159, 100],\n",
            "       [ 12,  29]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SDV-Oversampling"
      ],
      "metadata": {
        "id": "f_VUTRHBBVDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sd1, train_df = do_sdv(X_train, y_train)\n",
        "results_syn_sdv = dict()\n",
        "\n",
        "# Add synthetic data at different percentages to the main DataFrame\n",
        "for ratio in ratios:\n",
        "    combined_df = add_synthetic_data(train_df, sd1, ratio)\n",
        "    y_train_sdv = combined_df.iloc[:, -1]\n",
        "    X_train_sdv = combined_df.iloc[:, :-1]\n",
        "\n",
        "    preprocessed_X_train_sdv, scaler, imputer = preprocess_data_train(X_train_sdv)\n",
        "    preprocessed_X_test_sdv = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_sdv, y_train_sdv = preprocessed_X_train_sdv, y_train_sdv.to_numpy()\n",
        "    X_test_sdv, y_test_sdv = preprocessed_X_test_sdv, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    results = evaluate_models(X_train_sdv, X_test_sdv, y_train_sdv, y_test_sdv)\n",
        "    results_syn_sdv[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "g4V6WxpY9kbd",
        "outputId": "9169e907-eed7-4433-e094-0ba45dcbd1cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sdv/single_table/base.py:80: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8666666666666667, 'Precision': 0.5217391304347826, 'Recall': 0.2926829268292683, 'F1 Score': 0.375, 'ROC AUC': 0.7310952067049628, 'Confusion Matrix': array([[248,  11],\n",
            "       [ 29,  12]])}, 'SVM': {'Accuracy': 0.8733333333333333, 'Precision': 0.7142857142857143, 'Recall': 0.12195121951219512, 'F1 Score': 0.20833333333333334, 'ROC AUC': 0.7441378660890856, 'Confusion Matrix': array([[257,   2],\n",
            "       [ 36,   5]])}, 'Decision Tree': {'Accuracy': 0.7933333333333333, 'Precision': 0.29411764705882354, 'Recall': 0.36585365853658536, 'F1 Score': 0.32608695652173914, 'ROC AUC': 0.6134287597702232, 'Confusion Matrix': array([[223,  36],\n",
            "       [ 26,  15]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.87, 'Precision': 0.5454545454545454, 'Recall': 0.2926829268292683, 'F1 Score': 0.3809523809523809, 'ROC AUC': 0.725350786326396, 'Confusion Matrix': array([[249,  10],\n",
            "       [ 29,  12]])}, 'SVM': {'Accuracy': 0.8733333333333333, 'Precision': 0.6666666666666666, 'Recall': 0.14634146341463414, 'F1 Score': 0.24, 'ROC AUC': 0.7296355589038516, 'Confusion Matrix': array([[256,   3],\n",
            "       [ 35,   6]])}, 'Decision Tree': {'Accuracy': 0.7933333333333333, 'Precision': 0.29411764705882354, 'Recall': 0.36585365853658536, 'F1 Score': 0.32608695652173914, 'ROC AUC': 0.6134287597702232, 'Confusion Matrix': array([[223,  36],\n",
            "       [ 26,  15]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8666666666666667, 'Precision': 0.5217391304347826, 'Recall': 0.2926829268292683, 'F1 Score': 0.375, 'ROC AUC': 0.7274225444957152, 'Confusion Matrix': array([[248,  11],\n",
            "       [ 29,  12]])}, 'SVM': {'Accuracy': 0.87, 'Precision': 0.6, 'Recall': 0.14634146341463414, 'F1 Score': 0.23529411764705882, 'ROC AUC': 0.7287880214709482, 'Confusion Matrix': array([[255,   4],\n",
            "       [ 35,   6]])}, 'Decision Tree': {'Accuracy': 0.7933333333333333, 'Precision': 0.29411764705882354, 'Recall': 0.36585365853658536, 'F1 Score': 0.32608695652173914, 'ROC AUC': 0.6134287597702232, 'Confusion Matrix': array([[223,  36],\n",
            "       [ 26,  15]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.87, 'Precision': 0.5454545454545454, 'Recall': 0.2926829268292683, 'F1 Score': 0.3809523809523809, 'ROC AUC': 0.724691590545249, 'Confusion Matrix': array([[249,  10],\n",
            "       [ 29,  12]])}, 'SVM': {'Accuracy': 0.87, 'Precision': 0.6, 'Recall': 0.14634146341463414, 'F1 Score': 0.23529411764705882, 'ROC AUC': 0.7269046049533854, 'Confusion Matrix': array([[255,   4],\n",
            "       [ 35,   6]])}, 'Decision Tree': {'Accuracy': 0.79, 'Precision': 0.28846153846153844, 'Recall': 0.36585365853658536, 'F1 Score': 0.3225806451612903, 'ROC AUC': 0.6114982578397212, 'Confusion Matrix': array([[222,  37],\n",
            "       [ 26,  15]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8666666666666667, 'Precision': 0.5217391304347826, 'Recall': 0.2926829268292683, 'F1 Score': 0.375, 'ROC AUC': 0.7199359638384029, 'Confusion Matrix': array([[248,  11],\n",
            "       [ 29,  12]])}, 'SVM': {'Accuracy': 0.87, 'Precision': 0.6, 'Recall': 0.14634146341463414, 'F1 Score': 0.23529411764705882, 'ROC AUC': 0.7260570675204822, 'Confusion Matrix': array([[255,   4],\n",
            "       [ 35,   6]])}, 'Decision Tree': {'Accuracy': 0.7933333333333333, 'Precision': 0.29411764705882354, 'Recall': 0.36585365853658536, 'F1 Score': 0.32608695652173914, 'ROC AUC': 0.6134287597702232, 'Confusion Matrix': array([[223,  36],\n",
            "       [ 26,  15]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SMOTE-Oversampling"
      ],
      "metadata": {
        "id": "l78jR_BuCw1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_smote = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_smote, y_train_smote = smote_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "    preprocessed_X_train_smote, scaler, imputer = preprocess_data_train((np.array(X_train_smote))[0])\n",
        "    preprocessed_X_test_smote = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_smote, y_train_smote = preprocessed_X_train_smote, (np.array(y_train_smote))[0]\n",
        "    X_test_smote, y_test_smote = preprocessed_X_test_smote, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_smote), len(y_train_smote))\n",
        "    results = evaluate_models(X_train_smote, X_test_smote, y_train_smote, y_test_smote)\n",
        "    results_smote[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "X7S78dnHC0bw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d373188-8573-444b-d328-0a131a0e27d4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "1369 1369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8466666666666667, 'Precision': 0.42857142857142855, 'Recall': 0.36585365853658536, 'F1 Score': 0.39473684210526316, 'ROC AUC': 0.7496468594029569, 'Confusion Matrix': array([[239,  20],\n",
            "       [ 26,  15]])}, 'SVM': {'Accuracy': 0.8666666666666667, 'Precision': 0.5294117647058824, 'Recall': 0.21951219512195122, 'F1 Score': 0.3103448275862069, 'ROC AUC': 0.7928712684810245, 'Confusion Matrix': array([[251,   8],\n",
            "       [ 32,   9]])}, 'Decision Tree': {'Accuracy': 0.7933333333333333, 'Precision': 0.2558139534883721, 'Recall': 0.2682926829268293, 'F1 Score': 0.2619047619047619, 'ROC AUC': 0.5723702796873529, 'Confusion Matrix': array([[227,  32],\n",
            "       [ 30,  11]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "1541 1541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8166666666666667, 'Precision': 0.36, 'Recall': 0.43902439024390244, 'F1 Score': 0.3956043956043956, 'ROC AUC': 0.7506827384876166, 'Confusion Matrix': array([[227,  32],\n",
            "       [ 23,  18]])}, 'SVM': {'Accuracy': 0.8433333333333334, 'Precision': 0.4, 'Recall': 0.2926829268292683, 'F1 Score': 0.3380281690140845, 'ROC AUC': 0.7847725774555043, 'Confusion Matrix': array([[241,  18],\n",
            "       [ 29,  12]])}, 'Decision Tree': {'Accuracy': 0.7333333333333333, 'Precision': 0.2, 'Recall': 0.3170731707317073, 'F1 Score': 0.24528301886792453, 'ROC AUC': 0.5581504849797533, 'Confusion Matrix': array([[207,  52],\n",
            "       [ 28,  13]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "1713 1713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.79, 'Precision': 0.31666666666666665, 'Recall': 0.4634146341463415, 'F1 Score': 0.3762376237623763, 'ROC AUC': 0.756238817214427, 'Confusion Matrix': array([[218,  41],\n",
            "       [ 22,  19]])}, 'SVM': {'Accuracy': 0.83, 'Precision': 0.391304347826087, 'Recall': 0.43902439024390244, 'F1 Score': 0.4137931034482759, 'ROC AUC': 0.7752142386288727, 'Confusion Matrix': array([[231,  28],\n",
            "       [ 23,  18]])}, 'Decision Tree': {'Accuracy': 0.8066666666666666, 'Precision': 0.3508771929824561, 'Recall': 0.4878048780487805, 'F1 Score': 0.4081632653061224, 'ROC AUC': 0.672473867595819, 'Confusion Matrix': array([[222,  37],\n",
            "       [ 21,  20]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "1885 1885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7566666666666667, 'Precision': 0.2894736842105263, 'Recall': 0.5365853658536586, 'F1 Score': 0.37606837606837606, 'ROC AUC': 0.750965250965251, 'Confusion Matrix': array([[205,  54],\n",
            "       [ 19,  22]])}, 'SVM': {'Accuracy': 0.82, 'Precision': 0.38596491228070173, 'Recall': 0.5365853658536586, 'F1 Score': 0.4489795918367347, 'ROC AUC': 0.7738487616536398, 'Confusion Matrix': array([[224,  35],\n",
            "       [ 19,  22]])}, 'Decision Tree': {'Accuracy': 0.7966666666666666, 'Precision': 0.3148148148148148, 'Recall': 0.4146341463414634, 'F1 Score': 0.35789473684210527, 'ROC AUC': 0.6358885017421603, 'Confusion Matrix': array([[222,  37],\n",
            "       [ 24,  17]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "2058 2058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7433333333333333, 'Precision': 0.2804878048780488, 'Recall': 0.5609756097560976, 'F1 Score': 0.3739837398373984, 'ROC AUC': 0.7440436952632076, 'Confusion Matrix': array([[200,  59],\n",
            "       [ 18,  23]])}, 'SVM': {'Accuracy': 0.8, 'Precision': 0.3492063492063492, 'Recall': 0.5365853658536586, 'F1 Score': 0.4230769230769231, 'ROC AUC': 0.7628778604388361, 'Confusion Matrix': array([[218,  41],\n",
            "       [ 19,  22]])}, 'Decision Tree': {'Accuracy': 0.7633333333333333, 'Precision': 0.2222222222222222, 'Recall': 0.2926829268292683, 'F1 Score': 0.25263157894736843, 'ROC AUC': 0.565260382333553, 'Confusion Matrix': array([[217,  42],\n",
            "       [ 29,  12]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Random-Oversampling"
      ],
      "metadata": {
        "id": "KKwGBPjpKrJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_random = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_random, y_train_random = random_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "\n",
        "    preprocessed_X_train_random, scaler, imputer = preprocess_data_train((np.array(X_train_random)[0]))\n",
        "    preprocessed_X_test_random = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_random, y_train_random = preprocessed_X_train_random, (np.array(y_train_random))[0]\n",
        "    X_test_random, y_test_random = preprocessed_X_test_random, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_random), len(y_train_random))\n",
        "    results = evaluate_models(X_train_random, X_test_random, y_train_random, y_test_random)\n",
        "    results_random[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "LC2kVR1tKtFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5e5f3f-d843-48b3-f174-d07e8afe82be"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "1369 1369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8533333333333334, 'Precision': 0.45714285714285713, 'Recall': 0.3902439024390244, 'F1 Score': 0.42105263157894735, 'ROC AUC': 0.7561917318014879, 'Confusion Matrix': array([[240,  19],\n",
            "       [ 25,  16]])}, 'SVM': {'Accuracy': 0.8733333333333333, 'Precision': 0.6363636363636364, 'Recall': 0.17073170731707318, 'F1 Score': 0.2692307692307692, 'ROC AUC': 0.8068085507109898, 'Confusion Matrix': array([[255,   4],\n",
            "       [ 34,   7]])}, 'Decision Tree': {'Accuracy': 0.8033333333333333, 'Precision': 0.32, 'Recall': 0.3902439024390244, 'F1 Score': 0.35164835164835173, 'ROC AUC': 0.6294848855824465, 'Confusion Matrix': array([[225,  34],\n",
            "       [ 25,  16]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "1541 1541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8333333333333334, 'Precision': 0.3953488372093023, 'Recall': 0.4146341463414634, 'F1 Score': 0.40476190476190477, 'ROC AUC': 0.7737075054148226, 'Confusion Matrix': array([[233,  26],\n",
            "       [ 24,  17]])}, 'SVM': {'Accuracy': 0.85, 'Precision': 0.42857142857142855, 'Recall': 0.2926829268292683, 'F1 Score': 0.34782608695652173, 'ROC AUC': 0.8200866371598079, 'Confusion Matrix': array([[243,  16],\n",
            "       [ 29,  12]])}, 'Decision Tree': {'Accuracy': 0.8233333333333334, 'Precision': 0.35, 'Recall': 0.34146341463414637, 'F1 Score': 0.34567901234567905, 'ROC AUC': 0.6205386571240229, 'Confusion Matrix': array([[233,  26],\n",
            "       [ 27,  14]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "1713 1713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7933333333333333, 'Precision': 0.32786885245901637, 'Recall': 0.4878048780487805, 'F1 Score': 0.39215686274509803, 'ROC AUC': 0.7676334871456822, 'Confusion Matrix': array([[218,  41],\n",
            "       [ 21,  20]])}, 'SVM': {'Accuracy': 0.84, 'Precision': 0.4186046511627907, 'Recall': 0.43902439024390244, 'F1 Score': 0.4285714285714286, 'ROC AUC': 0.816225633298804, 'Confusion Matrix': array([[234,  25],\n",
            "       [ 23,  18]])}, 'Decision Tree': {'Accuracy': 0.83, 'Precision': 0.3333333333333333, 'Recall': 0.24390243902439024, 'F1 Score': 0.28169014084507044, 'ROC AUC': 0.5833411809021565, 'Confusion Matrix': array([[239,  20],\n",
            "       [ 31,  10]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "1885 1885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7566666666666667, 'Precision': 0.3, 'Recall': 0.5853658536585366, 'F1 Score': 0.39669421487603307, 'ROC AUC': 0.7600056502495527, 'Confusion Matrix': array([[203,  56],\n",
            "       [ 17,  24]])}, 'SVM': {'Accuracy': 0.8133333333333334, 'Precision': 0.3728813559322034, 'Recall': 0.5365853658536586, 'F1 Score': 0.44, 'ROC AUC': 0.8034654863923155, 'Confusion Matrix': array([[222,  37],\n",
            "       [ 19,  22]])}, 'Decision Tree': {'Accuracy': 0.82, 'Precision': 0.30303030303030304, 'Recall': 0.24390243902439024, 'F1 Score': 0.2702702702702703, 'ROC AUC': 0.5775496751106507, 'Confusion Matrix': array([[236,  23],\n",
            "       [ 31,  10]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "2058 2058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7266666666666667, 'Precision': 0.27472527472527475, 'Recall': 0.6097560975609756, 'F1 Score': 0.3787878787878788, 'ROC AUC': 0.7630191166776533, 'Confusion Matrix': array([[193,  66],\n",
            "       [ 16,  25]])}, 'SVM': {'Accuracy': 0.8, 'Precision': 0.37333333333333335, 'Recall': 0.6829268292682927, 'F1 Score': 0.4827586206896552, 'ROC AUC': 0.8079856860344666, 'Confusion Matrix': array([[212,  47],\n",
            "       [ 13,  28]])}, 'Decision Tree': {'Accuracy': 0.8, 'Precision': 0.24324324324324326, 'Recall': 0.21951219512195122, 'F1 Score': 0.23076923076923075, 'ROC AUC': 0.5557020435069215, 'Confusion Matrix': array([[231,  28],\n",
            "       [ 32,   9]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SVM-SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "28Pi8n0HM4vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_svm_smote = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_svm_smote, y_train_svm_smote = svm_smote_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "\n",
        "    preprocessed_X_train_svm_smote, scaler, imputer = preprocess_data_train((np.array(X_train_svm_smote))[0])\n",
        "    preprocessed_X_test_svm_smote = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_svm_smote, y_train_svm_smote = preprocessed_X_train_svm_smote, (np.array(y_train_svm_smote))[0]\n",
        "    X_test_svm_smote, y_test_svm_smote = preprocessed_X_test_svm_smote, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_svm_smote), len(y_train_svm_smote))\n",
        "    results = evaluate_models(X_train_svm_smote, X_test_svm_smote, y_train_svm_smote, y_test_svm_smote)\n",
        "    results_svm_smote[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "8vkEOubrM81F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162cc8c2-c464-47fc-aae2-4edf322304d0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "1369 1369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8533333333333334, 'Precision': 0.45161290322580644, 'Recall': 0.34146341463414637, 'F1 Score': 0.3888888888888889, 'ROC AUC': 0.7759676052358979, 'Confusion Matrix': array([[242,  17],\n",
            "       [ 27,  14]])}, 'SVM': {'Accuracy': 0.8733333333333333, 'Precision': 0.6363636363636364, 'Recall': 0.17073170731707318, 'F1 Score': 0.2692307692307692, 'ROC AUC': 0.776014690648837, 'Confusion Matrix': array([[255,   4],\n",
            "       [ 34,   7]])}, 'Decision Tree': {'Accuracy': 0.78, 'Precision': 0.2807017543859649, 'Recall': 0.3902439024390244, 'F1 Score': 0.326530612244898, 'ROC AUC': 0.615971372068933, 'Confusion Matrix': array([[218,  41],\n",
            "       [ 25,  16]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "1541 1541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8333333333333334, 'Precision': 0.3902439024390244, 'Recall': 0.3902439024390244, 'F1 Score': 0.3902439024390244, 'ROC AUC': 0.7569921838214522, 'Confusion Matrix': array([[234,  25],\n",
            "       [ 25,  16]])}, 'SVM': {'Accuracy': 0.8633333333333333, 'Precision': 0.5, 'Recall': 0.2682926829268293, 'F1 Score': 0.34920634920634924, 'ROC AUC': 0.7706469535737829, 'Confusion Matrix': array([[248,  11],\n",
            "       [ 30,  11]])}, 'Decision Tree': {'Accuracy': 0.8, 'Precision': 0.30612244897959184, 'Recall': 0.36585365853658536, 'F1 Score': 0.3333333333333333, 'ROC AUC': 0.617289763631227, 'Confusion Matrix': array([[225,  34],\n",
            "       [ 26,  15]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "1713 1713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8233333333333334, 'Precision': 0.375, 'Recall': 0.43902439024390244, 'F1 Score': 0.40449438202247195, 'ROC AUC': 0.7593464544684057, 'Confusion Matrix': array([[229,  30],\n",
            "       [ 23,  18]])}, 'SVM': {'Accuracy': 0.8566666666666667, 'Precision': 0.46875, 'Recall': 0.36585365853658536, 'F1 Score': 0.410958904109589, 'ROC AUC': 0.7731895658724928, 'Confusion Matrix': array([[242,  17],\n",
            "       [ 26,  15]])}, 'Decision Tree': {'Accuracy': 0.8166666666666667, 'Precision': 0.34782608695652173, 'Recall': 0.3902439024390244, 'F1 Score': 0.36781609195402304, 'ROC AUC': 0.6372068933044542, 'Confusion Matrix': array([[229,  30],\n",
            "       [ 25,  16]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "1885 1885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.34, 'Recall': 0.4146341463414634, 'F1 Score': 0.3736263736263737, 'ROC AUC': 0.7561917318014878, 'Confusion Matrix': array([[226,  33],\n",
            "       [ 24,  17]])}, 'SVM': {'Accuracy': 0.84, 'Precision': 0.41025641025641024, 'Recall': 0.3902439024390244, 'F1 Score': 0.4, 'ROC AUC': 0.7738487616536397, 'Confusion Matrix': array([[236,  23],\n",
            "       [ 25,  16]])}, 'Decision Tree': {'Accuracy': 0.82, 'Precision': 0.3617021276595745, 'Recall': 0.4146341463414634, 'F1 Score': 0.38636363636363635, 'ROC AUC': 0.6494020152556738, 'Confusion Matrix': array([[229,  30],\n",
            "       [ 24,  17]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "2058 2058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8, 'Precision': 0.3333333333333333, 'Recall': 0.4634146341463415, 'F1 Score': 0.38775510204081637, 'ROC AUC': 0.7581222337319898, 'Confusion Matrix': array([[221,  38],\n",
            "       [ 22,  19]])}, 'SVM': {'Accuracy': 0.8366666666666667, 'Precision': 0.4090909090909091, 'Recall': 0.43902439024390244, 'F1 Score': 0.42352941176470593, 'ROC AUC': 0.7710707222902344, 'Confusion Matrix': array([[233,  26],\n",
            "       [ 23,  18]])}, 'Decision Tree': {'Accuracy': 0.7966666666666666, 'Precision': 0.3, 'Recall': 0.36585365853658536, 'F1 Score': 0.3296703296703297, 'ROC AUC': 0.6153592617007252, 'Confusion Matrix': array([[224,  35],\n",
            "       [ 26,  15]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No-Sampling Results"
      ],
      "metadata": {
        "id": "v7igNZJnja1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_no_sampling = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_no_sampling, y_train_no_sampling = X_train.to_numpy(), y_train.to_numpy()\n",
        "\n",
        "    preprocessed_X_train_no_sampling, scaler, imputer = preprocess_data_train(X_train_no_sampling)\n",
        "    preprocessed_X_test_no_sampling = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_no_sampling, y_train_no_sampling = preprocessed_X_train_no_sampling, y_train_no_sampling\n",
        "    X_test_no_sampling, y_test_no_sampling = preprocessed_X_test_no_sampling, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_no_sampling), len(y_train_no_sampling))\n",
        "    results = evaluate_models(X_train_no_sampling, X_test_no_sampling, y_train_no_sampling, y_test_no_sampling)\n",
        "    results_no_sampling[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "pkbztvKijXEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "079acf72-c979-4c94-d47b-f80aec7bb1ae"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "1197 1197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8833333333333333, 'Precision': 0.6666666666666666, 'Recall': 0.2926829268292683, 'F1 Score': 0.4067796610169492, 'ROC AUC': 0.7583576607966852, 'Confusion Matrix': array([[253,   6],\n",
            "       [ 29,  12]])}, 'SVM': {'Accuracy': 0.8633333333333333, 'Precision': 0.5, 'Recall': 0.024390243902439025, 'F1 Score': 0.046511627906976744, 'ROC AUC': 0.7842075525002354, 'Confusion Matrix': array([[258,   1],\n",
            "       [ 40,   1]])}, 'Decision Tree': {'Accuracy': 0.8166666666666667, 'Precision': 0.325, 'Recall': 0.3170731707317073, 'F1 Score': 0.3209876543209877, 'ROC AUC': 0.6064130332423016, 'Confusion Matrix': array([[232,  27],\n",
            "       [ 28,  13]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "1197 1197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8833333333333333, 'Precision': 0.6666666666666666, 'Recall': 0.2926829268292683, 'F1 Score': 0.4067796610169492, 'ROC AUC': 0.7583576607966852, 'Confusion Matrix': array([[253,   6],\n",
            "       [ 29,  12]])}, 'SVM': {'Accuracy': 0.8633333333333333, 'Precision': 0.5, 'Recall': 0.024390243902439025, 'F1 Score': 0.046511627906976744, 'ROC AUC': 0.7842075525002354, 'Confusion Matrix': array([[258,   1],\n",
            "       [ 40,   1]])}, 'Decision Tree': {'Accuracy': 0.8166666666666667, 'Precision': 0.325, 'Recall': 0.3170731707317073, 'F1 Score': 0.3209876543209877, 'ROC AUC': 0.6064130332423016, 'Confusion Matrix': array([[232,  27],\n",
            "       [ 28,  13]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "1197 1197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8833333333333333, 'Precision': 0.6666666666666666, 'Recall': 0.2926829268292683, 'F1 Score': 0.4067796610169492, 'ROC AUC': 0.7583576607966852, 'Confusion Matrix': array([[253,   6],\n",
            "       [ 29,  12]])}, 'SVM': {'Accuracy': 0.8633333333333333, 'Precision': 0.5, 'Recall': 0.024390243902439025, 'F1 Score': 0.046511627906976744, 'ROC AUC': 0.7842075525002354, 'Confusion Matrix': array([[258,   1],\n",
            "       [ 40,   1]])}, 'Decision Tree': {'Accuracy': 0.8166666666666667, 'Precision': 0.325, 'Recall': 0.3170731707317073, 'F1 Score': 0.3209876543209877, 'ROC AUC': 0.6064130332423016, 'Confusion Matrix': array([[232,  27],\n",
            "       [ 28,  13]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "1197 1197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8833333333333333, 'Precision': 0.6666666666666666, 'Recall': 0.2926829268292683, 'F1 Score': 0.4067796610169492, 'ROC AUC': 0.7583576607966852, 'Confusion Matrix': array([[253,   6],\n",
            "       [ 29,  12]])}, 'SVM': {'Accuracy': 0.8633333333333333, 'Precision': 0.5, 'Recall': 0.024390243902439025, 'F1 Score': 0.046511627906976744, 'ROC AUC': 0.7842075525002354, 'Confusion Matrix': array([[258,   1],\n",
            "       [ 40,   1]])}, 'Decision Tree': {'Accuracy': 0.8166666666666667, 'Precision': 0.325, 'Recall': 0.3170731707317073, 'F1 Score': 0.3209876543209877, 'ROC AUC': 0.6064130332423016, 'Confusion Matrix': array([[232,  27],\n",
            "       [ 28,  13]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "1197 1197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8833333333333333, 'Precision': 0.6666666666666666, 'Recall': 0.2926829268292683, 'F1 Score': 0.4067796610169492, 'ROC AUC': 0.7583576607966852, 'Confusion Matrix': array([[253,   6],\n",
            "       [ 29,  12]])}, 'SVM': {'Accuracy': 0.8633333333333333, 'Precision': 0.5, 'Recall': 0.024390243902439025, 'F1 Score': 0.046511627906976744, 'ROC AUC': 0.7842075525002354, 'Confusion Matrix': array([[258,   1],\n",
            "       [ 40,   1]])}, 'Decision Tree': {'Accuracy': 0.8166666666666667, 'Precision': 0.325, 'Recall': 0.3170731707317073, 'F1 Score': 0.3209876543209877, 'ROC AUC': 0.6064130332423016, 'Confusion Matrix': array([[232,  27],\n",
            "       [ 28,  13]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}
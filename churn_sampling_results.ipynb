{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adipai/statistical-data-pruning-analysis/blob/main/churn_sampling_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pmlb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAJ8lflEvuaA",
        "outputId": "474ab598-9387-4676-d86c-a5c1d2fe2702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pmlb in /usr/local/lib/python3.10/dist-packages (1.0.1.post3)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from pmlb) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from pmlb) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from pmlb) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->pmlb) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sdv"
      ],
      "metadata": {
        "id": "COAFe5iG-02V",
        "outputId": "bd6ab764-a968-4e1f-9e11-8aaeeee373d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sdv in /usr/local/lib/python3.10/dist-packages (1.11.0)\n",
            "Requirement already satisfied: boto3<2,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (1.34.79)\n",
            "Requirement already satisfied: botocore<2,>=1.18 in /usr/local/lib/python3.10/dist-packages (from sdv) (1.34.79)\n",
            "Requirement already satisfied: cloudpickle<3.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (2.2.1)\n",
            "Requirement already satisfied: graphviz<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from sdv) (0.20.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.15 in /usr/local/lib/python3.10/dist-packages (from sdv) (4.66.2)\n",
            "Requirement already satisfied: copulas<0.10,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (0.9.2)\n",
            "Requirement already satisfied: ctgan<0.10,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (0.9.1)\n",
            "Requirement already satisfied: deepecho<0.6,>=0.5 in /usr/local/lib/python3.10/dist-packages (from sdv) (0.5.0)\n",
            "Requirement already satisfied: rdt<2,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (1.10.1)\n",
            "Requirement already satisfied: sdmetrics<0.14,>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (0.13.0)\n",
            "Requirement already satisfied: numpy<2,>=1.23.3 in /usr/local/lib/python3.10/dist-packages (from sdv) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.3.4 in /usr/local/lib/python3.10/dist-packages (from sdv) (2.0.3)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.15.0->sdv) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.15.0->sdv) (0.10.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<2,>=1.18->sdv) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<2,>=1.18->sdv) (2.0.7)\n",
            "Requirement already satisfied: matplotlib<4,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from copulas<0.10,>=0.9.0->sdv) (3.7.1)\n",
            "Requirement already satisfied: scipy<2,>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from copulas<0.10,>=0.9.0->sdv) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from ctgan<0.10,>=0.9.0->sdv) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from ctgan<0.10,>=0.9.0->sdv) (2.2.1+cu121)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.4->sdv) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.4->sdv) (2024.1)\n",
            "Requirement already satisfied: Faker<20,>=17 in /usr/local/lib/python3.10/dist-packages (from rdt<2,>=1.10.0->sdv) (19.13.0)\n",
            "Requirement already satisfied: plotly<6,>=5.10.0 in /usr/local/lib/python3.10/dist-packages (from sdmetrics<0.14,>=0.13.0->sdv) (5.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly<6,>=5.10.0->sdmetrics<0.14,>=0.13.0->sdv) (8.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<2,>=1.18->sdv) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.3->ctgan<0.10,>=0.9.0->sdv) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.3->ctgan<0.10,>=0.9.0->sdv) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install DataSynthesizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBcGtW-pIGJ4",
        "outputId": "3d33d7fb-e373-4ec7-9b89-09873424100e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: DataSynthesizer in /usr/local/lib/python3.10/dist-packages (0.1.13)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (3.7.1)\n",
            "Requirement already satisfied: seaborn>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (0.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->DataSynthesizer) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->DataSynthesizer) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->DataSynthesizer) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (3.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All imports here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pmlb import fetch_data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import time\n",
        "\n",
        "from sdv.datasets.local import load_csvs\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sdv.single_table import GaussianCopulaSynthesizer\n",
        "from DataSynthesizer.DataDescriber import DataDescriber\n",
        "from DataSynthesizer.DataGenerator import DataGenerator\n",
        "from DataSynthesizer.lib.utils import display_bayesian_network\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix"
      ],
      "metadata": {
        "id": "Lza8MeLYchI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "KH_s6WhMv_Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data_train(X_train):\n",
        "    # Count missing values before handling missing data\n",
        "    missing_before = np.isnan(X_train).sum()\n",
        "\n",
        "    # Handle missing data\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "\n",
        "    # Count missing values after handling missing data\n",
        "    missing_after = np.isnan(X_train).sum()\n",
        "\n",
        "    # Normalize numeric columns\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "    return X_train, scaler, imputer\n",
        "\n",
        "def preprocess_data_test(X_test, scaler, imputer):\n",
        "    # Count missing values before handling missing data\n",
        "    missing_before = np.isnan(X_test).sum()\n",
        "\n",
        "    # Handle missing data\n",
        "    X_test = imputer.transform(X_test)\n",
        "\n",
        "    # Count missing values after handling missing data\n",
        "    missing_after = np.isnan(X_test).sum()\n",
        "\n",
        "    # Normalize numeric columns\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_test"
      ],
      "metadata": {
        "id": "A9ept3j9vmUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "3Rjlt8zr4vyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset 1: Breast cancer"
      ],
      "metadata": {
        "id": "p22RSGg043d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer = fetch_data('breast_cancer')\n",
        "breast_cancer.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "wyi4iWJFwIhU",
        "outputId": "0c5e7f52-fa1b-400e-dcb6-b3b092a9f675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              age   menopause  tumor-size   inv-nodes   node-caps   deg-malig  \\\n",
              "count  286.000000  286.000000  286.000000  286.000000  286.000000  286.000000   \n",
              "mean     2.664336    1.073427    4.062937    1.073427    1.167832    2.048951   \n",
              "std      1.011818    0.986680    2.151187    1.935321    0.443052    0.738217   \n",
              "min      0.000000    0.000000    0.000000    0.000000    0.000000    1.000000   \n",
              "25%      2.000000    0.000000    3.000000    0.000000    1.000000    2.000000   \n",
              "50%      3.000000    2.000000    4.000000    0.000000    1.000000    2.000000   \n",
              "75%      3.000000    2.000000    5.000000    1.000000    1.000000    3.000000   \n",
              "max      5.000000    2.000000   10.000000    6.000000    2.000000    3.000000   \n",
              "\n",
              "           breast  breast-quad    irradiat      target  \n",
              "count  286.000000   286.000000  286.000000  286.000000  \n",
              "mean     0.468531     2.772727    0.237762    0.297203  \n",
              "std      0.499883     1.099006    0.426459    0.457828  \n",
              "min      0.000000     0.000000    0.000000    0.000000  \n",
              "25%      0.000000     2.000000    0.000000    0.000000  \n",
              "50%      0.000000     3.000000    0.000000    0.000000  \n",
              "75%      1.000000     3.000000    0.000000    1.000000  \n",
              "max      1.000000     5.000000    1.000000    1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a96e0d7-ba89-4218-b385-1f18c8328904\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>menopause</th>\n",
              "      <th>tumor-size</th>\n",
              "      <th>inv-nodes</th>\n",
              "      <th>node-caps</th>\n",
              "      <th>deg-malig</th>\n",
              "      <th>breast</th>\n",
              "      <th>breast-quad</th>\n",
              "      <th>irradiat</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>286.000000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>286.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.664336</td>\n",
              "      <td>1.073427</td>\n",
              "      <td>4.062937</td>\n",
              "      <td>1.073427</td>\n",
              "      <td>1.167832</td>\n",
              "      <td>2.048951</td>\n",
              "      <td>0.468531</td>\n",
              "      <td>2.772727</td>\n",
              "      <td>0.237762</td>\n",
              "      <td>0.297203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.011818</td>\n",
              "      <td>0.986680</td>\n",
              "      <td>2.151187</td>\n",
              "      <td>1.935321</td>\n",
              "      <td>0.443052</td>\n",
              "      <td>0.738217</td>\n",
              "      <td>0.499883</td>\n",
              "      <td>1.099006</td>\n",
              "      <td>0.426459</td>\n",
              "      <td>0.457828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a96e0d7-ba89-4218-b385-1f18c8328904')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0a96e0d7-ba89-4218-b385-1f18c8328904 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0a96e0d7-ba89-4218-b385-1f18c8328904');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-858e6568-8472-49cd-8165-8cf3cf983a87\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-858e6568-8472-49cd-8165-8cf3cf983a87')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-858e6568-8472-49cd-8165-8cf3cf983a87 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"breast_cancer\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100.28496233251452,\n        \"min\": 0.0,\n        \"max\": 286.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          286.0,\n          2.664335664335664,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"menopause\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100.7126091644541,\n        \"min\": 0.0,\n        \"max\": 286.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0734265734265733,\n          2.0,\n          0.9866797805400002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tumor-size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 99.73237088720457,\n        \"min\": 0.0,\n        \"max\": 286.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4.062937062937063,\n          4.0,\n          286.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inv-nodes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100.63033509698059,\n        \"min\": 0.0,\n        \"max\": 286.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          286.0,\n          1.0734265734265733,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"node-caps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100.78401159120105,\n        \"min\": 0.0,\n        \"max\": 286.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          286.0,\n          1.167832167832168,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"deg-malig\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100.42317598564789,\n        \"min\": 0.7382166403717156,\n        \"max\": 286.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          286.0,\n          2.0489510489510487,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"breast\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100.96719856582193,\n        \"min\": 0.0,\n        \"max\": 286.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.46853146853146854,\n          1.0,\n          0.49988343629635285\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"breast-quad\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100.2749683562094,\n        \"min\": 0.0,\n        \"max\": 286.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          286.0,\n          2.772727272727273,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"irradiat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 101.03280964797415,\n        \"min\": 0.0,\n        \"max\": 286.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.23776223776223776,\n          1.0,\n          0.4264589728818777\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100.97797813848246,\n        \"min\": 0.0,\n        \"max\": 286.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2972027972027972,\n          1.0,\n          0.45782767859795653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and testing using ML models"
      ],
      "metadata": {
        "id": "gGu1Qxej4WAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic function to test synthetic data using LR, SVM, DT\n",
        "\n",
        "def evaluate_models(X_train, X_test, y_train, y_test):\n",
        "\n",
        "    # Initialize classifiers\n",
        "    classifiers = {\n",
        "        \"Logistic Regression\": LogisticRegression(),\n",
        "        \"SVM\": SVC(),\n",
        "        \"Decision Tree\": DecisionTreeClassifier()\n",
        "    }\n",
        "\n",
        "    # Results dictionary to store evaluation metrics\n",
        "    results = {}\n",
        "\n",
        "    # Iterate over classifiers\n",
        "    for name, clf in classifiers.items():\n",
        "        # Fit classifier\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Predictions\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Evaluation metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        # AUC-ROC\n",
        "        if hasattr(clf, \"predict_proba\"):\n",
        "            y_prob = clf.predict_proba(X_test)[:,1]\n",
        "        else:\n",
        "            y_prob = clf.decision_function(X_test)\n",
        "        fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Store results\n",
        "        results[name] = {\n",
        "            \"Accuracy\": accuracy,\n",
        "            \"Precision\": precision,\n",
        "            \"Recall\": recall,\n",
        "            \"F1 Score\": f1,\n",
        "            \"ROC AUC\": roc_auc,\n",
        "            \"Confusion Matrix\": cm\n",
        "        }\n",
        "\n",
        "        # Plot AUC-ROC curve\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'{name} - AUC-ROC Curve')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.savefig(f'{name}_auc_roc_curve.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title(f'{name} - Confusion Matrix')\n",
        "        plt.savefig(f'{name}_confusion_matrix.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "SULk39gP2SUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y = breast_cancer['target']\n",
        "X = breast_cancer.drop('target', axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n"
      ],
      "metadata": {
        "id": "2aBR2GZH2bb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate_models(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "adNKyUsSLi6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAAzoxMlLpjk",
        "outputId": "f532bbbc-aff1-4312-89b7-83fb5cb51004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7931034482758621, 'Precision': 0.8, 'Recall': 0.4444444444444444, 'F1 Score': 0.5714285714285714, 'ROC AUC': 0.726388888888889, 'Confusion Matrix': array([[38,  2],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7241379310344828, 'Precision': 0.75, 'Recall': 0.16666666666666666, 'F1 Score': 0.27272727272727276, 'ROC AUC': 0.6847222222222222, 'Confusion Matrix': array([[39,  1],\n",
            "       [15,  3]])}, 'Decision Tree': {'Accuracy': 0.6379310344827587, 'Precision': 0.43478260869565216, 'Recall': 0.5555555555555556, 'F1 Score': 0.4878048780487805, 'ROC AUC': 0.6340277777777779, 'Confusion Matrix': array([[27, 13],\n",
            "       [ 8, 10]])}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SDV - Oversampling"
      ],
      "metadata": {
        "id": "_NaC7Ymj90QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def do_sdv(X_train, y_train):\n",
        "  train_df = pd.concat([X_train, y_train], axis=1)\n",
        "  class_counts = y_train.value_counts()\n",
        "\n",
        "  # Find minority class label\n",
        "  minority_class_label = class_counts.idxmin()\n",
        "\n",
        "  # Filter rows with minority class label\n",
        "  minority_df = train_df[train_df.iloc[:, -1] == minority_class_label]\n",
        "\n",
        "  # Calculate counts of majority and minority classes\n",
        "  majority_count = class_counts.max()\n",
        "  minority_count = class_counts.min()\n",
        "\n",
        "  metadata_data = SingleTableMetadata()\n",
        "  metadata_data.detect_from_dataframe(minority_df)\n",
        "  # Generate synthetic data using GaussianCopulaSynthesizer\n",
        "  synthesizer_breast_data = GaussianCopulaSynthesizer(metadata_data)\n",
        "  synthesizer_breast_data.fit(minority_df)\n",
        "\n",
        "  # Print sample synthetic data\n",
        "  synthesizer_breast_data.reset_sampling()\n",
        "  sd1 = synthesizer_breast_data.sample(num_rows=majority_count-minority_count)\n",
        "  return sd1, train_df\n",
        "\n",
        "# Function to add synthetic data to the main DataFrame based on percentage\n",
        "def add_synthetic_data(main_df, synthetic_df, percentage, seed=42):\n",
        "    # Calculate number of rows to sample\n",
        "    num_rows = int(len(synthetic_df) * percentage)\n",
        "\n",
        "    # Sample the specified percentage of synthetic data\n",
        "    sampled_synthetic_data = synthetic_df.sample(n=num_rows, replace=False, random_state=seed)\n",
        "    # print(sampled_synthetic_data)\n",
        "\n",
        "    # Concatenate sampled synthetic data with main DataFrame\n",
        "    combined_df = pd.concat([main_df, sampled_synthetic_data], ignore_index=True)\n",
        "    # print(combined_df)\n",
        "    return combined_df"
      ],
      "metadata": {
        "id": "o9yiYbcN93gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Over-Sampling"
      ],
      "metadata": {
        "id": "A3BmbGRgJ5Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def random_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = RandomOverSampler(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "bF2pvEGDJ704"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "TGGkRAzG15Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def smote_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = SMOTE(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "cF6biXPn125o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM-SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "QutsbBwdMujq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def svm_smote_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = SVMSMOTE(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "XwF74E6XMzG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intelligent Pruning"
      ],
      "metadata": {
        "id": "x7qohyP7L0DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_majority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    max_label = max(zip(counts, labels))[1]\n",
        "    indices_with_max_label = np.where(y == max_label)[0]\n",
        "    X_maj, y_maj = X[indices_with_max_label], y[indices_with_max_label]\n",
        "\n",
        "    # Exclude majority class samples\n",
        "    indices_without_max_label = np.where(y != max_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_max_label], y[indices_without_max_label]\n",
        "\n",
        "    return X_maj, y_maj, X_remaining, y_remaining, min(counts)\n",
        "\n",
        "def do_clustering(X, y, labels):\n",
        "  clustered_X = defaultdict(list)\n",
        "  clustered_y = defaultdict(list)\n",
        "\n",
        "  for i, label in enumerate(labels):\n",
        "      clustered_X[label].append(X[i])\n",
        "      clustered_y[label].append(y[i])\n",
        "\n",
        "  # Sort clustered_X and clustered_y in descending order based on the length of values in each dictionary\n",
        "  sorted_clustered_X = dict(sorted(clustered_X.items(), key=lambda x: -len(x[1])))\n",
        "  sorted_clustered_y = dict(sorted(clustered_y.items(), key=lambda x: -len(x[1])))\n",
        "\n",
        "  return sorted_clustered_X, sorted_clustered_y\n",
        "\n",
        "\n",
        "def intelligent_prune_data(pruning_samps, pruning_ratios, clustered_X, clustered_y, per_cluster_pruning_ratio=0.7, seed=42):\n",
        "  random.seed(seed)\n",
        "  pruning_ratios_X_maj, pruning_ratios_y_maj = defaultdict(list), defaultdict(list)\n",
        "  for pruning_samp, pruning_ratio in zip(pruning_samps, pruning_ratios):\n",
        "    samps = 0\n",
        "    # print(\"For Pruning samps: \", pruning_samp)\n",
        "    prune_samps = pruning_samp\n",
        "    clustered_X_new = defaultdict(list)\n",
        "    clustered_y_new = defaultdict(list)\n",
        "    # Iterate over the sorted dictionaries\n",
        "    for label, values_X in clustered_X.items():\n",
        "        # Calculate the number of samples to prune\n",
        "        num_samples_to_prune = int(prune_samps * per_cluster_pruning_ratio)\n",
        "        if(num_samples_to_prune > len(values_X)):\n",
        "          num_samples_to_prune = len(values_X)//2\n",
        "          prune_samps -= num_samples_to_prune\n",
        "        else:\n",
        "          prune_samps -= num_samples_to_prune\n",
        "\n",
        "        # Randomly choose samples to prune\n",
        "        indices_to_prune = random.sample(range(len(values_X)), num_samples_to_prune)\n",
        "\n",
        "        # Prune the samples from clustered_X and clustered_y\n",
        "        clustered_X_new[label] = [values_X[i] for i in range(len(values_X)) if i not in indices_to_prune]\n",
        "        clustered_y_new[label] = [clustered_y[label][i] for i in range(len(clustered_y[label])) if i not in indices_to_prune]\n",
        "\n",
        "    while(prune_samps > 0):\n",
        "        for label, values_X in clustered_X_new.items():\n",
        "          if(prune_samps <=0):\n",
        "            break\n",
        "\n",
        "          index_to_prune = random.sample(range(len(values_X)), 1)\n",
        "          clustered_X_new[label] = [values_X[i] for i in range(len(values_X)) if i not in index_to_prune]\n",
        "          clustered_y_new[label] = [clustered_y_new[label][i] for i in range(len(clustered_y_new[label])) if i not in index_to_prune]\n",
        "\n",
        "          prune_samps -= 1\n",
        "\n",
        "    for label in clustered_X_new:\n",
        "        pruning_ratios_X_maj[pruning_ratio].extend(clustered_X_new[label])\n",
        "        pruning_ratios_y_maj[pruning_ratio].extend(clustered_y_new[label])\n",
        "\n",
        "  return pruning_ratios_X_maj, pruning_ratios_y_maj\n",
        "\n",
        "def combine_data(pruning_ratios, pruning_ratios_X_maj, pruning_ratios_y_maj, X_remaining, y_remaining):\n",
        "\n",
        "  pruning_ratios_X, pruning_ratios_y = defaultdict(list), defaultdict(list)\n",
        "  for pruning_ratio in pruning_ratios:\n",
        "    pruning_ratios_X[pruning_ratio].extend(pruning_ratios_X_maj[pruning_ratio])\n",
        "    pruning_ratios_X[pruning_ratio].extend(X_remaining)\n",
        "\n",
        "    pruning_ratios_y[pruning_ratio].extend(pruning_ratios_y_maj[pruning_ratio])\n",
        "    pruning_ratios_y[pruning_ratio].extend(y_remaining)\n",
        "\n",
        "  return pruning_ratios_X, pruning_ratios_y\n",
        "\n",
        "def do_intelligent_pruning(X, y, ratio, per_cluster_pruning_ratio=0.7, seed=42):\n",
        "\n",
        "  X_maj, y_maj, X_remaining, y_remaining, min_class_samples = find_majority_data(X, y)\n",
        "  kmeans = KMeans(n_clusters=3, random_state = 42)\n",
        "  kmeans.fit(X_maj)\n",
        "  labels = kmeans.labels_\n",
        "  clustered_X, clustered_y = do_clustering(X_maj, y_maj, labels)\n",
        "\n",
        "  pruning_best = len(X_maj)-min_class_samples\n",
        "  pruning_samps = [int(pruning_best * ratio)]\n",
        "  pruning_ratios = [ratio]\n",
        "\n",
        "  pruning_ratios_X_maj, pruning_ratios_y_maj = intelligent_prune_data(pruning_samps, pruning_ratios, clustered_X, clustered_y, \\\n",
        "                                                                      per_cluster_pruning_ratio=per_cluster_pruning_ratio, seed=seed)\n",
        "\n",
        "  pruning_ratios_X, pruning_ratios_y = combine_data(pruning_ratios, pruning_ratios_X_maj, pruning_ratios_y_maj, X_remaining, y_remaining)\n",
        "\n",
        "  return list(pruning_ratios_X.values()), list(pruning_ratios_y.values())\n"
      ],
      "metadata": {
        "id": "w9_Pj009Lxp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Pruning"
      ],
      "metadata": {
        "id": "yky--qnU6rg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "inputs:\n",
        "X: np.array\n",
        "y: np.array\n",
        "percentage: from 0% upto 100%, enter int value\n",
        "\"\"\"\n",
        "def random_prune_data(X, y, ratio, seed = 42):\n",
        "  # preprocessed_X, scaler, imputer = preprocess_data_train(X)\n",
        "  # preprocessed_X_test = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "  # X_train, y_train = preprocessed_X_train.to_numpy(), y_train.to_numpy()\n",
        "  # X_test, y_test = preprocessed_X_test.to_numpy(), y_test.to_numpy()\n",
        "  np.random.seed(seed)\n",
        "  labels_count = {}\n",
        "  labels = np.unique(y)\n",
        "  for label in labels:\n",
        "    labels_count[label] = np.count_nonzero(y == label)\n",
        "  max_label = min_label = labels[0]\n",
        "  for label in labels_count:\n",
        "    if labels_count[label] > labels_count[max_label]:\n",
        "      max_label = label\n",
        "    if labels_count[label] < labels_count[min_label]:\n",
        "      min_label = label\n",
        "\n",
        "  # print(\"Max\", max_label, labels_count[max_label])\n",
        "  # print(\"Min\", min_label, labels_count[min_label])\n",
        "\n",
        "  prune_counts = {}\n",
        "  prune_indexes = {}\n",
        "  for label in labels_count:\n",
        "    prune_counts[label] = labels_count[label] - labels_count[min_label]\n",
        "    prune_indexes[label] = np.where(y == label)[0]\n",
        "\n",
        "  prune_amount = int(ratio * sum(map(lambda x: x[1], prune_counts.items())))\n",
        "  prune_it = {}\n",
        "\n",
        "  while prune_amount > 0:\n",
        "    for label in labels:\n",
        "      if (len(prune_indexes[label]) - labels_count[min_label]) > 0 and prune_amount > 0:\n",
        "        random_index = np.random.choice(len(prune_indexes[label]))\n",
        "        random_item = prune_indexes[label][random_index]\n",
        "        prune_indexes[label] = np.delete(prune_indexes[label], random_index)\n",
        "        if prune_it.get(label, None) is None:\n",
        "          prune_it[label] = np.array([])\n",
        "        prune_it[label] = np.append(prune_it[label], [random_item])\n",
        "        prune_amount -= 1\n",
        "\n",
        "\n",
        "\n",
        "  formatted_indexes = np.array([])\n",
        "  for label in prune_indexes:\n",
        "    formatted_indexes = np.append(formatted_indexes, prune_indexes[label])\n",
        "  formatted_indexes = np.sort(formatted_indexes)\n",
        "  new_arr = np.array([np.int64(i) for i in formatted_indexes])\n",
        "\n",
        "  return X[new_arr], y[new_arr]"
      ],
      "metadata": {
        "id": "BtB6jqhZtRD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratios = [ratio for ratio in np.arange(0.2, 1.1, 0.2)]"
      ],
      "metadata": {
        "id": "z0A-h4iX3J8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Intelligent Pruning"
      ],
      "metadata": {
        "id": "UY6hAjLw9fy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_intelligent_pruning = dict()\n",
        "per_cluster_pruning_ratios = [0.5, 0.7, 0.9, 1]\n",
        "\n",
        "for per_cluster_pruning_ratio in per_cluster_pruning_ratios:\n",
        "  print(f'For per-cluster pruning ratio {per_cluster_pruning_ratio}')\n",
        "  for ratio in ratios:\n",
        "    X_train_copy, y_train_copy = X_train.copy(), y_train.copy()\n",
        "\n",
        "    intelligent_pruned_X_train, intelligent_pruned_y_train = do_intelligent_pruning(X_train_copy.to_numpy(), y_train_copy.to_numpy(), ratio, per_cluster_pruning_ratio=per_cluster_pruning_ratio)\n",
        "\n",
        "    preprocessed_intelligent_pruned_X_train, scaler, imputer = preprocess_data_train((np.array(intelligent_pruned_X_train))[0])\n",
        "    preprocessed_X_test = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    intelligent_pruned_X_train, intelligent_pruned_y_train = preprocessed_intelligent_pruned_X_train, (np.array(intelligent_pruned_y_train))[0]\n",
        "    intelligent_pruned_X_test, intelligent_pruned_y_test = preprocessed_X_test, y_test.to_numpy()\n",
        "    print(f\"Train data pruned intelligently at {ratio * 100}% :\")\n",
        "    results = evaluate_models(intelligent_pruned_X_train, intelligent_pruned_X_test, intelligent_pruned_y_train, intelligent_pruned_y_test)\n",
        "    print(results)\n",
        "    results_intelligent_pruning[ratio] = results\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRV_KrPy9is0",
        "outputId": "51d73678-d368-4b6b-e577-6615fdf4fb81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For per-cluster pruning ratio 0.5\n",
            "Train data pruned intelligently at 20.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7758620689655172, 'Precision': 0.7272727272727273, 'Recall': 0.4444444444444444, 'F1 Score': 0.5517241379310345, 'ROC AUC': 0.7152777777777778, 'Confusion Matrix': array([[37,  3],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.7777777777777778, 'Recall': 0.3888888888888889, 'F1 Score': 0.5185185185185185, 'ROC AUC': 0.8111111111111111, 'Confusion Matrix': array([[38,  2],\n",
            "       [11,  7]])}, 'Decision Tree': {'Accuracy': 0.6379310344827587, 'Precision': 0.42857142857142855, 'Recall': 0.5, 'F1 Score': 0.4615384615384615, 'ROC AUC': 0.6194444444444444, 'Confusion Matrix': array([[28, 12],\n",
            "       [ 9,  9]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 40.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7758620689655172, 'Precision': 0.6923076923076923, 'Recall': 0.5, 'F1 Score': 0.5806451612903226, 'ROC AUC': 0.7527777777777778, 'Confusion Matrix': array([[36,  4],\n",
            "       [ 9,  9]])}, 'SVM': {'Accuracy': 0.7931034482758621, 'Precision': 0.8, 'Recall': 0.4444444444444444, 'F1 Score': 0.5714285714285714, 'ROC AUC': 0.7513888888888889, 'Confusion Matrix': array([[38,  2],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.7241379310344828, 'Precision': 0.5714285714285714, 'Recall': 0.4444444444444444, 'F1 Score': 0.5, 'ROC AUC': 0.6708333333333333, 'Confusion Matrix': array([[34,  6],\n",
            "       [10,  8]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 60.00000000000001% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7758620689655172, 'Precision': 0.6666666666666666, 'Recall': 0.5555555555555556, 'F1 Score': 0.606060606060606, 'ROC AUC': 0.7597222222222222, 'Confusion Matrix': array([[35,  5],\n",
            "       [ 8, 10]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.6923076923076923, 'Recall': 0.5, 'F1 Score': 0.5806451612903226, 'ROC AUC': 0.7972222222222223, 'Confusion Matrix': array([[36,  4],\n",
            "       [ 9,  9]])}, 'Decision Tree': {'Accuracy': 0.6724137931034483, 'Precision': 0.47619047619047616, 'Recall': 0.5555555555555556, 'F1 Score': 0.5128205128205129, 'ROC AUC': 0.6402777777777777, 'Confusion Matrix': array([[29, 11],\n",
            "       [ 8, 10]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 80.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7586206896551724, 'Precision': 0.625, 'Recall': 0.5555555555555556, 'F1 Score': 0.5882352941176471, 'ROC AUC': 0.7125, 'Confusion Matrix': array([[34,  6],\n",
            "       [ 8, 10]])}, 'SVM': {'Accuracy': 0.7413793103448276, 'Precision': 0.6, 'Recall': 0.5, 'F1 Score': 0.5454545454545454, 'ROC AUC': 0.7652777777777778, 'Confusion Matrix': array([[34,  6],\n",
            "       [ 9,  9]])}, 'Decision Tree': {'Accuracy': 0.5862068965517241, 'Precision': 0.38461538461538464, 'Recall': 0.5555555555555556, 'F1 Score': 0.4545454545454546, 'ROC AUC': 0.5777777777777778, 'Confusion Matrix': array([[24, 16],\n",
            "       [ 8, 10]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 100.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.6724137931034483, 'Precision': 0.48, 'Recall': 0.6666666666666666, 'F1 Score': 0.5581395348837209, 'ROC AUC': 0.7583333333333333, 'Confusion Matrix': array([[27, 13],\n",
            "       [ 6, 12]])}, 'SVM': {'Accuracy': 0.7413793103448276, 'Precision': 0.56, 'Recall': 0.7777777777777778, 'F1 Score': 0.6511627906976745, 'ROC AUC': 0.8236111111111112, 'Confusion Matrix': array([[29, 11],\n",
            "       [ 4, 14]])}, 'Decision Tree': {'Accuracy': 0.6724137931034483, 'Precision': 0.48148148148148145, 'Recall': 0.7222222222222222, 'F1 Score': 0.5777777777777777, 'ROC AUC': 0.7041666666666666, 'Confusion Matrix': array([[26, 14],\n",
            "       [ 5, 13]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 0.7\n",
            "Train data pruned intelligently at 20.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8103448275862069, 'Precision': 0.8888888888888888, 'Recall': 0.4444444444444444, 'F1 Score': 0.5925925925925926, 'ROC AUC': 0.7305555555555555, 'Confusion Matrix': array([[39,  1],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.7777777777777778, 'Recall': 0.3888888888888889, 'F1 Score': 0.5185185185185185, 'ROC AUC': 0.8041666666666667, 'Confusion Matrix': array([[38,  2],\n",
            "       [11,  7]])}, 'Decision Tree': {'Accuracy': 0.6724137931034483, 'Precision': 0.47619047619047616, 'Recall': 0.5555555555555556, 'F1 Score': 0.5128205128205129, 'ROC AUC': 0.6604166666666667, 'Confusion Matrix': array([[29, 11],\n",
            "       [ 8, 10]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 40.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7931034482758621, 'Precision': 0.8, 'Recall': 0.4444444444444444, 'F1 Score': 0.5714285714285714, 'ROC AUC': 0.7291666666666667, 'Confusion Matrix': array([[38,  2],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.7777777777777778, 'Recall': 0.3888888888888889, 'F1 Score': 0.5185185185185185, 'ROC AUC': 0.7541666666666668, 'Confusion Matrix': array([[38,  2],\n",
            "       [11,  7]])}, 'Decision Tree': {'Accuracy': 0.6206896551724138, 'Precision': 0.4, 'Recall': 0.4444444444444444, 'F1 Score': 0.4210526315789474, 'ROC AUC': 0.611111111111111, 'Confusion Matrix': array([[28, 12],\n",
            "       [10,  8]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 60.00000000000001% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7758620689655172, 'Precision': 0.7272727272727273, 'Recall': 0.4444444444444444, 'F1 Score': 0.5517241379310345, 'ROC AUC': 0.7083333333333334, 'Confusion Matrix': array([[37,  3],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7586206896551724, 'Precision': 0.6666666666666666, 'Recall': 0.4444444444444444, 'F1 Score': 0.5333333333333333, 'ROC AUC': 0.7777777777777778, 'Confusion Matrix': array([[36,  4],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.6551724137931034, 'Precision': 0.45454545454545453, 'Recall': 0.5555555555555556, 'F1 Score': 0.5, 'ROC AUC': 0.6472222222222223, 'Confusion Matrix': array([[28, 12],\n",
            "       [ 8, 10]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 80.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7586206896551724, 'Precision': 0.625, 'Recall': 0.5555555555555556, 'F1 Score': 0.5882352941176471, 'ROC AUC': 0.7055555555555556, 'Confusion Matrix': array([[34,  6],\n",
            "       [ 8, 10]])}, 'SVM': {'Accuracy': 0.7413793103448276, 'Precision': 0.6153846153846154, 'Recall': 0.4444444444444444, 'F1 Score': 0.5161290322580646, 'ROC AUC': 0.7375, 'Confusion Matrix': array([[35,  5],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.603448275862069, 'Precision': 0.4, 'Recall': 0.5555555555555556, 'F1 Score': 0.46511627906976744, 'ROC AUC': 0.5902777777777778, 'Confusion Matrix': array([[25, 15],\n",
            "       [ 8, 10]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 100.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.603448275862069, 'Precision': 0.4074074074074074, 'Recall': 0.6111111111111112, 'F1 Score': 0.4888888888888889, 'ROC AUC': 0.6444444444444444, 'Confusion Matrix': array([[24, 16],\n",
            "       [ 7, 11]])}, 'SVM': {'Accuracy': 0.7068965517241379, 'Precision': 0.5263157894736842, 'Recall': 0.5555555555555556, 'F1 Score': 0.5405405405405405, 'ROC AUC': 0.7375, 'Confusion Matrix': array([[31,  9],\n",
            "       [ 8, 10]])}, 'Decision Tree': {'Accuracy': 0.7241379310344828, 'Precision': 0.5454545454545454, 'Recall': 0.6666666666666666, 'F1 Score': 0.6, 'ROC AUC': 0.7041666666666666, 'Confusion Matrix': array([[30, 10],\n",
            "       [ 6, 12]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 0.9\n",
            "Train data pruned intelligently at 20.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8103448275862069, 'Precision': 0.8888888888888888, 'Recall': 0.4444444444444444, 'F1 Score': 0.5925925925925926, 'ROC AUC': 0.7291666666666666, 'Confusion Matrix': array([[39,  1],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.7777777777777778, 'Recall': 0.3888888888888889, 'F1 Score': 0.5185185185185185, 'ROC AUC': 0.7541666666666667, 'Confusion Matrix': array([[38,  2],\n",
            "       [11,  7]])}, 'Decision Tree': {'Accuracy': 0.6206896551724138, 'Precision': 0.4, 'Recall': 0.4444444444444444, 'F1 Score': 0.4210526315789474, 'ROC AUC': 0.5722222222222222, 'Confusion Matrix': array([[28, 12],\n",
            "       [10,  8]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 40.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8275862068965517, 'Precision': 1.0, 'Recall': 0.4444444444444444, 'F1 Score': 0.6153846153846153, 'ROC AUC': 0.7069444444444444, 'Confusion Matrix': array([[40,  0],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.7272727272727273, 'Recall': 0.4444444444444444, 'F1 Score': 0.5517241379310345, 'ROC AUC': 0.7305555555555556, 'Confusion Matrix': array([[37,  3],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.6379310344827587, 'Precision': 0.42105263157894735, 'Recall': 0.4444444444444444, 'F1 Score': 0.43243243243243246, 'ROC AUC': 0.5979166666666665, 'Confusion Matrix': array([[29, 11],\n",
            "       [10,  8]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 60.00000000000001% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8103448275862069, 'Precision': 0.8181818181818182, 'Recall': 0.5, 'F1 Score': 0.6206896551724137, 'ROC AUC': 0.7041666666666666, 'Confusion Matrix': array([[38,  2],\n",
            "       [ 9,  9]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.7272727272727273, 'Recall': 0.4444444444444444, 'F1 Score': 0.5517241379310345, 'ROC AUC': 0.7486111111111111, 'Confusion Matrix': array([[37,  3],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.6206896551724138, 'Precision': 0.4, 'Recall': 0.4444444444444444, 'F1 Score': 0.4210526315789474, 'ROC AUC': 0.5847222222222224, 'Confusion Matrix': array([[28, 12],\n",
            "       [10,  8]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 80.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.5862068965517241, 'Precision': 0.36363636363636365, 'Recall': 0.4444444444444444, 'F1 Score': 0.39999999999999997, 'ROC AUC': 0.5736111111111111, 'Confusion Matrix': array([[26, 14],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7241379310344828, 'Precision': 0.5833333333333334, 'Recall': 0.3888888888888889, 'F1 Score': 0.4666666666666666, 'ROC AUC': 0.6736111111111112, 'Confusion Matrix': array([[35,  5],\n",
            "       [11,  7]])}, 'Decision Tree': {'Accuracy': 0.6206896551724138, 'Precision': 0.4090909090909091, 'Recall': 0.5, 'F1 Score': 0.45, 'ROC AUC': 0.6062500000000001, 'Confusion Matrix': array([[27, 13],\n",
            "       [ 9,  9]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 100.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.41379310344827586, 'Precision': 0.3, 'Recall': 0.6666666666666666, 'F1 Score': 0.41379310344827586, 'ROC AUC': 0.4416666666666667, 'Confusion Matrix': array([[12, 28],\n",
            "       [ 6, 12]])}, 'SVM': {'Accuracy': 0.43103448275862066, 'Precision': 0.3076923076923077, 'Recall': 0.6666666666666666, 'F1 Score': 0.42105263157894735, 'ROC AUC': 0.46805555555555556, 'Confusion Matrix': array([[13, 27],\n",
            "       [ 6, 12]])}, 'Decision Tree': {'Accuracy': 0.29310344827586204, 'Precision': 0.24444444444444444, 'Recall': 0.6111111111111112, 'F1 Score': 0.3492063492063492, 'ROC AUC': 0.3805555555555556, 'Confusion Matrix': array([[ 6, 34],\n",
            "       [ 7, 11]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 1\n",
            "Train data pruned intelligently at 20.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8275862068965517, 'Precision': 1.0, 'Recall': 0.4444444444444444, 'F1 Score': 0.6153846153846153, 'ROC AUC': 0.7208333333333333, 'Confusion Matrix': array([[40,  0],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.7777777777777778, 'Recall': 0.3888888888888889, 'F1 Score': 0.5185185185185185, 'ROC AUC': 0.7569444444444445, 'Confusion Matrix': array([[38,  2],\n",
            "       [11,  7]])}, 'Decision Tree': {'Accuracy': 0.7068965517241379, 'Precision': 0.5263157894736842, 'Recall': 0.5555555555555556, 'F1 Score': 0.5405405405405405, 'ROC AUC': 0.6666666666666667, 'Confusion Matrix': array([[31,  9],\n",
            "       [ 8, 10]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 40.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8275862068965517, 'Precision': 1.0, 'Recall': 0.4444444444444444, 'F1 Score': 0.6153846153846153, 'ROC AUC': 0.7055555555555556, 'Confusion Matrix': array([[40,  0],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.7272727272727273, 'Recall': 0.4444444444444444, 'F1 Score': 0.5517241379310345, 'ROC AUC': 0.7319444444444445, 'Confusion Matrix': array([[37,  3],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.6724137931034483, 'Precision': 0.47058823529411764, 'Recall': 0.4444444444444444, 'F1 Score': 0.45714285714285713, 'ROC AUC': 0.6097222222222223, 'Confusion Matrix': array([[31,  9],\n",
            "       [10,  8]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 60.00000000000001% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8448275862068966, 'Precision': 0.9090909090909091, 'Recall': 0.5555555555555556, 'F1 Score': 0.6896551724137931, 'ROC AUC': 0.7041666666666666, 'Confusion Matrix': array([[39,  1],\n",
            "       [ 8, 10]])}, 'SVM': {'Accuracy': 0.7586206896551724, 'Precision': 0.6666666666666666, 'Recall': 0.4444444444444444, 'F1 Score': 0.5333333333333333, 'ROC AUC': 0.726388888888889, 'Confusion Matrix': array([[36,  4],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.6206896551724138, 'Precision': 0.4, 'Recall': 0.4444444444444444, 'F1 Score': 0.4210526315789474, 'ROC AUC': 0.5916666666666666, 'Confusion Matrix': array([[28, 12],\n",
            "       [10,  8]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 80.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.603448275862069, 'Precision': 0.4, 'Recall': 0.5555555555555556, 'F1 Score': 0.46511627906976744, 'ROC AUC': 0.5583333333333335, 'Confusion Matrix': array([[25, 15],\n",
            "       [ 8, 10]])}, 'SVM': {'Accuracy': 0.5172413793103449, 'Precision': 0.32142857142857145, 'Recall': 0.5, 'F1 Score': 0.391304347826087, 'ROC AUC': 0.5694444444444444, 'Confusion Matrix': array([[21, 19],\n",
            "       [ 9,  9]])}, 'Decision Tree': {'Accuracy': 0.46551724137931033, 'Precision': 0.2903225806451613, 'Recall': 0.5, 'F1 Score': 0.3673469387755102, 'ROC AUC': 0.4875, 'Confusion Matrix': array([[18, 22],\n",
            "       [ 9,  9]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned intelligently at 100.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.6896551724137931, 'Precision': 0.5, 'Recall': 0.6666666666666666, 'F1 Score': 0.5714285714285715, 'ROC AUC': 0.7319444444444445, 'Confusion Matrix': array([[28, 12],\n",
            "       [ 6, 12]])}, 'SVM': {'Accuracy': 0.7586206896551724, 'Precision': 0.5909090909090909, 'Recall': 0.7222222222222222, 'F1 Score': 0.65, 'ROC AUC': 0.8375, 'Confusion Matrix': array([[31,  9],\n",
            "       [ 5, 13]])}, 'Decision Tree': {'Accuracy': 0.6379310344827587, 'Precision': 0.42105263157894735, 'Recall': 0.4444444444444444, 'F1 Score': 0.43243243243243246, 'ROC AUC': 0.6048611111111111, 'Confusion Matrix': array([[29, 11],\n",
            "       [10,  8]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calling Random Pruning"
      ],
      "metadata": {
        "id": "uGrS3yXb-RYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_random_pruning = dict()\n",
        "for ratio in ratios:\n",
        "  random_pruned_X_train, random_pruned_y_train = random_prune_data(X_train.to_numpy(), y_train.to_numpy(), ratio)\n",
        "  preprocessed_random_pruned_X_train, scaler, imputer = preprocess_data_train(random_pruned_X_train)\n",
        "  preprocessed_X_test = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "  random_pruned_X_train, random_pruned_y_train = preprocessed_random_pruned_X_train, random_pruned_y_train\n",
        "  random_pruned_X_test, random_pruned_y_test = preprocessed_X_test, y_test.to_numpy()\n",
        "\n",
        "  print(f\"Train data pruned randomly at {ratio * 100}% :\")\n",
        "  results = evaluate_models(random_pruned_X_train, random_pruned_X_test, random_pruned_y_train, random_pruned_y_test)\n",
        "  print(results)\n",
        "  results_random_pruning[ratio] = results\n",
        "  print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "4od9tUcU-QI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c165a853-27d5-4506-a5f6-c57f44672555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned randomly at 20.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7931034482758621, 'Precision': 0.8, 'Recall': 0.4444444444444444, 'F1 Score': 0.5714285714285714, 'ROC AUC': 0.7236111111111111, 'Confusion Matrix': array([[38,  2],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7586206896551724, 'Precision': 0.7, 'Recall': 0.3888888888888889, 'F1 Score': 0.5, 'ROC AUC': 0.8027777777777778, 'Confusion Matrix': array([[37,  3],\n",
            "       [11,  7]])}, 'Decision Tree': {'Accuracy': 0.7413793103448276, 'Precision': 0.5789473684210527, 'Recall': 0.6111111111111112, 'F1 Score': 0.5945945945945946, 'ROC AUC': 0.7055555555555556, 'Confusion Matrix': array([[32,  8],\n",
            "       [ 7, 11]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 40.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7758620689655172, 'Precision': 0.7272727272727273, 'Recall': 0.4444444444444444, 'F1 Score': 0.5517241379310345, 'ROC AUC': 0.7194444444444446, 'Confusion Matrix': array([[37,  3],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7931034482758621, 'Precision': 0.8, 'Recall': 0.4444444444444444, 'F1 Score': 0.5714285714285714, 'ROC AUC': 0.8097222222222222, 'Confusion Matrix': array([[38,  2],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.6724137931034483, 'Precision': 0.47619047619047616, 'Recall': 0.5555555555555556, 'F1 Score': 0.5128205128205129, 'ROC AUC': 0.6347222222222222, 'Confusion Matrix': array([[29, 11],\n",
            "       [ 8, 10]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 60.00000000000001% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7758620689655172, 'Precision': 0.7272727272727273, 'Recall': 0.4444444444444444, 'F1 Score': 0.5517241379310345, 'ROC AUC': 0.673611111111111, 'Confusion Matrix': array([[37,  3],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.7272727272727273, 'Recall': 0.4444444444444444, 'F1 Score': 0.5517241379310345, 'ROC AUC': 0.8097222222222222, 'Confusion Matrix': array([[37,  3],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.6724137931034483, 'Precision': 0.47619047619047616, 'Recall': 0.5555555555555556, 'F1 Score': 0.5128205128205129, 'ROC AUC': 0.6402777777777777, 'Confusion Matrix': array([[29, 11],\n",
            "       [ 8, 10]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 80.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7758620689655172, 'Precision': 0.6666666666666666, 'Recall': 0.5555555555555556, 'F1 Score': 0.606060606060606, 'ROC AUC': 0.6583333333333333, 'Confusion Matrix': array([[35,  5],\n",
            "       [ 8, 10]])}, 'SVM': {'Accuracy': 0.7413793103448276, 'Precision': 0.6153846153846154, 'Recall': 0.4444444444444444, 'F1 Score': 0.5161290322580646, 'ROC AUC': 0.788888888888889, 'Confusion Matrix': array([[35,  5],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.7586206896551724, 'Precision': 0.6, 'Recall': 0.6666666666666666, 'F1 Score': 0.631578947368421, 'ROC AUC': 0.7333333333333333, 'Confusion Matrix': array([[32,  8],\n",
            "       [ 6, 12]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 100.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.6724137931034483, 'Precision': 0.4782608695652174, 'Recall': 0.6111111111111112, 'F1 Score': 0.5365853658536586, 'ROC AUC': 0.6722222222222223, 'Confusion Matrix': array([[28, 12],\n",
            "       [ 7, 11]])}, 'SVM': {'Accuracy': 0.7241379310344828, 'Precision': 0.55, 'Recall': 0.6111111111111112, 'F1 Score': 0.5789473684210527, 'ROC AUC': 0.7875, 'Confusion Matrix': array([[31,  9],\n",
            "       [ 7, 11]])}, 'Decision Tree': {'Accuracy': 0.6379310344827587, 'Precision': 0.4444444444444444, 'Recall': 0.6666666666666666, 'F1 Score': 0.5333333333333333, 'ROC AUC': 0.6416666666666666, 'Confusion Matrix': array([[25, 15],\n",
            "       [ 6, 12]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SDV-Oversampling"
      ],
      "metadata": {
        "id": "f_VUTRHBBVDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sd1, train_df = do_sdv(X_train, y_train)\n",
        "results_syn_sdv = dict()\n",
        "\n",
        "# Add synthetic data at different percentages to the main DataFrame\n",
        "for ratio in ratios:\n",
        "    combined_df = add_synthetic_data(train_df, sd1, ratio)\n",
        "    y_train_sdv = combined_df['target']\n",
        "    X_train_sdv = combined_df.drop('target', axis=1)\n",
        "\n",
        "    preprocessed_X_train_sdv, scaler, imputer = preprocess_data_train(X_train_sdv)\n",
        "    preprocessed_X_test_sdv = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_sdv, y_train_sdv = preprocessed_X_train_sdv, y_train_sdv.to_numpy()\n",
        "    X_test_sdv, y_test_sdv = preprocessed_X_test_sdv, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    results = evaluate_models(X_train_sdv, X_test_sdv, y_train_sdv, y_test_sdv)\n",
        "    results_syn_sdv[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "g4V6WxpY9kbd",
        "outputId": "268312d3-6de7-4b06-efd9-4f2e819ab99e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sdv/single_table/base.py:80: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "{'Logistic Regression': {'Accuracy': 0.7931034482758621, 'Precision': 0.75, 'Recall': 0.5, 'F1 Score': 0.6, 'ROC AUC': 0.7291666666666666, 'Confusion Matrix': array([[37,  3],\n",
            "       [ 9,  9]])}, 'SVM': {'Accuracy': 0.7586206896551724, 'Precision': 0.6666666666666666, 'Recall': 0.4444444444444444, 'F1 Score': 0.5333333333333333, 'ROC AUC': 0.7944444444444444, 'Confusion Matrix': array([[36,  4],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.5862068965517241, 'Precision': 0.36363636363636365, 'Recall': 0.4444444444444444, 'F1 Score': 0.39999999999999997, 'ROC AUC': 0.5652777777777778, 'Confusion Matrix': array([[26, 14],\n",
            "       [10,  8]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "{'Logistic Regression': {'Accuracy': 0.8103448275862069, 'Precision': 0.7333333333333333, 'Recall': 0.6111111111111112, 'F1 Score': 0.6666666666666666, 'ROC AUC': 0.7416666666666667, 'Confusion Matrix': array([[36,  4],\n",
            "       [ 7, 11]])}, 'SVM': {'Accuracy': 0.7241379310344828, 'Precision': 0.5625, 'Recall': 0.5, 'F1 Score': 0.5294117647058824, 'ROC AUC': 0.7958333333333335, 'Confusion Matrix': array([[33,  7],\n",
            "       [ 9,  9]])}, 'Decision Tree': {'Accuracy': 0.7413793103448276, 'Precision': 0.5714285714285714, 'Recall': 0.6666666666666666, 'F1 Score': 0.6153846153846153, 'ROC AUC': 0.7208333333333332, 'Confusion Matrix': array([[31,  9],\n",
            "       [ 6, 12]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "{'Logistic Regression': {'Accuracy': 0.7758620689655172, 'Precision': 0.6470588235294118, 'Recall': 0.6111111111111112, 'F1 Score': 0.6285714285714287, 'ROC AUC': 0.7430555555555556, 'Confusion Matrix': array([[34,  6],\n",
            "       [ 7, 11]])}, 'SVM': {'Accuracy': 0.7241379310344828, 'Precision': 0.5555555555555556, 'Recall': 0.5555555555555556, 'F1 Score': 0.5555555555555556, 'ROC AUC': 0.7777777777777778, 'Confusion Matrix': array([[32,  8],\n",
            "       [ 8, 10]])}, 'Decision Tree': {'Accuracy': 0.6206896551724138, 'Precision': 0.42857142857142855, 'Recall': 0.6666666666666666, 'F1 Score': 0.5217391304347826, 'ROC AUC': 0.6583333333333334, 'Confusion Matrix': array([[24, 16],\n",
            "       [ 6, 12]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "{'Logistic Regression': {'Accuracy': 0.7413793103448276, 'Precision': 0.5789473684210527, 'Recall': 0.6111111111111112, 'F1 Score': 0.5945945945945946, 'ROC AUC': 0.7472222222222222, 'Confusion Matrix': array([[32,  8],\n",
            "       [ 7, 11]])}, 'SVM': {'Accuracy': 0.7413793103448276, 'Precision': 0.5789473684210527, 'Recall': 0.6111111111111112, 'F1 Score': 0.5945945945945946, 'ROC AUC': 0.7777777777777778, 'Confusion Matrix': array([[32,  8],\n",
            "       [ 7, 11]])}, 'Decision Tree': {'Accuracy': 0.7413793103448276, 'Precision': 0.56, 'Recall': 0.7777777777777778, 'F1 Score': 0.6511627906976745, 'ROC AUC': 0.7513888888888889, 'Confusion Matrix': array([[29, 11],\n",
            "       [ 4, 14]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "{'Logistic Regression': {'Accuracy': 0.7241379310344828, 'Precision': 0.5454545454545454, 'Recall': 0.6666666666666666, 'F1 Score': 0.6, 'ROC AUC': 0.7541666666666667, 'Confusion Matrix': array([[30, 10],\n",
            "       [ 6, 12]])}, 'SVM': {'Accuracy': 0.7413793103448276, 'Precision': 0.5789473684210527, 'Recall': 0.6111111111111112, 'F1 Score': 0.5945945945945946, 'ROC AUC': 0.7763888888888888, 'Confusion Matrix': array([[32,  8],\n",
            "       [ 7, 11]])}, 'Decision Tree': {'Accuracy': 0.6379310344827587, 'Precision': 0.42857142857142855, 'Recall': 0.5, 'F1 Score': 0.4615384615384615, 'ROC AUC': 0.5999999999999999, 'Confusion Matrix': array([[28, 12],\n",
            "       [ 9,  9]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SMOTE-Oversampling"
      ],
      "metadata": {
        "id": "l78jR_BuCw1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_smote = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_smote, y_train_smote = smote_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "    preprocessed_X_train_smote, scaler, imputer = preprocess_data_train((np.array(X_train_smote))[0])\n",
        "    preprocessed_X_test_smote = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_smote, y_train_smote = preprocessed_X_train_smote, (np.array(y_train_smote))[0]\n",
        "    X_test_smote, y_test_smote = preprocessed_X_test_smote, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_smote), len(y_train_smote))\n",
        "    results = evaluate_models(X_train_smote, X_test_smote, y_train_smote, y_test_smote)\n",
        "    results_smote[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7S78dnHC0bw",
        "outputId": "bc08d118-f9c7-4fe9-cca7-2fa9b63d174a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "246 246\n",
            "{'Logistic Regression': {'Accuracy': 0.8103448275862069, 'Precision': 0.8181818181818182, 'Recall': 0.5, 'F1 Score': 0.6206896551724137, 'ROC AUC': 0.7541666666666667, 'Confusion Matrix': array([[38,  2],\n",
            "       [ 9,  9]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.7272727272727273, 'Recall': 0.4444444444444444, 'F1 Score': 0.5517241379310345, 'ROC AUC': 0.7944444444444445, 'Confusion Matrix': array([[37,  3],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.6206896551724138, 'Precision': 0.4, 'Recall': 0.4444444444444444, 'F1 Score': 0.4210526315789474, 'ROC AUC': 0.5722222222222222, 'Confusion Matrix': array([[28, 12],\n",
            "       [10,  8]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "265 265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7931034482758621, 'Precision': 0.7142857142857143, 'Recall': 0.5555555555555556, 'F1 Score': 0.6250000000000001, 'ROC AUC': 0.7652777777777778, 'Confusion Matrix': array([[36,  4],\n",
            "       [ 8, 10]])}, 'SVM': {'Accuracy': 0.7931034482758621, 'Precision': 0.75, 'Recall': 0.5, 'F1 Score': 0.6, 'ROC AUC': 0.8, 'Confusion Matrix': array([[37,  3],\n",
            "       [ 9,  9]])}, 'Decision Tree': {'Accuracy': 0.6724137931034483, 'Precision': 0.48, 'Recall': 0.6666666666666666, 'F1 Score': 0.5581395348837209, 'ROC AUC': 0.6618055555555555, 'Confusion Matrix': array([[27, 13],\n",
            "       [ 6, 12]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "284 284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7586206896551724, 'Precision': 0.6111111111111112, 'Recall': 0.6111111111111112, 'F1 Score': 0.6111111111111112, 'ROC AUC': 0.7583333333333333, 'Confusion Matrix': array([[33,  7],\n",
            "       [ 7, 11]])}, 'SVM': {'Accuracy': 0.7068965517241379, 'Precision': 0.5294117647058824, 'Recall': 0.5, 'F1 Score': 0.5142857142857143, 'ROC AUC': 0.8, 'Confusion Matrix': array([[32,  8],\n",
            "       [ 9,  9]])}, 'Decision Tree': {'Accuracy': 0.6551724137931034, 'Precision': 0.45, 'Recall': 0.5, 'F1 Score': 0.4736842105263158, 'ROC AUC': 0.598611111111111, 'Confusion Matrix': array([[29, 11],\n",
            "       [ 9,  9]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "303 303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7241379310344828, 'Precision': 0.5454545454545454, 'Recall': 0.6666666666666666, 'F1 Score': 0.6, 'ROC AUC': 0.7430555555555556, 'Confusion Matrix': array([[30, 10],\n",
            "       [ 6, 12]])}, 'SVM': {'Accuracy': 0.6896551724137931, 'Precision': 0.5, 'Recall': 0.5555555555555556, 'F1 Score': 0.5263157894736842, 'ROC AUC': 0.7791666666666667, 'Confusion Matrix': array([[30, 10],\n",
            "       [ 8, 10]])}, 'Decision Tree': {'Accuracy': 0.7068965517241379, 'Precision': 0.5238095238095238, 'Recall': 0.6111111111111112, 'F1 Score': 0.5641025641025642, 'ROC AUC': 0.6805555555555556, 'Confusion Matrix': array([[30, 10],\n",
            "       [ 7, 11]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "322 322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.6724137931034483, 'Precision': 0.48, 'Recall': 0.6666666666666666, 'F1 Score': 0.5581395348837209, 'ROC AUC': 0.7374999999999999, 'Confusion Matrix': array([[27, 13],\n",
            "       [ 6, 12]])}, 'SVM': {'Accuracy': 0.7068965517241379, 'Precision': 0.5238095238095238, 'Recall': 0.6111111111111112, 'F1 Score': 0.5641025641025642, 'ROC AUC': 0.7361111111111112, 'Confusion Matrix': array([[30, 10],\n",
            "       [ 7, 11]])}, 'Decision Tree': {'Accuracy': 0.6206896551724138, 'Precision': 0.4166666666666667, 'Recall': 0.5555555555555556, 'F1 Score': 0.4761904761904762, 'ROC AUC': 0.6097222222222222, 'Confusion Matrix': array([[26, 14],\n",
            "       [ 8, 10]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Random-Oversampling"
      ],
      "metadata": {
        "id": "KKwGBPjpKrJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_random = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_random, y_train_random = random_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "\n",
        "    preprocessed_X_train_random, scaler, imputer = preprocess_data_train((np.array(X_train_random)[0]))\n",
        "    preprocessed_X_test_random = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_random, y_train_random = preprocessed_X_train_random, (np.array(y_train_random))[0]\n",
        "    X_test_random, y_test_random = preprocessed_X_test_random, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_random), len(y_train_random))\n",
        "    results = evaluate_models(X_train_random, X_test_random, y_train_random, y_test_random)\n",
        "    results_random[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC2kVR1tKtFn",
        "outputId": "935b987a-96be-4547-aad3-a95d26a5f223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "246 246\n",
            "{'Logistic Regression': {'Accuracy': 0.7586206896551724, 'Precision': 0.6666666666666666, 'Recall': 0.4444444444444444, 'F1 Score': 0.5333333333333333, 'ROC AUC': 0.7152777777777777, 'Confusion Matrix': array([[36,  4],\n",
            "       [10,  8]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.7272727272727273, 'Recall': 0.4444444444444444, 'F1 Score': 0.5517241379310345, 'ROC AUC': 0.7763888888888889, 'Confusion Matrix': array([[37,  3],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.7413793103448276, 'Precision': 0.6, 'Recall': 0.5, 'F1 Score': 0.5454545454545454, 'ROC AUC': 0.7222222222222222, 'Confusion Matrix': array([[34,  6],\n",
            "       [ 9,  9]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "265 265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7758620689655172, 'Precision': 0.6923076923076923, 'Recall': 0.5, 'F1 Score': 0.5806451612903226, 'ROC AUC': 0.7361111111111112, 'Confusion Matrix': array([[36,  4],\n",
            "       [ 9,  9]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.6923076923076923, 'Recall': 0.5, 'F1 Score': 0.5806451612903226, 'ROC AUC': 0.7902777777777777, 'Confusion Matrix': array([[36,  4],\n",
            "       [ 9,  9]])}, 'Decision Tree': {'Accuracy': 0.7413793103448276, 'Precision': 0.6, 'Recall': 0.5, 'F1 Score': 0.5454545454545454, 'ROC AUC': 0.6944444444444444, 'Confusion Matrix': array([[34,  6],\n",
            "       [ 9,  9]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "284 284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7758620689655172, 'Precision': 0.6666666666666666, 'Recall': 0.5555555555555556, 'F1 Score': 0.606060606060606, 'ROC AUC': 0.7277777777777777, 'Confusion Matrix': array([[35,  5],\n",
            "       [ 8, 10]])}, 'SVM': {'Accuracy': 0.7586206896551724, 'Precision': 0.6428571428571429, 'Recall': 0.5, 'F1 Score': 0.5625000000000001, 'ROC AUC': 0.7749999999999999, 'Confusion Matrix': array([[35,  5],\n",
            "       [ 9,  9]])}, 'Decision Tree': {'Accuracy': 0.6896551724137931, 'Precision': 0.5, 'Recall': 0.6111111111111112, 'F1 Score': 0.55, 'ROC AUC': 0.6680555555555556, 'Confusion Matrix': array([[29, 11],\n",
            "       [ 7, 11]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "303 303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7413793103448276, 'Precision': 0.5882352941176471, 'Recall': 0.5555555555555556, 'F1 Score': 0.5714285714285715, 'ROC AUC': 0.7388888888888888, 'Confusion Matrix': array([[33,  7],\n",
            "       [ 8, 10]])}, 'SVM': {'Accuracy': 0.7413793103448276, 'Precision': 0.5882352941176471, 'Recall': 0.5555555555555556, 'F1 Score': 0.5714285714285715, 'ROC AUC': 0.7930555555555555, 'Confusion Matrix': array([[33,  7],\n",
            "       [ 8, 10]])}, 'Decision Tree': {'Accuracy': 0.6896551724137931, 'Precision': 0.5, 'Recall': 0.4444444444444444, 'F1 Score': 0.47058823529411764, 'ROC AUC': 0.6222222222222222, 'Confusion Matrix': array([[32,  8],\n",
            "       [10,  8]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "322 322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7241379310344828, 'Precision': 0.5454545454545454, 'Recall': 0.6666666666666666, 'F1 Score': 0.6, 'ROC AUC': 0.7444444444444445, 'Confusion Matrix': array([[30, 10],\n",
            "       [ 6, 12]])}, 'SVM': {'Accuracy': 0.7241379310344828, 'Precision': 0.5555555555555556, 'Recall': 0.5555555555555556, 'F1 Score': 0.5555555555555556, 'ROC AUC': 0.8069444444444445, 'Confusion Matrix': array([[32,  8],\n",
            "       [ 8, 10]])}, 'Decision Tree': {'Accuracy': 0.6896551724137931, 'Precision': 0.5, 'Recall': 0.5555555555555556, 'F1 Score': 0.5263157894736842, 'ROC AUC': 0.6527777777777778, 'Confusion Matrix': array([[30, 10],\n",
            "       [ 8, 10]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SVM-SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "28Pi8n0HM4vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_svm_smote = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_svm_smote, y_train_svm_smote = svm_smote_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "\n",
        "    preprocessed_X_train_svm_smote, scaler, imputer = preprocess_data_train((np.array(X_train_svm_smote))[0])\n",
        "    preprocessed_X_test_svm_smote = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_svm_smote, y_train_svm_smote = preprocessed_X_train_svm_smote, (np.array(y_train_svm_smote))[0]\n",
        "    X_test_svm_smote, y_test_svm_smote = preprocessed_X_test_svm_smote, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_svm_smote), len(y_train_svm_smote))\n",
        "    results = evaluate_models(X_train_svm_smote, X_test_svm_smote, y_train_svm_smote, y_test_svm_smote)\n",
        "    results_svm_smote[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vkEOubrM81F",
        "outputId": "54fa35c3-d46f-483c-bcbb-be4770e4a357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "246 246\n",
            "{'Logistic Regression': {'Accuracy': 0.7931034482758621, 'Precision': 0.75, 'Recall': 0.5, 'F1 Score': 0.6, 'ROC AUC': 0.7222222222222221, 'Confusion Matrix': array([[37,  3],\n",
            "       [ 9,  9]])}, 'SVM': {'Accuracy': 0.7758620689655172, 'Precision': 0.7777777777777778, 'Recall': 0.3888888888888889, 'F1 Score': 0.5185185185185185, 'ROC AUC': 0.7916666666666666, 'Confusion Matrix': array([[38,  2],\n",
            "       [11,  7]])}, 'Decision Tree': {'Accuracy': 0.6206896551724138, 'Precision': 0.4090909090909091, 'Recall': 0.5, 'F1 Score': 0.45, 'ROC AUC': 0.5875000000000001, 'Confusion Matrix': array([[27, 13],\n",
            "       [ 9,  9]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "265 265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8103448275862069, 'Precision': 0.7692307692307693, 'Recall': 0.5555555555555556, 'F1 Score': 0.6451612903225806, 'ROC AUC': 0.7430555555555555, 'Confusion Matrix': array([[37,  3],\n",
            "       [ 8, 10]])}, 'SVM': {'Accuracy': 0.7931034482758621, 'Precision': 0.8, 'Recall': 0.4444444444444444, 'F1 Score': 0.5714285714285714, 'ROC AUC': 0.7805555555555556, 'Confusion Matrix': array([[38,  2],\n",
            "       [10,  8]])}, 'Decision Tree': {'Accuracy': 0.6551724137931034, 'Precision': 0.45454545454545453, 'Recall': 0.5555555555555556, 'F1 Score': 0.5, 'ROC AUC': 0.6277777777777778, 'Confusion Matrix': array([[28, 12],\n",
            "       [ 8, 10]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "284 284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7586206896551724, 'Precision': 0.6111111111111112, 'Recall': 0.6111111111111112, 'F1 Score': 0.6111111111111112, 'ROC AUC': 0.7680555555555556, 'Confusion Matrix': array([[33,  7],\n",
            "       [ 7, 11]])}, 'SVM': {'Accuracy': 0.8103448275862069, 'Precision': 0.8181818181818182, 'Recall': 0.5, 'F1 Score': 0.6206896551724137, 'ROC AUC': 0.8125, 'Confusion Matrix': array([[38,  2],\n",
            "       [ 9,  9]])}, 'Decision Tree': {'Accuracy': 0.6724137931034483, 'Precision': 0.48, 'Recall': 0.6666666666666666, 'F1 Score': 0.5581395348837209, 'ROC AUC': 0.6708333333333334, 'Confusion Matrix': array([[27, 13],\n",
            "       [ 6, 12]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "303 303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7413793103448276, 'Precision': 0.5789473684210527, 'Recall': 0.6111111111111112, 'F1 Score': 0.5945945945945946, 'ROC AUC': 0.7583333333333334, 'Confusion Matrix': array([[32,  8],\n",
            "       [ 7, 11]])}, 'SVM': {'Accuracy': 0.7931034482758621, 'Precision': 0.75, 'Recall': 0.5, 'F1 Score': 0.6, 'ROC AUC': 0.7875, 'Confusion Matrix': array([[37,  3],\n",
            "       [ 9,  9]])}, 'Decision Tree': {'Accuracy': 0.6896551724137931, 'Precision': 0.5, 'Recall': 0.6666666666666666, 'F1 Score': 0.5714285714285715, 'ROC AUC': 0.6833333333333332, 'Confusion Matrix': array([[28, 12],\n",
            "       [ 6, 12]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "322 322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7068965517241379, 'Precision': 0.5238095238095238, 'Recall': 0.6111111111111112, 'F1 Score': 0.5641025641025642, 'ROC AUC': 0.7250000000000001, 'Confusion Matrix': array([[30, 10],\n",
            "       [ 7, 11]])}, 'SVM': {'Accuracy': 0.7068965517241379, 'Precision': 0.5294117647058824, 'Recall': 0.5, 'F1 Score': 0.5142857142857143, 'ROC AUC': 0.7652777777777777, 'Confusion Matrix': array([[32,  8],\n",
            "       [ 9,  9]])}, 'Decision Tree': {'Accuracy': 0.6206896551724138, 'Precision': 0.4, 'Recall': 0.4444444444444444, 'F1 Score': 0.4210526315789474, 'ROC AUC': 0.5722222222222222, 'Confusion Matrix': array([[28, 12],\n",
            "       [10,  8]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}
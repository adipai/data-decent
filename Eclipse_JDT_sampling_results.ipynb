{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adipai/data-decent/blob/main/Eclipse_JDT_sampling_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pmlb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAJ8lflEvuaA",
        "outputId": "9161a68f-9683-415c-ac3b-a188d2a7f7a9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pmlb\n",
            "  Downloading pmlb-1.0.1.post3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from pmlb) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from pmlb) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from pmlb) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->pmlb) (1.16.0)\n",
            "Installing collected packages: pmlb\n",
            "Successfully installed pmlb-1.0.1.post3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sdv"
      ],
      "metadata": {
        "id": "COAFe5iG-02V",
        "outputId": "33b1792c-b0c6-45d1-ea02-ed55e9c8ade1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sdv\n",
            "  Downloading sdv-1.11.0-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2,>=1.15.0 (from sdv)\n",
            "  Downloading boto3-1.34.81-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<2,>=1.18 (from sdv)\n",
            "  Downloading botocore-1.34.81-py3-none-any.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<3.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (2.2.1)\n",
            "Requirement already satisfied: graphviz<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from sdv) (0.20.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.15 in /usr/local/lib/python3.10/dist-packages (from sdv) (4.66.2)\n",
            "Collecting copulas<0.10,>=0.9.0 (from sdv)\n",
            "  Downloading copulas-0.9.2-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctgan<0.10,>=0.9.0 (from sdv)\n",
            "  Downloading ctgan-0.9.1-py3-none-any.whl (24 kB)\n",
            "Collecting deepecho<0.6,>=0.5 (from sdv)\n",
            "  Downloading deepecho-0.5.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting rdt<2,>=1.10.0 (from sdv)\n",
            "  Downloading rdt-1.10.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sdmetrics<0.14,>=0.13.0 (from sdv)\n",
            "  Downloading sdmetrics-0.13.1-py3-none-any.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.8/169.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1.23.3 in /usr/local/lib/python3.10/dist-packages (from sdv) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.3.4 in /usr/local/lib/python3.10/dist-packages (from sdv) (2.0.3)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.15.0->sdv)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.15.0->sdv)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<2,>=1.18->sdv) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<2,>=1.18->sdv) (2.0.7)\n",
            "Requirement already satisfied: matplotlib<4,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from copulas<0.10,>=0.9.0->sdv) (3.7.1)\n",
            "Requirement already satisfied: scipy<2,>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from copulas<0.10,>=0.9.0->sdv) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from ctgan<0.10,>=0.9.0->sdv) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from ctgan<0.10,>=0.9.0->sdv) (2.2.1+cu121)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.4->sdv) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.4->sdv) (2024.1)\n",
            "Collecting Faker<20,>=17 (from rdt<2,>=1.10.0->sdv)\n",
            "  Downloading Faker-19.13.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of sdmetrics to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sdmetrics<0.14,>=0.13.0 (from sdv)\n",
            "  Downloading sdmetrics-0.13.0-py2.py3-none-any.whl (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.7/170.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: plotly<6,>=5.10.0 in /usr/local/lib/python3.10/dist-packages (from sdmetrics<0.14,>=0.13.0->sdv) (5.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly<6,>=5.10.0->sdmetrics<0.14,>=0.13.0->sdv) (8.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<2,>=1.18->sdv) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.3->ctgan<0.10,>=0.9.0->sdv) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.3->ctgan<0.10,>=0.9.0->sdv) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, nvidia-cusparse-cu12, nvidia-cudnn-cu12, Faker, botocore, s3transfer, rdt, nvidia-cusolver-cu12, copulas, sdmetrics, boto3, deepecho, ctgan, sdv\n",
            "Successfully installed Faker-19.13.0 boto3-1.34.81 botocore-1.34.81 copulas-0.9.2 ctgan-0.9.1 deepecho-0.5.0 jmespath-1.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 rdt-1.10.1 s3transfer-0.10.1 sdmetrics-0.13.0 sdv-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install DataSynthesizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBcGtW-pIGJ4",
        "outputId": "a4448470-0a0e-4d2c-eaa3-3929a9c49d31"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting DataSynthesizer\n",
            "  Downloading DataSynthesizer-0.1.13-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (3.7.1)\n",
            "Requirement already satisfied: seaborn>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (0.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->DataSynthesizer) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->DataSynthesizer) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->DataSynthesizer) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (3.4.0)\n",
            "Installing collected packages: DataSynthesizer\n",
            "Successfully installed DataSynthesizer-0.1.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWPFD1ycAEY1",
        "outputId": "c56274ac-0a7b-4052-af3a-71e960da5d90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "   creating: data/imbalance_defects_prediction/\n",
            "   creating: data/project_health/\n",
            "  inflating: data/README.md          \n",
            "   creating: data/JavaScript_Vulnerability/\n",
            "   creating: data/Bug_Reports/\n",
            "   creating: data/Vulnerable_Files/\n",
            "   creating: data/defects_prediction/\n",
            "   creating: data/imbalance_defects_prediction/7_CK_NET_PROC/\n",
            "   creating: data/imbalance_defects_prediction/2_NET/\n",
            "   creating: data/imbalance_defects_prediction/4_CK_NET/\n",
            "   creating: data/imbalance_defects_prediction/3_PROC/\n",
            "   creating: data/imbalance_defects_prediction/6_NET_PROC/\n",
            "   creating: data/imbalance_defects_prediction/1_CK/\n",
            "   creating: data/imbalance_defects_prediction/5_CK_PROC/\n",
            "   creating: data/project_health/monthly_closed_PRs_2mo/\n",
            "   creating: data/project_health/monthly_commits_2mo/\n",
            "   creating: data/project_health/monthly_open_PRs_2mo/\n",
            "   creating: data/project_health/monthly_closed_issues_2mo/\n",
            "   creating: data/project_health/monthly_commits_12mo/\n",
            "   creating: data/project_health/monthly_open_issues_2mo/\n",
            "   creating: data/project_health/monthly_closed_issues_12mo/\n",
            "   creating: data/project_health/monthly_contributors_2mo/\n",
            "   creating: data/project_health/monthly_closed_PRs_12mo/\n",
            "  inflating: data/JavaScript_Vulnerability/JSVulnerabilityDataSet-1.0.csv  \n",
            "  inflating: data/Bug_Reports/ambari-train.csv  \n",
            "  inflating: data/Bug_Reports/ambari-test.csv  \n",
            "  inflating: data/Vulnerable_Files/moodle-2_0_0-metrics.arff  \n",
            "  inflating: data/Vulnerable_Files/moodle-2_0_0-tokens.arff  \n",
            "  inflating: data/defects_prediction/Droppy.csv  \n",
            "  inflating: data/defects_prediction/android-transcoder.csv  \n",
            "  inflating: data/defects_prediction/android-flowlayout.csv  \n",
            "   creating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/\n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/data_sets.txt  \n",
            "   creating: data/imbalance_defects_prediction/2_NET/input/\n",
            "  inflating: data/imbalance_defects_prediction/2_NET/data_sets.txt  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/reImbPUB0.jar  \n",
            "   creating: data/imbalance_defects_prediction/4_CK_NET/input/\n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/data_sets.txt  \n",
            "   creating: data/imbalance_defects_prediction/3_PROC/input/\n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/data_sets.txt  \n",
            "   creating: data/imbalance_defects_prediction/6_NET_PROC/input/\n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/data_sets.txt  \n",
            "   creating: data/imbalance_defects_prediction/1_CK/input/\n",
            "  inflating: data/imbalance_defects_prediction/1_CK/data_sets.txt  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/reImbPUB0.jar  \n",
            "   creating: data/imbalance_defects_prediction/5_CK_PROC/input/\n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/data_sets.txt  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_2mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_commits_2mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_open_PRs_2mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_2mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_commits_12mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_open_issues_2mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_closed_issues_12mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_contributors_2mo/health_project0003.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0008.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0009.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0007.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0006.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0004.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0010.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0011.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0005.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0001.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0000.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0002.csv  \n",
            "  inflating: data/project_health/monthly_closed_PRs_12mo/health_project0003.csv  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/jedit-4.0--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/Lucene--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/synapse-1.2--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/jedit-4.1--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/synapse-1.1--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/jedit-4.2--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/Equinox_Framework--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/xerces-1.2--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/velocity-1.6--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/synapse-1.0--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/jedit-4.3--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/xerces-1.3--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/jedit-3.2--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/ant-1.4--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/poi-2.0--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/camel-1.2--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/ant-1.5--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/camel-1.6--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/Eclipse_PDE_UI--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/ant-1.6--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/ant-1.3--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/Eclipse_JDT_Core--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/camel-1.0--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/Mylyn--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/camel-1.4--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/log4j-1.0--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/7_CK_NET_PROC/input/ivy-2.0--CK_NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/jedit-4.0--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/camel-1.4--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/Eclipse_PDE_UI--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/ant-1.6--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/camel-1.2--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/Equinox_Framework--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/Eclipse_JDT_Core--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/jedit-4.1--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/synapse-1.2--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/Mylyn--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/Lucene--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/jedit-3.2--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/poi-2.0--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/synapse-1.1--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/jedit-4.2--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/camel-1.6--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/velocity-1.6--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/xerces-1.3--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/ivy-2.0--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/ant-1.4--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/camel-1.0--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/jedit-4.3--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/synapse-1.0--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/ant-1.3--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/xerces-1.2--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/ant-1.5--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/2_NET/input/log4j-1.0--NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/synapse-1.2--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/jedit-3.2--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/camel-1.2--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/ant-1.6--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/velocity-1.6--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/jedit-4.2--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/xerces-1.2--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/camel-1.4--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/Lucene--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/xerces-1.3--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/jedit-4.3--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/Mylyn--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/log4j-1.0--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/Eclipse_JDT_Core--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/Equinox_Framework--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/poi-2.0--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/Eclipse_PDE_UI--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/ant-1.5--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/camel-1.6--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/synapse-1.1--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/jedit-4.1--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/synapse-1.0--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/ant-1.3--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/ivy-2.0--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/ant-1.4--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/camel-1.0--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/4_CK_NET/input/jedit-4.0--CK_NET.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/xerces-1.2--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/poi-2.0--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/camel-1.4--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/log4j-1.0--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/jedit-4.2--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/jedit-3.2--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/ant-1.5--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/camel-1.6--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/jedit-4.0--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/synapse-1.1--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/camel-1.0--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/jedit-4.3--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/ant-1.4--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/synapse-1.2--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/xerces-1.3--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/ivy-2.0--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/camel-1.2--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/jedit-4.1--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/Eclipse_PDE_UI--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/velocity-1.6--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/Mylyn--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/ant-1.6--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/Equinox_Framework--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/synapse-1.0--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/Eclipse_JDT_Core--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/Lucene--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/3_PROC/input/ant-1.3--PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/log4j-1.0--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/Eclipse_PDE_UI--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/synapse-1.1--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/Equinox_Framework--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/synapse-1.0--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/synapse-1.2--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/jedit-3.2--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/xerces-1.2--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/jedit-4.3--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/Eclipse_JDT_Core--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/Mylyn--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/camel-1.0--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/ant-1.6--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/ivy-2.0--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/camel-1.6--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/jedit-4.2--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/xerces-1.3--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/ant-1.3--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/jedit-4.0--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/camel-1.4--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/ant-1.4--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/poi-2.0--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/ant-1.5--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/velocity-1.6--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/camel-1.2--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/jedit-4.1--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/6_NET_PROC/input/Lucene--NET_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/synapse-1.0--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/synapse-1.1--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/ant-1.3--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/Equinox_Framework--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/log4j-1.0--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/velocity-1.6--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/jedit-3.2--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/camel-1.6--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/camel-1.0--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/jedit-4.2--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/jedit-4.3--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/Eclipse_JDT_Core--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/ivy-2.0--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/ant-1.5--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/ant-1.4--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/xerces-1.2--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/xerces-1.3--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/camel-1.4--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/synapse-1.2--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/ant-1.6--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/poi-2.0--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/Eclipse_PDE_UI--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/jedit-4.1--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/jedit-4.0--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/Mylyn--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/Lucene--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/1_CK/input/camel-1.2--CK.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/synapse-1.1--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/velocity-1.6--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/ant-1.6--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/Mylyn--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/ant-1.5--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/ivy-2.0--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/synapse-1.2--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/Lucene--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/Eclipse_JDT_Core--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/Equinox_Framework--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/xerces-1.2--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/jedit-4.2--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/jedit-4.1--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/camel-1.0--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/jedit-3.2--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/camel-1.4--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/jedit-4.0--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/log4j-1.0--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/xerces-1.3--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/camel-1.6--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/jedit-4.3--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/camel-1.2--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/ant-1.4--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/Eclipse_PDE_UI--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/poi-2.0--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/synapse-1.0--CK_PROC.arff  \n",
            "  inflating: data/imbalance_defects_prediction/5_CK_PROC/input/ant-1.3--CK_PROC.arff  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All imports here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pmlb import fetch_data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import time\n",
        "\n",
        "from scipy.io import arff\n",
        "from sdv.datasets.local import load_csvs\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sdv.single_table import GaussianCopulaSynthesizer\n",
        "from DataSynthesizer.DataDescriber import DataDescriber\n",
        "from DataSynthesizer.DataGenerator import DataGenerator\n",
        "from DataSynthesizer.lib.utils import display_bayesian_network\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix"
      ],
      "metadata": {
        "id": "Lza8MeLYchI2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "KH_s6WhMv_Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data_train(X_train):\n",
        "    # Count missing values before handling missing data\n",
        "    missing_before = np.isnan(X_train).sum()\n",
        "\n",
        "    # Handle missing data\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "\n",
        "    # Count missing values after handling missing data\n",
        "    missing_after = np.isnan(X_train).sum()\n",
        "\n",
        "    # Normalize numeric columns\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "    return X_train, scaler, imputer\n",
        "\n",
        "def preprocess_data_test(X_test, scaler, imputer):\n",
        "    # Count missing values before handling missing data\n",
        "    missing_before = np.isnan(X_test).sum()\n",
        "\n",
        "    # Handle missing data\n",
        "    X_test = imputer.transform(X_test)\n",
        "\n",
        "    # Count missing values after handling missing data\n",
        "    missing_after = np.isnan(X_test).sum()\n",
        "\n",
        "    # Normalize numeric columns\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_test"
      ],
      "metadata": {
        "id": "A9ept3j9vmUy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "3Rjlt8zr4vyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: Eclipse JDT"
      ],
      "metadata": {
        "id": "p22RSGg043d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project = \"Defect_Eclipse_JDT_Core\"\n",
        "fname = \"_\".join(project.split(\"_\")[1:])\n",
        "data_path = f\"data/imbalance_defects_prediction/7_CK_NET_PROC/input/{fname}--CK_NET_PROC.arff\"\n",
        "data = arff.loadarff(data_path)\n",
        "df = pd.DataFrame(data[0])\n",
        "df['isBug'] = df['isBug'].astype('str')\n",
        "d = {'YES': 1, 'NO': 0}  # Remove the byte string prefix 'b'\n",
        "df['isBug'] = df['isBug'].map(d).fillna(df['isBug'])\n",
        "print(df['isBug'])\n",
        "print(\"before drop duplicates\", df.shape[0])\n",
        "df = df.drop_duplicates()\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "print(\"after drop duplicates\", df.shape[0])\n",
        "\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "wyi4iWJFwIhU",
        "outputId": "8f2a6872-fb76-406d-9b2a-443c6dec15b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "992    0\n",
            "993    0\n",
            "994    0\n",
            "995    0\n",
            "996    0\n",
            "Name: isBug, Length: 997, dtype: int64\n",
            "before drop duplicates 997\n",
            "after drop duplicates 997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               wmc         dit          rfc         noc         cbo  \\\n",
              "count   997.000000  997.000000   997.000000  997.000000  997.000000   \n",
              "mean     58.384152    2.727182    76.874624    0.712136   12.216650   \n",
              "std     135.722660    1.721525   180.978591    2.154752   17.815915   \n",
              "min       0.000000    1.000000     0.000000    0.000000    0.000000   \n",
              "25%       8.000000    1.000000    12.000000    0.000000    3.000000   \n",
              "50%      20.000000    2.000000    30.000000    0.000000    7.000000   \n",
              "75%      50.000000    4.000000    70.000000    0.000000   14.000000   \n",
              "max    1680.000000    8.000000  2603.000000   26.000000  156.000000   \n",
              "\n",
              "               lcom          loc  revision_num  author_num  linesadd_sum  ...  \\\n",
              "count    997.000000   997.000000    997.000000  997.000000    997.000000  ...   \n",
              "mean     364.727182   224.729188     45.618857    5.793380   1209.460381  ...   \n",
              "std     3230.074059   555.700530     60.995862    2.570187   3921.650184  ...   \n",
              "min        0.000000     0.000000      1.000000    1.000000      0.000000  ...   \n",
              "25%        6.000000    28.000000     13.000000    4.000000     81.000000  ...   \n",
              "50%       28.000000    75.000000     30.000000    6.000000    276.000000  ...   \n",
              "75%       91.000000   192.000000     52.000000    7.000000    833.000000  ...   \n",
              "max    81003.000000  7341.000000    709.000000   15.000000  65571.000000  ...   \n",
              "\n",
              "        InFreeClo   OutValClo    InValClo  OutRecipClo  InRecipClo  \\\n",
              "count  997.000000  997.000000  997.000000   997.000000  997.000000   \n",
              "mean     0.003507    0.577920    0.577920     0.173663    0.173663   \n",
              "std      0.002629    0.388013    0.202109     0.106940    0.089645   \n",
              "min      0.001003    0.000000    0.000000     0.001003    0.001003   \n",
              "25%      0.002014    0.257659    0.502486     0.092025    0.118853   \n",
              "50%      0.002016    0.951735    0.502911     0.162254    0.150396   \n",
              "75%      0.007888    0.953893    0.873717     0.267023    0.225866   \n",
              "max      0.008033    0.970087    0.876018     0.438462    0.534813   \n",
              "\n",
              "       OutdwReach   IndwReach  nOutdwReach  nIndwReach       isBug  \n",
              "count  997.000000  997.000000   997.000000  997.000000  997.000000  \n",
              "mean   173.548682  173.548714     0.174071    0.174071    0.206620  \n",
              "std    106.878591   89.463820     0.107200    0.089733    0.405084  \n",
              "min      1.000000    1.000000     0.001003    0.001003    0.000000  \n",
              "25%     91.916748  118.883202     0.092193    0.119241    0.000000  \n",
              "50%    162.562225  150.299881     0.163051    0.150752    0.000000  \n",
              "75%    266.911713  225.466293     0.267715    0.226145    0.000000  \n",
              "max    437.664520  533.550598     0.438981    0.535156    1.000000  \n",
              "\n",
              "[8 rows x 82 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7843a9bd-4ff8-4a71-ab1b-811146356ac4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wmc</th>\n",
              "      <th>dit</th>\n",
              "      <th>rfc</th>\n",
              "      <th>noc</th>\n",
              "      <th>cbo</th>\n",
              "      <th>lcom</th>\n",
              "      <th>loc</th>\n",
              "      <th>revision_num</th>\n",
              "      <th>author_num</th>\n",
              "      <th>linesadd_sum</th>\n",
              "      <th>...</th>\n",
              "      <th>InFreeClo</th>\n",
              "      <th>OutValClo</th>\n",
              "      <th>InValClo</th>\n",
              "      <th>OutRecipClo</th>\n",
              "      <th>InRecipClo</th>\n",
              "      <th>OutdwReach</th>\n",
              "      <th>IndwReach</th>\n",
              "      <th>nOutdwReach</th>\n",
              "      <th>nIndwReach</th>\n",
              "      <th>isBug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>997.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>58.384152</td>\n",
              "      <td>2.727182</td>\n",
              "      <td>76.874624</td>\n",
              "      <td>0.712136</td>\n",
              "      <td>12.216650</td>\n",
              "      <td>364.727182</td>\n",
              "      <td>224.729188</td>\n",
              "      <td>45.618857</td>\n",
              "      <td>5.793380</td>\n",
              "      <td>1209.460381</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003507</td>\n",
              "      <td>0.577920</td>\n",
              "      <td>0.577920</td>\n",
              "      <td>0.173663</td>\n",
              "      <td>0.173663</td>\n",
              "      <td>173.548682</td>\n",
              "      <td>173.548714</td>\n",
              "      <td>0.174071</td>\n",
              "      <td>0.174071</td>\n",
              "      <td>0.206620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>135.722660</td>\n",
              "      <td>1.721525</td>\n",
              "      <td>180.978591</td>\n",
              "      <td>2.154752</td>\n",
              "      <td>17.815915</td>\n",
              "      <td>3230.074059</td>\n",
              "      <td>555.700530</td>\n",
              "      <td>60.995862</td>\n",
              "      <td>2.570187</td>\n",
              "      <td>3921.650184</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002629</td>\n",
              "      <td>0.388013</td>\n",
              "      <td>0.202109</td>\n",
              "      <td>0.106940</td>\n",
              "      <td>0.089645</td>\n",
              "      <td>106.878591</td>\n",
              "      <td>89.463820</td>\n",
              "      <td>0.107200</td>\n",
              "      <td>0.089733</td>\n",
              "      <td>0.405084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002014</td>\n",
              "      <td>0.257659</td>\n",
              "      <td>0.502486</td>\n",
              "      <td>0.092025</td>\n",
              "      <td>0.118853</td>\n",
              "      <td>91.916748</td>\n",
              "      <td>118.883202</td>\n",
              "      <td>0.092193</td>\n",
              "      <td>0.119241</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>276.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002016</td>\n",
              "      <td>0.951735</td>\n",
              "      <td>0.502911</td>\n",
              "      <td>0.162254</td>\n",
              "      <td>0.150396</td>\n",
              "      <td>162.562225</td>\n",
              "      <td>150.299881</td>\n",
              "      <td>0.163051</td>\n",
              "      <td>0.150752</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>50.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>192.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>833.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007888</td>\n",
              "      <td>0.953893</td>\n",
              "      <td>0.873717</td>\n",
              "      <td>0.267023</td>\n",
              "      <td>0.225866</td>\n",
              "      <td>266.911713</td>\n",
              "      <td>225.466293</td>\n",
              "      <td>0.267715</td>\n",
              "      <td>0.226145</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1680.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2603.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>81003.000000</td>\n",
              "      <td>7341.000000</td>\n",
              "      <td>709.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>65571.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008033</td>\n",
              "      <td>0.970087</td>\n",
              "      <td>0.876018</td>\n",
              "      <td>0.438462</td>\n",
              "      <td>0.534813</td>\n",
              "      <td>437.664520</td>\n",
              "      <td>533.550598</td>\n",
              "      <td>0.438981</td>\n",
              "      <td>0.535156</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 82 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7843a9bd-4ff8-4a71-ab1b-811146356ac4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7843a9bd-4ff8-4a71-ab1b-811146356ac4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7843a9bd-4ff8-4a71-ab1b-811146356ac4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8623b911-33b9-4311-ada4-a927d5f25f9d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8623b911-33b9-4311-ada4-a927d5f25f9d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8623b911-33b9-4311-ada4-a927d5f25f9d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and testing using ML models"
      ],
      "metadata": {
        "id": "gGu1Qxej4WAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic function to test synthetic data using LR, SVM, DT\n",
        "\n",
        "def evaluate_models(X_train, X_test, y_train, y_test, random_state=42):\n",
        "\n",
        "    # Initialize classifiers\n",
        "    classifiers = {\n",
        "        \"Logistic Regression\": LogisticRegression(random_state=random_state),\n",
        "        \"SVM\": SVC(random_state=random_state),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(random_state=random_state)\n",
        "    }\n",
        "\n",
        "    # Results dictionary to store evaluation metrics\n",
        "    results = {}\n",
        "\n",
        "    # Iterate over classifiers\n",
        "    for name, clf in classifiers.items():\n",
        "        # Fit classifier\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Predictions\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Evaluation metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        # AUC-ROC\n",
        "        if hasattr(clf, \"predict_proba\"):\n",
        "            y_prob = clf.predict_proba(X_test)[:,1]\n",
        "        else:\n",
        "            y_prob = clf.decision_function(X_test)\n",
        "        fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Store results\n",
        "        results[name] = {\n",
        "            \"Accuracy\": accuracy,\n",
        "            \"Precision\": precision,\n",
        "            \"Recall\": recall,\n",
        "            \"F1 Score\": f1,\n",
        "            \"ROC AUC\": roc_auc,\n",
        "            \"Confusion Matrix\": cm\n",
        "        }\n",
        "\n",
        "        # Plot AUC-ROC curve\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'{name} - AUC-ROC Curve')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.savefig(f'{name}_auc_roc_curve.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title(f'{name} - Confusion Matrix')\n",
        "        plt.savefig(f'{name}_confusion_matrix.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "SULk39gP2SUj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n"
      ],
      "metadata": {
        "id": "2aBR2GZH2bb_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate_models(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "adNKyUsSLi6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497e8c16-e6eb-4e49-9cc7-5d99d8c82cce"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAAzoxMlLpjk",
        "outputId": "d1de0550-1510-4587-9f1b-b14056b5df46"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.84, 'Precision': 0.7777777777777778, 'Recall': 0.44680851063829785, 'F1 Score': 0.5675675675675675, 'ROC AUC': 0.8149075232930052, 'Confusion Matrix': array([[147,   6],\n",
            "       [ 26,  21]])}, 'SVM': {'Accuracy': 0.82, 'Precision': 0.7894736842105263, 'Recall': 0.3191489361702128, 'F1 Score': 0.4545454545454545, 'ROC AUC': 0.7744402725629259, 'Confusion Matrix': array([[149,   4],\n",
            "       [ 32,  15]])}, 'Decision Tree': {'Accuracy': 0.78, 'Precision': 0.5306122448979592, 'Recall': 0.5531914893617021, 'F1 Score': 0.5416666666666667, 'ROC AUC': 0.7014323459880406, 'Confusion Matrix': array([[130,  23],\n",
            "       [ 21,  26]])}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SDV - Oversampling"
      ],
      "metadata": {
        "id": "_NaC7Ymj90QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def do_sdv(X_train, y_train):\n",
        "  train_df = pd.concat([X_train, y_train], axis=1)\n",
        "  class_counts = y_train.value_counts()\n",
        "\n",
        "  # Find minority class label\n",
        "  minority_class_label = class_counts.idxmin()\n",
        "\n",
        "  # Filter rows with minority class label\n",
        "  minority_df = train_df[train_df.iloc[:, -1] == minority_class_label]\n",
        "\n",
        "  # Calculate counts of majority and minority classes\n",
        "  majority_count = class_counts.max()\n",
        "  minority_count = class_counts.min()\n",
        "\n",
        "  metadata_data = SingleTableMetadata()\n",
        "  metadata_data.detect_from_dataframe(minority_df)\n",
        "  # print(metadata_data)\n",
        "  # Generate synthetic data using GaussianCopulaSynthesizer\n",
        "  synthesizer_breast_data = GaussianCopulaSynthesizer(metadata_data)\n",
        "  synthesizer_breast_data.fit(minority_df)\n",
        "\n",
        "  # Print sample synthetic data\n",
        "  synthesizer_breast_data.reset_sampling()\n",
        "  sd1 = synthesizer_breast_data.sample(num_rows=majority_count-minority_count)\n",
        "  return sd1, train_df\n",
        "\n",
        "# Function to add synthetic data to the main DataFrame based on percentage\n",
        "def add_synthetic_data(main_df, synthetic_df, percentage, seed=42):\n",
        "    # Calculate number of rows to sample\n",
        "    num_rows = int(len(synthetic_df) * percentage)\n",
        "\n",
        "    # Sample the specified percentage of synthetic data\n",
        "    sampled_synthetic_data = synthetic_df.sample(n=num_rows, replace=False, random_state=seed)\n",
        "    # print(sampled_synthetic_data)\n",
        "\n",
        "    # Concatenate sampled synthetic data with main DataFrame\n",
        "    combined_df = pd.concat([main_df, sampled_synthetic_data], ignore_index=True)\n",
        "    # print(combined_df)\n",
        "    return combined_df"
      ],
      "metadata": {
        "id": "o9yiYbcN93gn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Over-Sampling"
      ],
      "metadata": {
        "id": "A3BmbGRgJ5Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def random_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = RandomOverSampler(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "bF2pvEGDJ704"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "TGGkRAzG15Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def smote_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = SMOTE(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "cF6biXPn125o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM-SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "QutsbBwdMujq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def svm_smote_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = SVMSMOTE(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "XwF74E6XMzG4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intelligent Pruning"
      ],
      "metadata": {
        "id": "x7qohyP7L0DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_majority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    max_label = max(zip(counts, labels))[1]\n",
        "    indices_with_max_label = np.where(y == max_label)[0]\n",
        "    X_maj, y_maj = X[indices_with_max_label], y[indices_with_max_label]\n",
        "\n",
        "    # Exclude majority class samples\n",
        "    indices_without_max_label = np.where(y != max_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_max_label], y[indices_without_max_label]\n",
        "\n",
        "    return X_maj, y_maj, X_remaining, y_remaining, min(counts)\n",
        "\n",
        "def do_clustering(X, y, labels):\n",
        "  clustered_X = defaultdict(list)\n",
        "  clustered_y = defaultdict(list)\n",
        "\n",
        "  for i, label in enumerate(labels):\n",
        "      clustered_X[label].append(X[i])\n",
        "      clustered_y[label].append(y[i])\n",
        "\n",
        "  # Sort clustered_X and clustered_y in descending order based on the length of values in each dictionary\n",
        "  sorted_clustered_X = dict(sorted(clustered_X.items(), key=lambda x: -len(x[1])))\n",
        "  sorted_clustered_y = dict(sorted(clustered_y.items(), key=lambda x: -len(x[1])))\n",
        "\n",
        "  return sorted_clustered_X, sorted_clustered_y\n",
        "\n",
        "\n",
        "def intelligent_prune_data(pruning_samps, pruning_ratios, clustered_X, clustered_y, per_cluster_pruning_ratio=0.7, seed=42):\n",
        "  random.seed(seed)\n",
        "  pruning_ratios_X_maj, pruning_ratios_y_maj = defaultdict(list), defaultdict(list)\n",
        "  for pruning_samp, pruning_ratio in zip(pruning_samps, pruning_ratios):\n",
        "    samps = 0\n",
        "    # print(\"For Pruning samps: \", pruning_samp)\n",
        "    prune_samps = pruning_samp\n",
        "    # print(prune_samps)\n",
        "    clustered_X_new = defaultdict(list)\n",
        "    clustered_y_new = defaultdict(list)\n",
        "    # Iterate over the sorted dictionaries\n",
        "    for label, values_X in clustered_X.items():\n",
        "        # Calculate the number of samples to prune\n",
        "        num_samples_to_prune = int(prune_samps * per_cluster_pruning_ratio)\n",
        "        if(num_samples_to_prune > len(values_X)):\n",
        "          num_samples_to_prune = len(values_X)//2\n",
        "          prune_samps -= num_samples_to_prune\n",
        "        else:\n",
        "          prune_samps -= num_samples_to_prune\n",
        "\n",
        "        # Randomly choose samples to prune\n",
        "        indices_to_prune = random.sample(range(len(values_X)), num_samples_to_prune)\n",
        "\n",
        "        # Prune the samples from clustered_X and clustered_y\n",
        "        clustered_X_new[label] = [values_X[i] for i in range(len(values_X)) if i not in indices_to_prune]\n",
        "        clustered_y_new[label] = [clustered_y[label][i] for i in range(len(clustered_y[label])) if i not in indices_to_prune]\n",
        "\n",
        "    iter = 0\n",
        "    while(prune_samps > 0):\n",
        "        if(iter>=100):\n",
        "          break\n",
        "        for label, values_X in clustered_X_new.items():\n",
        "          if(prune_samps <=0 or len(values_X) <= 0):\n",
        "            break\n",
        "          # print(len(values_X))\n",
        "          index_to_prune = random.sample(range(len(values_X)), 1)\n",
        "          clustered_X_new[label] = [values_X[i] for i in range(len(values_X)) if i not in index_to_prune]\n",
        "          clustered_y_new[label] = [clustered_y_new[label][i] for i in range(len(clustered_y_new[label])) if i not in index_to_prune]\n",
        "\n",
        "          prune_samps -= 1\n",
        "        iter += 1\n",
        "\n",
        "    for label in clustered_X_new:\n",
        "        pruning_ratios_X_maj[pruning_ratio].extend(clustered_X_new[label])\n",
        "        pruning_ratios_y_maj[pruning_ratio].extend(clustered_y_new[label])\n",
        "\n",
        "  return pruning_ratios_X_maj, pruning_ratios_y_maj\n",
        "\n",
        "def combine_data(pruning_ratios, pruning_ratios_X_maj, pruning_ratios_y_maj, X_remaining, y_remaining):\n",
        "\n",
        "  pruning_ratios_X, pruning_ratios_y = defaultdict(list), defaultdict(list)\n",
        "  for pruning_ratio in pruning_ratios:\n",
        "    pruning_ratios_X[pruning_ratio].extend(pruning_ratios_X_maj[pruning_ratio])\n",
        "    pruning_ratios_X[pruning_ratio].extend(X_remaining)\n",
        "\n",
        "    pruning_ratios_y[pruning_ratio].extend(pruning_ratios_y_maj[pruning_ratio])\n",
        "    pruning_ratios_y[pruning_ratio].extend(y_remaining)\n",
        "\n",
        "  return pruning_ratios_X, pruning_ratios_y\n",
        "\n",
        "def do_intelligent_pruning(X, y, ratio, per_cluster_pruning_ratio=0.7, seed=42):\n",
        "\n",
        "  X_maj, y_maj, X_remaining, y_remaining, min_class_samples = find_majority_data(X, y)\n",
        "  kmeans = KMeans(n_clusters=3, random_state = 42)\n",
        "  kmeans.fit(X_maj)\n",
        "  labels = kmeans.labels_\n",
        "  clustered_X, clustered_y = do_clustering(X_maj, y_maj, labels)\n",
        "\n",
        "  pruning_best = len(X_maj)-min_class_samples\n",
        "  pruning_samps = [int(pruning_best * ratio)]\n",
        "  pruning_ratios = [ratio]\n",
        "\n",
        "  pruning_ratios_X_maj, pruning_ratios_y_maj = intelligent_prune_data(pruning_samps, pruning_ratios, clustered_X, clustered_y, \\\n",
        "                                                                      per_cluster_pruning_ratio=per_cluster_pruning_ratio, seed=seed)\n",
        "\n",
        "  pruning_ratios_X, pruning_ratios_y = combine_data(pruning_ratios, pruning_ratios_X_maj, pruning_ratios_y_maj, X_remaining, y_remaining)\n",
        "\n",
        "  return list(pruning_ratios_X.values()), list(pruning_ratios_y.values())"
      ],
      "metadata": {
        "id": "w9_Pj009Lxp9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Pruning"
      ],
      "metadata": {
        "id": "yky--qnU6rg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "inputs:\n",
        "X: np.array\n",
        "y: np.array\n",
        "percentage: from 0% upto 100%, enter int value\n",
        "\"\"\"\n",
        "def random_prune_data(X, y, ratio, seed = 42):\n",
        "  # preprocessed_X, scaler, imputer = preprocess_data_train(X)\n",
        "  # preprocessed_X_test = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "  # X_train, y_train = preprocessed_X_train.to_numpy(), y_train.to_numpy()\n",
        "  # X_test, y_test = preprocessed_X_test.to_numpy(), y_test.to_numpy()\n",
        "  np.random.seed(seed)\n",
        "  labels_count = {}\n",
        "  labels = np.unique(y)\n",
        "  for label in labels:\n",
        "    labels_count[label] = np.count_nonzero(y == label)\n",
        "  max_label = min_label = labels[0]\n",
        "  for label in labels_count:\n",
        "    if labels_count[label] > labels_count[max_label]:\n",
        "      max_label = label\n",
        "    if labels_count[label] < labels_count[min_label]:\n",
        "      min_label = label\n",
        "\n",
        "  # print(\"Max\", max_label, labels_count[max_label])\n",
        "  # print(\"Min\", min_label, labels_count[min_label])\n",
        "\n",
        "  prune_counts = {}\n",
        "  prune_indexes = {}\n",
        "  for label in labels_count:\n",
        "    prune_counts[label] = labels_count[label] - labels_count[min_label]\n",
        "    prune_indexes[label] = np.where(y == label)[0]\n",
        "\n",
        "  prune_amount = int(ratio * sum(map(lambda x: x[1], prune_counts.items())))\n",
        "  prune_it = {}\n",
        "\n",
        "  while prune_amount > 0:\n",
        "    for label in labels:\n",
        "      if (len(prune_indexes[label]) - labels_count[min_label]) > 0 and prune_amount > 0:\n",
        "        random_index = np.random.choice(len(prune_indexes[label]))\n",
        "        random_item = prune_indexes[label][random_index]\n",
        "        prune_indexes[label] = np.delete(prune_indexes[label], random_index)\n",
        "        if prune_it.get(label, None) is None:\n",
        "          prune_it[label] = np.array([])\n",
        "        prune_it[label] = np.append(prune_it[label], [random_item])\n",
        "        prune_amount -= 1\n",
        "\n",
        "\n",
        "\n",
        "  formatted_indexes = np.array([])\n",
        "  for label in prune_indexes:\n",
        "    formatted_indexes = np.append(formatted_indexes, prune_indexes[label])\n",
        "  formatted_indexes = np.sort(formatted_indexes)\n",
        "  new_arr = np.array([np.int64(i) for i in formatted_indexes])\n",
        "\n",
        "  return X[new_arr], y[new_arr]"
      ],
      "metadata": {
        "id": "BtB6jqhZtRD0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratios = [ratio for ratio in np.arange(0.2, 1.1, 0.2)]"
      ],
      "metadata": {
        "id": "z0A-h4iX3J8p"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Intelligent Pruning"
      ],
      "metadata": {
        "id": "UY6hAjLw9fy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_intelligent_pruning = dict()\n",
        "per_cluster_pruning_ratios = [0.5, 0.7, 0.9, 1]\n",
        "\n",
        "for per_cluster_pruning_ratio in per_cluster_pruning_ratios:\n",
        "  print(f'For per-cluster pruning ratio {per_cluster_pruning_ratio}')\n",
        "  for ratio in ratios:\n",
        "    X_train_copy, y_train_copy = X_train.copy(), y_train.copy()\n",
        "\n",
        "    intelligent_pruned_X_train, intelligent_pruned_y_train = do_intelligent_pruning(X_train_copy.to_numpy(), y_train_copy.to_numpy(), ratio, per_cluster_pruning_ratio=per_cluster_pruning_ratio)\n",
        "\n",
        "    preprocessed_intelligent_pruned_X_train, scaler, imputer = preprocess_data_train((np.array(intelligent_pruned_X_train))[0])\n",
        "    preprocessed_X_test = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    intelligent_pruned_X_train, intelligent_pruned_y_train = preprocessed_intelligent_pruned_X_train, (np.array(intelligent_pruned_y_train))[0]\n",
        "    intelligent_pruned_X_test, intelligent_pruned_y_test = preprocessed_X_test, y_test.to_numpy()\n",
        "    print(f\"Train data pruned intelligently at {ratio * 100}% :\")\n",
        "    results = evaluate_models(intelligent_pruned_X_train, intelligent_pruned_X_test, intelligent_pruned_y_train, intelligent_pruned_y_test)\n",
        "    print(results)\n",
        "    results_intelligent_pruning[ratio] = results\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRV_KrPy9is0",
        "outputId": "964dac8b-d4f1-48d5-de8a-16352a609703"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For per-cluster pruning ratio 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 20.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.825, 'Precision': 0.6428571428571429, 'Recall': 0.574468085106383, 'F1 Score': 0.6067415730337079, 'ROC AUC': 0.8327075511055486, 'Confusion Matrix': array([[138,  15],\n",
            "       [ 20,  27]])}, 'SVM': {'Accuracy': 0.83, 'Precision': 0.7407407407407407, 'Recall': 0.425531914893617, 'F1 Score': 0.5405405405405406, 'ROC AUC': 0.8210262828535669, 'Confusion Matrix': array([[146,   7],\n",
            "       [ 27,  20]])}, 'Decision Tree': {'Accuracy': 0.815, 'Precision': 0.5961538461538461, 'Recall': 0.6595744680851063, 'F1 Score': 0.6262626262626262, 'ROC AUC': 0.761159783062161, 'Confusion Matrix': array([[132,  21],\n",
            "       [ 16,  31]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 40.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.805, 'Precision': 0.58, 'Recall': 0.6170212765957447, 'F1 Score': 0.5979381443298969, 'ROC AUC': 0.8236684744819914, 'Confusion Matrix': array([[132,  21],\n",
            "       [ 18,  29]])}, 'SVM': {'Accuracy': 0.84, 'Precision': 0.7142857142857143, 'Recall': 0.5319148936170213, 'F1 Score': 0.6097560975609756, 'ROC AUC': 0.8100403281880127, 'Confusion Matrix': array([[143,  10],\n",
            "       [ 22,  25]])}, 'Decision Tree': {'Accuracy': 0.785, 'Precision': 0.5370370370370371, 'Recall': 0.6170212765957447, 'F1 Score': 0.5742574257425743, 'ROC AUC': 0.7268112918926436, 'Confusion Matrix': array([[128,  25],\n",
            "       [ 18,  29]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 60.00000000000001% :\n",
            "{'Logistic Regression': {'Accuracy': 0.77, 'Precision': 0.5081967213114754, 'Recall': 0.6595744680851063, 'F1 Score': 0.5740740740740742, 'ROC AUC': 0.7940481157001809, 'Confusion Matrix': array([[123,  30],\n",
            "       [ 16,  31]])}, 'SVM': {'Accuracy': 0.82, 'Precision': 0.6170212765957447, 'Recall': 0.6170212765957447, 'F1 Score': 0.6170212765957447, 'ROC AUC': 0.8094840773188707, 'Confusion Matrix': array([[135,  18],\n",
            "       [ 18,  29]])}, 'Decision Tree': {'Accuracy': 0.75, 'Precision': 0.4805194805194805, 'Recall': 0.7872340425531915, 'F1 Score': 0.5967741935483871, 'ROC AUC': 0.7628980670282297, 'Confusion Matrix': array([[113,  40],\n",
            "       [ 10,  37]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 80.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.755, 'Precision': 0.48484848484848486, 'Recall': 0.6808510638297872, 'F1 Score': 0.5663716814159292, 'ROC AUC': 0.7978028090668892, 'Confusion Matrix': array([[119,  34],\n",
            "       [ 15,  32]])}, 'SVM': {'Accuracy': 0.81, 'Precision': 0.5918367346938775, 'Recall': 0.6170212765957447, 'F1 Score': 0.6041666666666666, 'ROC AUC': 0.8192184675288555, 'Confusion Matrix': array([[133,  20],\n",
            "       [ 18,  29]])}, 'Decision Tree': {'Accuracy': 0.715, 'Precision': 0.44047619047619047, 'Recall': 0.7872340425531915, 'F1 Score': 0.564885496183206, 'ROC AUC': 0.7400222500347656, 'Confusion Matrix': array([[106,  47],\n",
            "       [ 10,  37]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 100.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.745, 'Precision': 0.4722222222222222, 'Recall': 0.723404255319149, 'F1 Score': 0.5714285714285714, 'ROC AUC': 0.80086218884717, 'Confusion Matrix': array([[115,  38],\n",
            "       [ 13,  34]])}, 'SVM': {'Accuracy': 0.8, 'Precision': 0.5660377358490566, 'Recall': 0.6382978723404256, 'F1 Score': 0.6, 'ROC AUC': 0.8158809623140036, 'Confusion Matrix': array([[130,  23],\n",
            "       [ 17,  30]])}, 'Decision Tree': {'Accuracy': 0.65, 'Precision': 0.38144329896907214, 'Recall': 0.7872340425531915, 'F1 Score': 0.513888888888889, 'ROC AUC': 0.6975385899040467, 'Confusion Matrix': array([[93, 60],\n",
            "       [10, 37]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 20.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.82, 'Precision': 0.6341463414634146, 'Recall': 0.5531914893617021, 'F1 Score': 0.5909090909090909, 'ROC AUC': 0.8239465999165624, 'Confusion Matrix': array([[138,  15],\n",
            "       [ 21,  26]])}, 'SVM': {'Accuracy': 0.835, 'Precision': 0.7916666666666666, 'Recall': 0.40425531914893614, 'F1 Score': 0.5352112676056338, 'ROC AUC': 0.8190794048115699, 'Confusion Matrix': array([[148,   5],\n",
            "       [ 28,  19]])}, 'Decision Tree': {'Accuracy': 0.77, 'Precision': 0.5111111111111111, 'Recall': 0.48936170212765956, 'F1 Score': 0.5, 'ROC AUC': 0.6727854262272285, 'Confusion Matrix': array([[131,  22],\n",
            "       [ 24,  23]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 40.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.82, 'Precision': 0.627906976744186, 'Recall': 0.574468085106383, 'F1 Score': 0.6, 'ROC AUC': 0.799193436239744, 'Confusion Matrix': array([[137,  16],\n",
            "       [ 20,  27]])}, 'SVM': {'Accuracy': 0.84, 'Precision': 0.7586206896551724, 'Recall': 0.46808510638297873, 'F1 Score': 0.5789473684210527, 'ROC AUC': 0.8099012654707274, 'Confusion Matrix': array([[146,   7],\n",
            "       [ 25,  22]])}, 'Decision Tree': {'Accuracy': 0.79, 'Precision': 0.5471698113207547, 'Recall': 0.6170212765957447, 'F1 Score': 0.58, 'ROC AUC': 0.7300792657488528, 'Confusion Matrix': array([[129,  24],\n",
            "       [ 18,  29]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 60.00000000000001% :\n",
            "{'Logistic Regression': {'Accuracy': 0.78, 'Precision': 0.5283018867924528, 'Recall': 0.5957446808510638, 'F1 Score': 0.56, 'ROC AUC': 0.8078153247114448, 'Confusion Matrix': array([[128,  25],\n",
            "       [ 19,  28]])}, 'SVM': {'Accuracy': 0.84, 'Precision': 0.7027027027027027, 'Recall': 0.5531914893617021, 'F1 Score': 0.6190476190476191, 'ROC AUC': 0.8306216103462662, 'Confusion Matrix': array([[142,  11],\n",
            "       [ 21,  26]])}, 'Decision Tree': {'Accuracy': 0.76, 'Precision': 0.49295774647887325, 'Recall': 0.7446808510638298, 'F1 Score': 0.5932203389830508, 'ROC AUC': 0.7546933667083855, 'Confusion Matrix': array([[117,  36],\n",
            "       [ 12,  35]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 80.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.76, 'Precision': 0.49230769230769234, 'Recall': 0.6808510638297872, 'F1 Score': 0.5714285714285714, 'ROC AUC': 0.804199694062022, 'Confusion Matrix': array([[120,  33],\n",
            "       [ 15,  32]])}, 'SVM': {'Accuracy': 0.82, 'Precision': 0.6122448979591837, 'Recall': 0.6382978723404256, 'F1 Score': 0.625, 'ROC AUC': 0.8082325128633013, 'Confusion Matrix': array([[134,  19],\n",
            "       [ 17,  30]])}, 'Decision Tree': {'Accuracy': 0.67, 'Precision': 0.38823529411764707, 'Recall': 0.7021276595744681, 'F1 Score': 0.5, 'ROC AUC': 0.6811291892643583, 'Confusion Matrix': array([[101,  52],\n",
            "       [ 14,  33]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 100.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.73, 'Precision': 0.45569620253164556, 'Recall': 0.7659574468085106, 'F1 Score': 0.5714285714285715, 'ROC AUC': 0.7755527743012098, 'Confusion Matrix': array([[110,  43],\n",
            "       [ 11,  36]])}, 'SVM': {'Accuracy': 0.73, 'Precision': 0.4533333333333333, 'Recall': 0.723404255319149, 'F1 Score': 0.5573770491803279, 'ROC AUC': 0.8135168961201502, 'Confusion Matrix': array([[112,  41],\n",
            "       [ 13,  34]])}, 'Decision Tree': {'Accuracy': 0.68, 'Precision': 0.4, 'Recall': 0.723404255319149, 'F1 Score': 0.5151515151515151, 'ROC AUC': 0.6950354609929079, 'Confusion Matrix': array([[102,  51],\n",
            "       [ 13,  34]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 20.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.6153846153846154, 'Recall': 0.5106382978723404, 'F1 Score': 0.558139534883721, 'ROC AUC': 0.7925184258100403, 'Confusion Matrix': array([[138,  15],\n",
            "       [ 23,  24]])}, 'SVM': {'Accuracy': 0.825, 'Precision': 1.0, 'Recall': 0.2553191489361702, 'F1 Score': 0.4067796610169491, 'ROC AUC': 0.8161590877485747, 'Confusion Matrix': array([[153,   0],\n",
            "       [ 35,  12]])}, 'Decision Tree': {'Accuracy': 0.775, 'Precision': 0.5217391304347826, 'Recall': 0.5106382978723404, 'F1 Score': 0.5161290322580645, 'ROC AUC': 0.6834237240995689, 'Confusion Matrix': array([[131,  22],\n",
            "       [ 23,  24]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 40.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.805, 'Precision': 0.5952380952380952, 'Recall': 0.5319148936170213, 'F1 Score': 0.5617977528089887, 'ROC AUC': 0.7794465303852038, 'Confusion Matrix': array([[136,  17],\n",
            "       [ 22,  25]])}, 'SVM': {'Accuracy': 0.83, 'Precision': 0.782608695652174, 'Recall': 0.3829787234042553, 'F1 Score': 0.5142857142857143, 'ROC AUC': 0.8239465999165624, 'Confusion Matrix': array([[148,   5],\n",
            "       [ 29,  18]])}, 'Decision Tree': {'Accuracy': 0.775, 'Precision': 0.5208333333333334, 'Recall': 0.5319148936170213, 'F1 Score': 0.5263157894736842, 'ROC AUC': 0.6907940481157001, 'Confusion Matrix': array([[130,  23],\n",
            "       [ 22,  25]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 60.00000000000001% :\n",
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.6046511627906976, 'Recall': 0.5531914893617021, 'F1 Score': 0.5777777777777778, 'ROC AUC': 0.7813934084272007, 'Confusion Matrix': array([[136,  17],\n",
            "       [ 21,  26]])}, 'SVM': {'Accuracy': 0.835, 'Precision': 0.75, 'Recall': 0.44680851063829785, 'F1 Score': 0.56, 'ROC AUC': 0.8421638158809625, 'Confusion Matrix': array([[146,   7],\n",
            "       [ 26,  21]])}, 'Decision Tree': {'Accuracy': 0.75, 'Precision': 0.4727272727272727, 'Recall': 0.5531914893617021, 'F1 Score': 0.5098039215686275, 'ROC AUC': 0.6818245028507858, 'Confusion Matrix': array([[124,  29],\n",
            "       [ 21,  26]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 80.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.785, 'Precision': 0.5370370370370371, 'Recall': 0.6170212765957447, 'F1 Score': 0.5742574257425743, 'ROC AUC': 0.783757474621054, 'Confusion Matrix': array([[128,  25],\n",
            "       [ 18,  29]])}, 'SVM': {'Accuracy': 0.835, 'Precision': 0.6521739130434783, 'Recall': 0.6382978723404256, 'F1 Score': 0.6451612903225806, 'ROC AUC': 0.85551383674037, 'Confusion Matrix': array([[137,  16],\n",
            "       [ 17,  30]])}, 'Decision Tree': {'Accuracy': 0.73, 'Precision': 0.4507042253521127, 'Recall': 0.6808510638297872, 'F1 Score': 0.5423728813559323, 'ROC AUC': 0.7129745515227368, 'Confusion Matrix': array([[114,  39],\n",
            "       [ 15,  32]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 100.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.685, 'Precision': 0.4, 'Recall': 0.6808510638297872, 'F1 Score': 0.5039370078740157, 'ROC AUC': 0.7900152968989014, 'Confusion Matrix': array([[105,  48],\n",
            "       [ 15,  32]])}, 'SVM': {'Accuracy': 0.76, 'Precision': 0.4931506849315068, 'Recall': 0.7659574468085106, 'F1 Score': 0.6, 'ROC AUC': 0.7990543735224587, 'Confusion Matrix': array([[116,  37],\n",
            "       [ 11,  36]])}, 'Decision Tree': {'Accuracy': 0.685, 'Precision': 0.4024390243902439, 'Recall': 0.7021276595744681, 'F1 Score': 0.5116279069767442, 'ROC AUC': 0.6909331108329857, 'Confusion Matrix': array([[104,  49],\n",
            "       [ 14,  33]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 20.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.815, 'Precision': 0.625, 'Recall': 0.5319148936170213, 'F1 Score': 0.5747126436781609, 'ROC AUC': 0.7922403003754693, 'Confusion Matrix': array([[138,  15],\n",
            "       [ 22,  25]])}, 'SVM': {'Accuracy': 0.825, 'Precision': 1.0, 'Recall': 0.2553191489361702, 'F1 Score': 0.4067796610169491, 'ROC AUC': 0.8178278403560005, 'Confusion Matrix': array([[153,   0],\n",
            "       [ 35,  12]])}, 'Decision Tree': {'Accuracy': 0.74, 'Precision': 0.44680851063829785, 'Recall': 0.44680851063829785, 'F1 Score': 0.44680851063829785, 'ROC AUC': 0.6384369350577109, 'Confusion Matrix': array([[127,  26],\n",
            "       [ 26,  21]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 40.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.815, 'Precision': 0.625, 'Recall': 0.5319148936170213, 'F1 Score': 0.5747126436781609, 'ROC AUC': 0.7729105826727853, 'Confusion Matrix': array([[138,  15],\n",
            "       [ 22,  25]])}, 'SVM': {'Accuracy': 0.835, 'Precision': 0.85, 'Recall': 0.3617021276595745, 'F1 Score': 0.5074626865671642, 'ROC AUC': 0.819635655680712, 'Confusion Matrix': array([[150,   3],\n",
            "       [ 30,  17]])}, 'Decision Tree': {'Accuracy': 0.75, 'Precision': 0.4716981132075472, 'Recall': 0.5319148936170213, 'F1 Score': 0.4999999999999999, 'ROC AUC': 0.6744541788346544, 'Confusion Matrix': array([[125,  28],\n",
            "       [ 22,  25]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 60.00000000000001% :\n",
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.6046511627906976, 'Recall': 0.5531914893617021, 'F1 Score': 0.5777777777777778, 'ROC AUC': 0.7638715060492282, 'Confusion Matrix': array([[136,  17],\n",
            "       [ 21,  26]])}, 'SVM': {'Accuracy': 0.825, 'Precision': 0.7727272727272727, 'Recall': 0.3617021276595745, 'F1 Score': 0.4927536231884059, 'ROC AUC': 0.8324294256709777, 'Confusion Matrix': array([[148,   5],\n",
            "       [ 30,  17]])}, 'Decision Tree': {'Accuracy': 0.72, 'Precision': 0.42857142857142855, 'Recall': 0.574468085106383, 'F1 Score': 0.4909090909090909, 'ROC AUC': 0.6695869837296621, 'Confusion Matrix': array([[117,  36],\n",
            "       [ 20,  27]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 80.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.765, 'Precision': 0.5, 'Recall': 0.6382978723404256, 'F1 Score': 0.5607476635514019, 'ROC AUC': 0.784869976359338, 'Confusion Matrix': array([[123,  30],\n",
            "       [ 17,  30]])}, 'SVM': {'Accuracy': 0.8, 'Precision': 0.5853658536585366, 'Recall': 0.5106382978723404, 'F1 Score': 0.5454545454545454, 'ROC AUC': 0.8404950632735364, 'Confusion Matrix': array([[136,  17],\n",
            "       [ 23,  24]])}, 'Decision Tree': {'Accuracy': 0.72, 'Precision': 0.4262295081967213, 'Recall': 0.5531914893617021, 'F1 Score': 0.48148148148148145, 'ROC AUC': 0.6622166597135308, 'Confusion Matrix': array([[118,  35],\n",
            "       [ 21,  26]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 100.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.62, 'Precision': 0.34065934065934067, 'Recall': 0.6595744680851063, 'F1 Score': 0.4492753623188405, 'ROC AUC': 0.6907245167570575, 'Confusion Matrix': array([[93, 60],\n",
            "       [16, 31]])}, 'SVM': {'Accuracy': 0.625, 'Precision': 0.36792452830188677, 'Recall': 0.8297872340425532, 'F1 Score': 0.5098039215686274, 'ROC AUC': 0.7195104992351551, 'Confusion Matrix': array([[86, 67],\n",
            "       [ 8, 39]])}, 'Decision Tree': {'Accuracy': 0.645, 'Precision': 0.3695652173913043, 'Recall': 0.723404255319149, 'F1 Score': 0.4892086330935252, 'ROC AUC': 0.6721596439994437, 'Confusion Matrix': array([[95, 58],\n",
            "       [13, 34]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calling Random Pruning"
      ],
      "metadata": {
        "id": "uGrS3yXb-RYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_random_pruning = dict()\n",
        "for ratio in ratios:\n",
        "  random_pruned_X_train, random_pruned_y_train = random_prune_data(X_train.to_numpy(), y_train.to_numpy(), ratio)\n",
        "  preprocessed_random_pruned_X_train, scaler, imputer = preprocess_data_train(random_pruned_X_train)\n",
        "  preprocessed_X_test = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "  random_pruned_X_train, random_pruned_y_train = preprocessed_random_pruned_X_train, random_pruned_y_train\n",
        "  random_pruned_X_test, random_pruned_y_test = preprocessed_X_test, y_test.to_numpy()\n",
        "\n",
        "  print(f\"Train data pruned randomly at {ratio * 100}% :\")\n",
        "  results = evaluate_models(random_pruned_X_train, random_pruned_X_test, random_pruned_y_train, random_pruned_y_test)\n",
        "  print(results)\n",
        "  results_random_pruning[ratio] = results\n",
        "  print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "4od9tUcU-QI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0783ee17-2845-4094-f267-3b99675fbc39"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned randomly at 20.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.6216216216216216, 'Recall': 0.48936170212765956, 'F1 Score': 0.5476190476190476, 'ROC AUC': 0.7880684188569045, 'Confusion Matrix': array([[139,  14],\n",
            "       [ 24,  23]])}, 'SVM': {'Accuracy': 0.82, 'Precision': 0.7391304347826086, 'Recall': 0.3617021276595745, 'F1 Score': 0.4857142857142858, 'ROC AUC': 0.8142122097065776, 'Confusion Matrix': array([[147,   6],\n",
            "       [ 30,  17]])}, 'Decision Tree': {'Accuracy': 0.755, 'Precision': 0.4807692307692308, 'Recall': 0.5319148936170213, 'F1 Score': 0.505050505050505, 'ROC AUC': 0.6777221526908636, 'Confusion Matrix': array([[126,  27],\n",
            "       [ 22,  25]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 40.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.82, 'Precision': 0.6341463414634146, 'Recall': 0.5531914893617021, 'F1 Score': 0.5909090909090909, 'ROC AUC': 0.7683215130023641, 'Confusion Matrix': array([[138,  15],\n",
            "       [ 21,  26]])}, 'SVM': {'Accuracy': 0.825, 'Precision': 0.75, 'Recall': 0.3829787234042553, 'F1 Score': 0.5070422535211269, 'ROC AUC': 0.8308997357808372, 'Confusion Matrix': array([[147,   6],\n",
            "       [ 29,  18]])}, 'Decision Tree': {'Accuracy': 0.73, 'Precision': 0.4426229508196721, 'Recall': 0.574468085106383, 'F1 Score': 0.5, 'ROC AUC': 0.6761229314420804, 'Confusion Matrix': array([[119,  34],\n",
            "       [ 20,  27]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 60.00000000000001% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.79, 'Precision': 0.5510204081632653, 'Recall': 0.574468085106383, 'F1 Score': 0.5625, 'ROC AUC': 0.789598108747045, 'Confusion Matrix': array([[131,  22],\n",
            "       [ 20,  27]])}, 'SVM': {'Accuracy': 0.855, 'Precision': 0.78125, 'Recall': 0.5319148936170213, 'F1 Score': 0.6329113924050632, 'ROC AUC': 0.8374356834932555, 'Confusion Matrix': array([[146,   7],\n",
            "       [ 22,  25]])}, 'Decision Tree': {'Accuracy': 0.745, 'Precision': 0.4714285714285714, 'Recall': 0.7021276595744681, 'F1 Score': 0.5641025641025642, 'ROC AUC': 0.7301487971074955, 'Confusion Matrix': array([[116,  37],\n",
            "       [ 14,  33]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 80.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.78, 'Precision': 0.5263157894736842, 'Recall': 0.6382978723404256, 'F1 Score': 0.5769230769230769, 'ROC AUC': 0.8008621888471701, 'Confusion Matrix': array([[126,  27],\n",
            "       [ 17,  30]])}, 'SVM': {'Accuracy': 0.82, 'Precision': 0.627906976744186, 'Recall': 0.574468085106383, 'F1 Score': 0.6, 'ROC AUC': 0.8553747740230844, 'Confusion Matrix': array([[137,  16],\n",
            "       [ 20,  27]])}, 'Decision Tree': {'Accuracy': 0.735, 'Precision': 0.4605263157894737, 'Recall': 0.7446808510638298, 'F1 Score': 0.5691056910569106, 'ROC AUC': 0.7383534974273398, 'Confusion Matrix': array([[112,  41],\n",
            "       [ 12,  35]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 100.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.715, 'Precision': 0.43243243243243246, 'Recall': 0.6808510638297872, 'F1 Score': 0.5289256198347106, 'ROC AUC': 0.756223056598526, 'Confusion Matrix': array([[111,  42],\n",
            "       [ 15,  32]])}, 'SVM': {'Accuracy': 0.785, 'Precision': 0.5303030303030303, 'Recall': 0.7446808510638298, 'F1 Score': 0.6194690265486724, 'ROC AUC': 0.867890418578779, 'Confusion Matrix': array([[122,  31],\n",
            "       [ 12,  35]])}, 'Decision Tree': {'Accuracy': 0.665, 'Precision': 0.38095238095238093, 'Recall': 0.6808510638297872, 'F1 Score': 0.48854961832061056, 'ROC AUC': 0.6704908913920178, 'Confusion Matrix': array([[101,  52],\n",
            "       [ 15,  32]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SDV-Oversampling"
      ],
      "metadata": {
        "id": "f_VUTRHBBVDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sd1, train_df = do_sdv(X_train, y_train)\n",
        "results_syn_sdv = dict()\n",
        "\n",
        "# Add synthetic data at different percentages to the main DataFrame\n",
        "for ratio in ratios:\n",
        "    combined_df = add_synthetic_data(train_df, sd1, ratio)\n",
        "    y_train_sdv = combined_df.iloc[:, -1]\n",
        "    X_train_sdv = combined_df.iloc[:, :-1]\n",
        "\n",
        "    preprocessed_X_train_sdv, scaler, imputer = preprocess_data_train(X_train_sdv)\n",
        "    preprocessed_X_test_sdv = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_sdv, y_train_sdv = preprocessed_X_train_sdv, y_train_sdv.to_numpy()\n",
        "    X_test_sdv, y_test_sdv = preprocessed_X_test_sdv, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    results = evaluate_models(X_train_sdv, X_test_sdv, y_train_sdv, y_test_sdv)\n",
        "    results_syn_sdv[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "g4V6WxpY9kbd",
        "outputId": "259c0266-8731-40e8-9a66-ab1e94ce842f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sdv/single_table/base.py:80: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.825, 'Precision': 0.6764705882352942, 'Recall': 0.48936170212765956, 'F1 Score': 0.5679012345679013, 'ROC AUC': 0.8003059379780281, 'Confusion Matrix': array([[142,  11],\n",
            "       [ 24,  23]])}, 'SVM': {'Accuracy': 0.835, 'Precision': 0.8888888888888888, 'Recall': 0.3404255319148936, 'F1 Score': 0.4923076923076923, 'ROC AUC': 0.822138784591851, 'Confusion Matrix': array([[151,   2],\n",
            "       [ 31,  16]])}, 'Decision Tree': {'Accuracy': 0.78, 'Precision': 0.5294117647058824, 'Recall': 0.574468085106383, 'F1 Score': 0.5510204081632654, 'ROC AUC': 0.708802670004172, 'Confusion Matrix': array([[129,  24],\n",
            "       [ 20,  27]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.825, 'Precision': 0.6764705882352942, 'Recall': 0.48936170212765956, 'F1 Score': 0.5679012345679013, 'ROC AUC': 0.8037825059101655, 'Confusion Matrix': array([[142,  11],\n",
            "       [ 24,  23]])}, 'SVM': {'Accuracy': 0.835, 'Precision': 0.8888888888888888, 'Recall': 0.3404255319148936, 'F1 Score': 0.4923076923076923, 'ROC AUC': 0.816854401335002, 'Confusion Matrix': array([[151,   2],\n",
            "       [ 31,  16]])}, 'Decision Tree': {'Accuracy': 0.74, 'Precision': 0.45614035087719296, 'Recall': 0.5531914893617021, 'F1 Score': 0.5, 'ROC AUC': 0.6752885551383675, 'Confusion Matrix': array([[122,  31],\n",
            "       [ 21,  26]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.83, 'Precision': 0.696969696969697, 'Recall': 0.48936170212765956, 'F1 Score': 0.575, 'ROC AUC': 0.8032262550410236, 'Confusion Matrix': array([[143,  10],\n",
            "       [ 24,  23]])}, 'SVM': {'Accuracy': 0.835, 'Precision': 0.8888888888888888, 'Recall': 0.3404255319148936, 'F1 Score': 0.4923076923076923, 'ROC AUC': 0.817410652204144, 'Confusion Matrix': array([[151,   2],\n",
            "       [ 31,  16]])}, 'Decision Tree': {'Accuracy': 0.74, 'Precision': 0.45614035087719296, 'Recall': 0.5531914893617021, 'F1 Score': 0.5, 'ROC AUC': 0.6752885551383675, 'Confusion Matrix': array([[122,  31],\n",
            "       [ 21,  26]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.825, 'Precision': 0.6764705882352942, 'Recall': 0.48936170212765956, 'F1 Score': 0.5679012345679013, 'ROC AUC': 0.8029481296064525, 'Confusion Matrix': array([[142,  11],\n",
            "       [ 24,  23]])}, 'SVM': {'Accuracy': 0.835, 'Precision': 0.8888888888888888, 'Recall': 0.3404255319148936, 'F1 Score': 0.4923076923076923, 'ROC AUC': 0.8144903351411485, 'Confusion Matrix': array([[151,   2],\n",
            "       [ 31,  16]])}, 'Decision Tree': {'Accuracy': 0.74, 'Precision': 0.45614035087719296, 'Recall': 0.5531914893617021, 'F1 Score': 0.5, 'ROC AUC': 0.6752885551383675, 'Confusion Matrix': array([[122,  31],\n",
            "       [ 21,  26]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.83, 'Precision': 0.696969696969697, 'Recall': 0.48936170212765956, 'F1 Score': 0.575, 'ROC AUC': 0.80364344319288, 'Confusion Matrix': array([[143,  10],\n",
            "       [ 24,  23]])}, 'SVM': {'Accuracy': 0.835, 'Precision': 0.8888888888888888, 'Recall': 0.3404255319148936, 'F1 Score': 0.4923076923076923, 'ROC AUC': 0.8124043943818662, 'Confusion Matrix': array([[151,   2],\n",
            "       [ 31,  16]])}, 'Decision Tree': {'Accuracy': 0.74, 'Precision': 0.45614035087719296, 'Recall': 0.5531914893617021, 'F1 Score': 0.5, 'ROC AUC': 0.6752885551383675, 'Confusion Matrix': array([[122,  31],\n",
            "       [ 21,  26]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SMOTE-Oversampling"
      ],
      "metadata": {
        "id": "l78jR_BuCw1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_smote = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_smote, y_train_smote = smote_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "    preprocessed_X_train_smote, scaler, imputer = preprocess_data_train((np.array(X_train_smote))[0])\n",
        "    preprocessed_X_test_smote = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_smote, y_train_smote = preprocessed_X_train_smote, (np.array(y_train_smote))[0]\n",
        "    X_test_smote, y_test_smote = preprocessed_X_test_smote, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_smote), len(y_train_smote))\n",
        "    results = evaluate_models(X_train_smote, X_test_smote, y_train_smote, y_test_smote)\n",
        "    results_smote[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "X7S78dnHC0bw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1399e380-d761-4670-8c04-c895e59998a2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "892 892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.6097560975609756, 'Recall': 0.5319148936170213, 'F1 Score': 0.5681818181818181, 'ROC AUC': 0.7844527882074815, 'Confusion Matrix': array([[137,  16],\n",
            "       [ 22,  25]])}, 'SVM': {'Accuracy': 0.825, 'Precision': 0.7727272727272727, 'Recall': 0.3617021276595745, 'F1 Score': 0.4927536231884059, 'ROC AUC': 0.8468919482686692, 'Confusion Matrix': array([[148,   5],\n",
            "       [ 30,  17]])}, 'Decision Tree': {'Accuracy': 0.79, 'Precision': 0.5510204081632653, 'Recall': 0.574468085106383, 'F1 Score': 0.5625, 'ROC AUC': 0.7153386177165902, 'Confusion Matrix': array([[131,  22],\n",
            "       [ 20,  27]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "988 988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.78, 'Precision': 0.5283018867924528, 'Recall': 0.5957446808510638, 'F1 Score': 0.56, 'ROC AUC': 0.7832012237519121, 'Confusion Matrix': array([[128,  25],\n",
            "       [ 19,  28]])}, 'SVM': {'Accuracy': 0.835, 'Precision': 0.71875, 'Recall': 0.48936170212765956, 'F1 Score': 0.5822784810126582, 'ROC AUC': 0.84995132804895, 'Confusion Matrix': array([[144,   9],\n",
            "       [ 24,  23]])}, 'Decision Tree': {'Accuracy': 0.8, 'Precision': 0.574468085106383, 'Recall': 0.574468085106383, 'F1 Score': 0.574468085106383, 'ROC AUC': 0.7218745654290085, 'Confusion Matrix': array([[133,  20],\n",
            "       [ 20,  27]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "1084 1084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.755, 'Precision': 0.4827586206896552, 'Recall': 0.5957446808510638, 'F1 Score': 0.5333333333333333, 'ROC AUC': 0.7805590321234877, 'Confusion Matrix': array([[123,  30],\n",
            "       [ 19,  28]])}, 'SVM': {'Accuracy': 0.81, 'Precision': 0.6097560975609756, 'Recall': 0.5319148936170213, 'F1 Score': 0.5681818181818181, 'ROC AUC': 0.8448060075093868, 'Confusion Matrix': array([[137,  16],\n",
            "       [ 22,  25]])}, 'Decision Tree': {'Accuracy': 0.79, 'Precision': 0.5555555555555556, 'Recall': 0.5319148936170213, 'F1 Score': 0.5434782608695652, 'ROC AUC': 0.7005979696843276, 'Confusion Matrix': array([[133,  20],\n",
            "       [ 22,  25]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "1180 1180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.75, 'Precision': 0.47540983606557374, 'Recall': 0.6170212765957447, 'F1 Score': 0.537037037037037, 'ROC AUC': 0.7820887220136282, 'Confusion Matrix': array([[121,  32],\n",
            "       [ 18,  29]])}, 'SVM': {'Accuracy': 0.805, 'Precision': 0.5769230769230769, 'Recall': 0.6382978723404256, 'F1 Score': 0.6060606060606061, 'ROC AUC': 0.8381309970796829, 'Confusion Matrix': array([[131,  22],\n",
            "       [ 17,  30]])}, 'Decision Tree': {'Accuracy': 0.76, 'Precision': 0.49019607843137253, 'Recall': 0.5319148936170213, 'F1 Score': 0.5102040816326531, 'ROC AUC': 0.6809901265470727, 'Confusion Matrix': array([[127,  26],\n",
            "       [ 22,  25]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "1276 1276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.73, 'Precision': 0.4492753623188406, 'Recall': 0.6595744680851063, 'F1 Score': 0.5344827586206896, 'ROC AUC': 0.7854262272284801, 'Confusion Matrix': array([[115,  38],\n",
            "       [ 16,  31]])}, 'SVM': {'Accuracy': 0.745, 'Precision': 0.4696969696969697, 'Recall': 0.6595744680851063, 'F1 Score': 0.5486725663716814, 'ROC AUC': 0.8174106522041441, 'Confusion Matrix': array([[118,  35],\n",
            "       [ 16,  31]])}, 'Decision Tree': {'Accuracy': 0.735, 'Precision': 0.44642857142857145, 'Recall': 0.5319148936170213, 'F1 Score': 0.48543689320388356, 'ROC AUC': 0.664650257266027, 'Confusion Matrix': array([[122,  31],\n",
            "       [ 22,  25]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Random-Oversampling"
      ],
      "metadata": {
        "id": "KKwGBPjpKrJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_random = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_random, y_train_random = random_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "\n",
        "    preprocessed_X_train_random, scaler, imputer = preprocess_data_train((np.array(X_train_random)[0]))\n",
        "    preprocessed_X_test_random = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_random, y_train_random = preprocessed_X_train_random, (np.array(y_train_random))[0]\n",
        "    X_test_random, y_test_random = preprocessed_X_test_random, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_random), len(y_train_random))\n",
        "    results = evaluate_models(X_train_random, X_test_random, y_train_random, y_test_random)\n",
        "    results_random[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "LC2kVR1tKtFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c17eafb-46c0-4335-e867-1a5b1152db41"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "892 892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.6046511627906976, 'Recall': 0.5531914893617021, 'F1 Score': 0.5777777777777778, 'ROC AUC': 0.8073981365595885, 'Confusion Matrix': array([[136,  17],\n",
            "       [ 21,  26]])}, 'SVM': {'Accuracy': 0.835, 'Precision': 0.8181818181818182, 'Recall': 0.3829787234042553, 'F1 Score': 0.5217391304347826, 'ROC AUC': 0.8428591294673897, 'Confusion Matrix': array([[149,   4],\n",
            "       [ 29,  18]])}, 'Decision Tree': {'Accuracy': 0.785, 'Precision': 0.5476190476190477, 'Recall': 0.48936170212765956, 'F1 Score': 0.5168539325842697, 'ROC AUC': 0.6825893477958559, 'Confusion Matrix': array([[134,  19],\n",
            "       [ 24,  23]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "988 988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8, 'Precision': 0.574468085106383, 'Recall': 0.574468085106383, 'F1 Score': 0.574468085106383, 'ROC AUC': 0.7978028090668892, 'Confusion Matrix': array([[133,  20],\n",
            "       [ 20,  27]])}, 'SVM': {'Accuracy': 0.825, 'Precision': 0.6578947368421053, 'Recall': 0.5319148936170213, 'F1 Score': 0.5882352941176471, 'ROC AUC': 0.8573216520650813, 'Confusion Matrix': array([[140,  13],\n",
            "       [ 22,  25]])}, 'Decision Tree': {'Accuracy': 0.76, 'Precision': 0.4883720930232558, 'Recall': 0.44680851063829785, 'F1 Score': 0.4666666666666666, 'ROC AUC': 0.6515088304825476, 'Confusion Matrix': array([[131,  22],\n",
            "       [ 26,  21]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "1084 1084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.765, 'Precision': 0.5, 'Recall': 0.574468085106383, 'F1 Score': 0.5346534653465347, 'ROC AUC': 0.7848699763593382, 'Confusion Matrix': array([[126,  27],\n",
            "       [ 20,  27]])}, 'SVM': {'Accuracy': 0.805, 'Precision': 0.5833333333333334, 'Recall': 0.5957446808510638, 'F1 Score': 0.5894736842105263, 'ROC AUC': 0.8450841329439577, 'Confusion Matrix': array([[133,  20],\n",
            "       [ 19,  28]])}, 'Decision Tree': {'Accuracy': 0.715, 'Precision': 0.391304347826087, 'Recall': 0.3829787234042553, 'F1 Score': 0.3870967741935484, 'ROC AUC': 0.5999860937282714, 'Confusion Matrix': array([[125,  28],\n",
            "       [ 29,  18]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "1180 1180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.75, 'Precision': 0.47619047619047616, 'Recall': 0.6382978723404256, 'F1 Score': 0.5454545454545455, 'ROC AUC': 0.7900152968989014, 'Confusion Matrix': array([[120,  33],\n",
            "       [ 17,  30]])}, 'SVM': {'Accuracy': 0.8, 'Precision': 0.5614035087719298, 'Recall': 0.6808510638297872, 'F1 Score': 0.6153846153846153, 'ROC AUC': 0.8453622583785287, 'Confusion Matrix': array([[128,  25],\n",
            "       [ 15,  32]])}, 'Decision Tree': {'Accuracy': 0.745, 'Precision': 0.45652173913043476, 'Recall': 0.44680851063829785, 'F1 Score': 0.45161290322580644, 'ROC AUC': 0.6417049089139202, 'Confusion Matrix': array([[128,  25],\n",
            "       [ 26,  21]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "1276 1276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.73, 'Precision': 0.4492753623188406, 'Recall': 0.6595744680851063, 'F1 Score': 0.5344827586206896, 'ROC AUC': 0.7825059101654848, 'Confusion Matrix': array([[115,  38],\n",
            "       [ 16,  31]])}, 'SVM': {'Accuracy': 0.78, 'Precision': 0.5238095238095238, 'Recall': 0.7021276595744681, 'F1 Score': 0.6, 'ROC AUC': 0.838687247948825, 'Confusion Matrix': array([[123,  30],\n",
            "       [ 14,  33]])}, 'Decision Tree': {'Accuracy': 0.775, 'Precision': 0.5238095238095238, 'Recall': 0.46808510638297873, 'F1 Score': 0.49438202247191015, 'ROC AUC': 0.6686830760673064, 'Confusion Matrix': array([[133,  20],\n",
            "       [ 25,  22]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SVM-SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "28Pi8n0HM4vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_svm_smote = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_svm_smote, y_train_svm_smote = svm_smote_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "\n",
        "    preprocessed_X_train_svm_smote, scaler, imputer = preprocess_data_train((np.array(X_train_svm_smote))[0])\n",
        "    preprocessed_X_test_svm_smote = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_svm_smote, y_train_svm_smote = preprocessed_X_train_svm_smote, (np.array(y_train_svm_smote))[0]\n",
        "    X_test_svm_smote, y_test_svm_smote = preprocessed_X_test_svm_smote, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_svm_smote), len(y_train_svm_smote))\n",
        "    results = evaluate_models(X_train_svm_smote, X_test_svm_smote, y_train_svm_smote, y_test_svm_smote)\n",
        "    results_svm_smote[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "8vkEOubrM81F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae2c60c3-beba-4d2d-cb85-b92546623a4b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "892 892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.6097560975609756, 'Recall': 0.5319148936170213, 'F1 Score': 0.5681818181818181, 'ROC AUC': 0.7955778055903213, 'Confusion Matrix': array([[137,  16],\n",
            "       [ 22,  25]])}, 'SVM': {'Accuracy': 0.85, 'Precision': 0.8148148148148148, 'Recall': 0.46808510638297873, 'F1 Score': 0.5945945945945945, 'ROC AUC': 0.8438325684883883, 'Confusion Matrix': array([[148,   5],\n",
            "       [ 25,  22]])}, 'Decision Tree': {'Accuracy': 0.765, 'Precision': 0.5, 'Recall': 0.574468085106383, 'F1 Score': 0.5346534653465347, 'ROC AUC': 0.6989987484355444, 'Confusion Matrix': array([[126,  27],\n",
            "       [ 20,  27]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "988 988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.6, 'Recall': 0.574468085106383, 'F1 Score': 0.5869565217391305, 'ROC AUC': 0.8117090807954388, 'Confusion Matrix': array([[135,  18],\n",
            "       [ 20,  27]])}, 'SVM': {'Accuracy': 0.855, 'Precision': 0.8, 'Recall': 0.5106382978723404, 'F1 Score': 0.6233766233766233, 'ROC AUC': 0.8584341538033653, 'Confusion Matrix': array([[147,   6],\n",
            "       [ 23,  24]])}, 'Decision Tree': {'Accuracy': 0.79, 'Precision': 0.5531914893617021, 'Recall': 0.5531914893617021, 'F1 Score': 0.5531914893617021, 'ROC AUC': 0.707968293700459, 'Confusion Matrix': array([[132,  21],\n",
            "       [ 21,  26]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "1084 1084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.79, 'Precision': 0.5510204081632653, 'Recall': 0.574468085106383, 'F1 Score': 0.5625, 'ROC AUC': 0.8032262550410235, 'Confusion Matrix': array([[131,  22],\n",
            "       [ 20,  27]])}, 'SVM': {'Accuracy': 0.845, 'Precision': 0.7222222222222222, 'Recall': 0.5531914893617021, 'F1 Score': 0.6265060240963856, 'ROC AUC': 0.852454456960089, 'Confusion Matrix': array([[143,  10],\n",
            "       [ 21,  26]])}, 'Decision Tree': {'Accuracy': 0.77, 'Precision': 0.5121951219512195, 'Recall': 0.44680851063829785, 'F1 Score': 0.4772727272727273, 'ROC AUC': 0.6580447781949659, 'Confusion Matrix': array([[133,  20],\n",
            "       [ 26,  21]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "1180 1180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.78, 'Precision': 0.5306122448979592, 'Recall': 0.5531914893617021, 'F1 Score': 0.5416666666666667, 'ROC AUC': 0.7902934223334724, 'Confusion Matrix': array([[130,  23],\n",
            "       [ 21,  26]])}, 'SVM': {'Accuracy': 0.82, 'Precision': 0.6341463414634146, 'Recall': 0.5531914893617021, 'F1 Score': 0.5909090909090909, 'ROC AUC': 0.8514810179390906, 'Confusion Matrix': array([[138,  15],\n",
            "       [ 21,  26]])}, 'Decision Tree': {'Accuracy': 0.765, 'Precision': 0.5, 'Recall': 0.5957446808510638, 'F1 Score': 0.5436893203883495, 'ROC AUC': 0.7063690724516757, 'Confusion Matrix': array([[125,  28],\n",
            "       [ 19,  28]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "1276 1276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.755, 'Precision': 0.48214285714285715, 'Recall': 0.574468085106383, 'F1 Score': 0.5242718446601942, 'ROC AUC': 0.7900152968989015, 'Confusion Matrix': array([[124,  29],\n",
            "       [ 20,  27]])}, 'SVM': {'Accuracy': 0.81, 'Precision': 0.5918367346938775, 'Recall': 0.6170212765957447, 'F1 Score': 0.6041666666666666, 'ROC AUC': 0.8475872618550967, 'Confusion Matrix': array([[133,  20],\n",
            "       [ 18,  29]])}, 'Decision Tree': {'Accuracy': 0.715, 'Precision': 0.41935483870967744, 'Recall': 0.5531914893617021, 'F1 Score': 0.47706422018348627, 'ROC AUC': 0.6589486858573217, 'Confusion Matrix': array([[117,  36],\n",
            "       [ 21,  26]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No-Sampling Results"
      ],
      "metadata": {
        "id": "v7igNZJnja1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_no_sampling = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_no_sampling, y_train_no_sampling = X_train.to_numpy(), y_train.to_numpy()\n",
        "\n",
        "    preprocessed_X_train_no_sampling, scaler, imputer = preprocess_data_train(X_train_no_sampling)\n",
        "    preprocessed_X_test_no_sampling = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_no_sampling, y_train_no_sampling = preprocessed_X_train_no_sampling, y_train_no_sampling\n",
        "    X_test_no_sampling, y_test_no_sampling = preprocessed_X_test_no_sampling, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_no_sampling), len(y_train_no_sampling))\n",
        "    results = evaluate_models(X_train_no_sampling, X_test_no_sampling, y_train_no_sampling, y_test_no_sampling)\n",
        "    results_no_sampling[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "pkbztvKijXEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a790e0c-9687-4826-a371-1a71bd6a7796"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "797 797\n",
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.6285714285714286, 'Recall': 0.46808510638297873, 'F1 Score': 0.5365853658536586, 'ROC AUC': 0.7968293700458907, 'Confusion Matrix': array([[140,  13],\n",
            "       [ 25,  22]])}, 'SVM': {'Accuracy': 0.82, 'Precision': 1.0, 'Recall': 0.23404255319148937, 'F1 Score': 0.3793103448275862, 'ROC AUC': 0.8115700180781532, 'Confusion Matrix': array([[153,   0],\n",
            "       [ 36,  11]])}, 'Decision Tree': {'Accuracy': 0.78, 'Precision': 0.5306122448979592, 'Recall': 0.5531914893617021, 'F1 Score': 0.5416666666666667, 'ROC AUC': 0.7014323459880406, 'Confusion Matrix': array([[130,  23],\n",
            "       [ 21,  26]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "797 797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.6285714285714286, 'Recall': 0.46808510638297873, 'F1 Score': 0.5365853658536586, 'ROC AUC': 0.7968293700458907, 'Confusion Matrix': array([[140,  13],\n",
            "       [ 25,  22]])}, 'SVM': {'Accuracy': 0.82, 'Precision': 1.0, 'Recall': 0.23404255319148937, 'F1 Score': 0.3793103448275862, 'ROC AUC': 0.8115700180781532, 'Confusion Matrix': array([[153,   0],\n",
            "       [ 36,  11]])}, 'Decision Tree': {'Accuracy': 0.78, 'Precision': 0.5306122448979592, 'Recall': 0.5531914893617021, 'F1 Score': 0.5416666666666667, 'ROC AUC': 0.7014323459880406, 'Confusion Matrix': array([[130,  23],\n",
            "       [ 21,  26]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "797 797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.6285714285714286, 'Recall': 0.46808510638297873, 'F1 Score': 0.5365853658536586, 'ROC AUC': 0.7968293700458907, 'Confusion Matrix': array([[140,  13],\n",
            "       [ 25,  22]])}, 'SVM': {'Accuracy': 0.82, 'Precision': 1.0, 'Recall': 0.23404255319148937, 'F1 Score': 0.3793103448275862, 'ROC AUC': 0.8115700180781532, 'Confusion Matrix': array([[153,   0],\n",
            "       [ 36,  11]])}, 'Decision Tree': {'Accuracy': 0.78, 'Precision': 0.5306122448979592, 'Recall': 0.5531914893617021, 'F1 Score': 0.5416666666666667, 'ROC AUC': 0.7014323459880406, 'Confusion Matrix': array([[130,  23],\n",
            "       [ 21,  26]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "797 797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.6285714285714286, 'Recall': 0.46808510638297873, 'F1 Score': 0.5365853658536586, 'ROC AUC': 0.7968293700458907, 'Confusion Matrix': array([[140,  13],\n",
            "       [ 25,  22]])}, 'SVM': {'Accuracy': 0.82, 'Precision': 1.0, 'Recall': 0.23404255319148937, 'F1 Score': 0.3793103448275862, 'ROC AUC': 0.8115700180781532, 'Confusion Matrix': array([[153,   0],\n",
            "       [ 36,  11]])}, 'Decision Tree': {'Accuracy': 0.78, 'Precision': 0.5306122448979592, 'Recall': 0.5531914893617021, 'F1 Score': 0.5416666666666667, 'ROC AUC': 0.7014323459880406, 'Confusion Matrix': array([[130,  23],\n",
            "       [ 21,  26]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "797 797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.81, 'Precision': 0.6285714285714286, 'Recall': 0.46808510638297873, 'F1 Score': 0.5365853658536586, 'ROC AUC': 0.7968293700458907, 'Confusion Matrix': array([[140,  13],\n",
            "       [ 25,  22]])}, 'SVM': {'Accuracy': 0.82, 'Precision': 1.0, 'Recall': 0.23404255319148937, 'F1 Score': 0.3793103448275862, 'ROC AUC': 0.8115700180781532, 'Confusion Matrix': array([[153,   0],\n",
            "       [ 36,  11]])}, 'Decision Tree': {'Accuracy': 0.78, 'Precision': 0.5306122448979592, 'Recall': 0.5531914893617021, 'F1 Score': 0.5416666666666667, 'ROC AUC': 0.7014323459880406, 'Confusion Matrix': array([[130,  23],\n",
            "       [ 21,  26]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adipai/data-decent/blob/main/js_vuln_sampling_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "jUSzegeVFEKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sdv"
      ],
      "metadata": {
        "id": "COAFe5iG-02V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install DataSynthesizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBcGtW-pIGJ4",
        "outputId": "ce4b8ad3-9b4a-4869-ac4e-6468714299f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting DataSynthesizer\n",
            "  Downloading DataSynthesizer-0.1.13-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (3.7.1)\n",
            "Requirement already satisfied: seaborn>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (0.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from DataSynthesizer) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->DataSynthesizer) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->DataSynthesizer) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->DataSynthesizer) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->DataSynthesizer) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->DataSynthesizer) (3.4.0)\n",
            "Installing collected packages: DataSynthesizer\n",
            "Successfully installed DataSynthesizer-0.1.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All imports here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import time\n",
        "from scipy.io import arff\n",
        "from sdv.datasets.local import load_csvs\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sdv.single_table import GaussianCopulaSynthesizer\n",
        "from DataSynthesizer.DataDescriber import DataDescriber\n",
        "from DataSynthesizer.DataGenerator import DataGenerator\n",
        "from DataSynthesizer.lib.utils import display_bayesian_network\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix"
      ],
      "metadata": {
        "id": "Lza8MeLYchI2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "KH_s6WhMv_Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data_train(X_train):\n",
        "    # Count missing values before handling missing data\n",
        "    missing_before = np.isnan(X_train).sum()\n",
        "\n",
        "    # Handle missing data\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "\n",
        "    # Count missing values after handling missing data\n",
        "    missing_after = np.isnan(X_train).sum()\n",
        "\n",
        "    # Normalize numeric columns\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "    return X_train, scaler, imputer\n",
        "\n",
        "def preprocess_data_test(X_test, scaler, imputer):\n",
        "    # Count missing values before handling missing data\n",
        "    missing_before = np.isnan(X_test).sum()\n",
        "\n",
        "    # Handle missing data\n",
        "    X_test = imputer.transform(X_test)\n",
        "\n",
        "    # Count missing values after handling missing data\n",
        "    missing_after = np.isnan(X_test).sum()\n",
        "\n",
        "    # Normalize numeric columns\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_test"
      ],
      "metadata": {
        "id": "A9ept3j9vmUy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "3Rjlt8zr4vyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset : JavaScript Vulnerbalities"
      ],
      "metadata": {
        "id": "p22RSGg043d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = f\"data/JavaScript_Vulnerability/JSVulnerabilityDataSet-1.0.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "drop_columns = [\"name\", \"longname\", \"path\", \"full_repo_path\", \"line\", \"column\", \"endline\", \"endcolumn\"]\n",
        "df = df.drop(drop_columns, axis=1)\n",
        "print(\"before drop duplicates\", df.shape[0])\n",
        "df = df.drop_duplicates()\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "print(\"after drop duplicates\", df.shape[0])\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyi4iWJFwIhU",
        "outputId": "0617a139-382b-4cc1-e463-7d4d4a52d135"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before drop duplicates 12125\n",
            "after drop duplicates 6271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and testing using ML models"
      ],
      "metadata": {
        "id": "gGu1Qxej4WAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic function to test synthetic data using LR, SVM, DT\n",
        "\n",
        "def evaluate_models(X_train, X_test, y_train, y_test, random_state=42):\n",
        "\n",
        "    # Initialize classifiers\n",
        "    classifiers = {\n",
        "        \"Logistic Regression\": LogisticRegression(random_state=random_state),\n",
        "        \"SVM\": SVC(random_state=random_state),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(random_state=random_state)\n",
        "    }\n",
        "\n",
        "    # Results dictionary to store evaluation metrics\n",
        "    results = {}\n",
        "\n",
        "    # Iterate over classifiers\n",
        "    for name, clf in classifiers.items():\n",
        "        # Fit classifier\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Predictions\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Evaluation metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        # AUC-ROC\n",
        "        if hasattr(clf, \"predict_proba\"):\n",
        "            y_prob = clf.predict_proba(X_test)[:,1]\n",
        "        else:\n",
        "            y_prob = clf.decision_function(X_test)\n",
        "        fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Store results\n",
        "        results[name] = {\n",
        "            \"Accuracy\": accuracy,\n",
        "            \"Precision\": precision,\n",
        "            \"Recall\": recall,\n",
        "            \"F1 Score\": f1,\n",
        "            \"ROC AUC\": roc_auc,\n",
        "            \"Confusion Matrix\": cm\n",
        "        }\n",
        "\n",
        "        # Plot AUC-ROC curve\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'{name} - AUC-ROC Curve')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.savefig(f'{name}_auc_roc_curve.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title(f'{name} - Confusion Matrix')\n",
        "        plt.savefig(f'{name}_confusion_matrix.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "SULk39gP2SUj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate_models(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "adNKyUsSLi6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e768e23-8cae-4532-8658-f7a61c04d652"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAAzoxMlLpjk",
        "outputId": "776e9a52-0fa5-4ab9-a77a-2d458f8a76f6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8940239043824701, 'Precision': 0.8428571428571429, 'Recall': 0.3259668508287293, 'F1 Score': 0.47011952191235057, 'ROC AUC': 0.6766129613053902, 'Confusion Matrix': array([[1063,   11],\n",
            "       [ 122,   59]])}, 'SVM': {'Accuracy': 0.8549800796812749, 'Precision': 0.48484848484848486, 'Recall': 0.08839779005524862, 'F1 Score': 0.14953271028037382, 'ROC AUC': 0.6180000411535336, 'Confusion Matrix': array([[1057,   17],\n",
            "       [ 165,   16]])}, 'Decision Tree': {'Accuracy': 0.850199203187251, 'Precision': 0.4816753926701571, 'Recall': 0.5082872928176796, 'F1 Score': 0.49462365591397844, 'ROC AUC': 0.7100939329403171, 'Confusion Matrix': array([[975,  99],\n",
            "       [ 89,  92]])}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SDV - Oversampling"
      ],
      "metadata": {
        "id": "_NaC7Ymj90QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def do_sdv(X_train, y_train):\n",
        "  train_df = pd.concat([X_train, y_train], axis=1)\n",
        "  class_counts = y_train.value_counts()\n",
        "\n",
        "  # Find minority class label\n",
        "  minority_class_label = class_counts.idxmin()\n",
        "\n",
        "  # Filter rows with minority class label\n",
        "  minority_df = train_df[train_df.iloc[:, -1] == minority_class_label]\n",
        "\n",
        "  # Calculate counts of majority and minority classes\n",
        "  majority_count = class_counts.max()\n",
        "  minority_count = class_counts.min()\n",
        "\n",
        "  metadata_data = SingleTableMetadata()\n",
        "  metadata_data.detect_from_dataframe(minority_df)\n",
        "  print(metadata_data)\n",
        "  # Generate synthetic data using GaussianCopulaSynthesizer\n",
        "  synthesizer_breast_data = GaussianCopulaSynthesizer(metadata_data)\n",
        "  synthesizer_breast_data.fit(minority_df)\n",
        "\n",
        "  # Print sample synthetic data\n",
        "  synthesizer_breast_data.reset_sampling()\n",
        "  sd1 = synthesizer_breast_data.sample(num_rows=majority_count-minority_count)\n",
        "  return sd1, train_df\n",
        "\n",
        "# Function to add synthetic data to the main DataFrame based on percentage\n",
        "def add_synthetic_data(main_df, synthetic_df, percentage, seed=42):\n",
        "    # Calculate number of rows to sample\n",
        "    num_rows = int(len(synthetic_df) * percentage)\n",
        "\n",
        "    # Sample the specified percentage of synthetic data\n",
        "    sampled_synthetic_data = synthetic_df.sample(n=num_rows, replace=False, random_state=seed)\n",
        "    # print(sampled_synthetic_data)\n",
        "\n",
        "    # Concatenate sampled synthetic data with main DataFrame\n",
        "    combined_df = pd.concat([main_df, sampled_synthetic_data], ignore_index=True)\n",
        "    # print(combined_df)\n",
        "    return combined_df"
      ],
      "metadata": {
        "id": "o9yiYbcN93gn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Over-Sampling"
      ],
      "metadata": {
        "id": "A3BmbGRgJ5Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def random_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = RandomOverSampler(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "bF2pvEGDJ704"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "TGGkRAzG15Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def smote_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = SMOTE(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "cF6biXPn125o"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM-SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "QutsbBwdMujq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    min_label = min(zip(counts, labels))[1]\n",
        "    indices_with_min_label = np.where(y == min_label)[0]\n",
        "    X_min, y_min = X[indices_with_min_label], y[indices_with_min_label]\n",
        "\n",
        "    # Other class samples\n",
        "    indices_without_min_label = np.where(y != min_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_min_label], y[indices_without_min_label]\n",
        "\n",
        "    return X_min, y_min, X_remaining, y_remaining, min_label\n",
        "\n",
        "def svm_smote_oversampling(X_train, y_train, oversampling_ratios, seed=42):\n",
        "\n",
        "  oversampled_X_train_ratios = dict()\n",
        "  oversampled_y_train_ratios = dict()\n",
        "  X_minority, y_minority, X_remaining, y_remaining, min_label = find_minority_data(X_train, y_train)\n",
        "  ideal_samps = len(X_remaining) - len(X_minority)\n",
        "\n",
        "  oversampling_samps = [int(ideal_samps * (oversampling_ratio)) for oversampling_ratio in oversampling_ratios]\n",
        "  for oversampling_samp, oversampling_ratio in zip(oversampling_samps, oversampling_ratios):\n",
        "\n",
        "    sampling_strategy = {min_label: len(X_minority) + oversampling_samp}\n",
        "    X_train_upsampled, y_train_upsampled = SVMSMOTE(sampling_strategy=sampling_strategy, random_state = seed).fit_resample(X_train, y_train)\n",
        "\n",
        "    oversampled_X_train_ratios[oversampling_ratio] = X_train_upsampled\n",
        "    oversampled_y_train_ratios[oversampling_ratio] = y_train_upsampled\n",
        "\n",
        "  return list(oversampled_X_train_ratios.values()), list(oversampled_y_train_ratios.values())\n"
      ],
      "metadata": {
        "id": "XwF74E6XMzG4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intelligent Pruning"
      ],
      "metadata": {
        "id": "x7qohyP7L0DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_majority_data(X, y):\n",
        "    labels, counts = np.unique(y, return_counts=True)\n",
        "    max_label = max(zip(counts, labels))[1]\n",
        "    indices_with_max_label = np.where(y == max_label)[0]\n",
        "    X_maj, y_maj = X[indices_with_max_label], y[indices_with_max_label]\n",
        "\n",
        "    # Exclude majority class samples\n",
        "    indices_without_max_label = np.where(y != max_label)[0]\n",
        "    X_remaining, y_remaining = X[indices_without_max_label], y[indices_without_max_label]\n",
        "\n",
        "    return X_maj, y_maj, X_remaining, y_remaining, min(counts)\n",
        "\n",
        "def do_clustering(X, y, labels):\n",
        "  clustered_X = defaultdict(list)\n",
        "  clustered_y = defaultdict(list)\n",
        "\n",
        "  for i, label in enumerate(labels):\n",
        "      clustered_X[label].append(X[i])\n",
        "      clustered_y[label].append(y[i])\n",
        "\n",
        "  # Sort clustered_X and clustered_y in descending order based on the length of values in each dictionary\n",
        "  sorted_clustered_X = dict(sorted(clustered_X.items(), key=lambda x: -len(x[1])))\n",
        "  sorted_clustered_y = dict(sorted(clustered_y.items(), key=lambda x: -len(x[1])))\n",
        "\n",
        "  return sorted_clustered_X, sorted_clustered_y\n",
        "\n",
        "\n",
        "def intelligent_prune_data(pruning_samps, pruning_ratios, clustered_X, clustered_y, per_cluster_pruning_ratio=0.7, seed=42):\n",
        "  random.seed(seed)\n",
        "  pruning_ratios_X_maj, pruning_ratios_y_maj = defaultdict(list), defaultdict(list)\n",
        "  for pruning_samp, pruning_ratio in zip(pruning_samps, pruning_ratios):\n",
        "    samps = 0\n",
        "    # print(\"For Pruning samps: \", pruning_samp)\n",
        "    prune_samps = pruning_samp\n",
        "    # print(prune_samps)\n",
        "    clustered_X_new = defaultdict(list)\n",
        "    clustered_y_new = defaultdict(list)\n",
        "    # Iterate over the sorted dictionaries\n",
        "    for label, values_X in clustered_X.items():\n",
        "        # Calculate the number of samples to prune\n",
        "        num_samples_to_prune = int(prune_samps * per_cluster_pruning_ratio)\n",
        "        if(num_samples_to_prune > len(values_X)):\n",
        "          num_samples_to_prune = len(values_X)//2\n",
        "          prune_samps -= num_samples_to_prune\n",
        "        else:\n",
        "          prune_samps -= num_samples_to_prune\n",
        "\n",
        "        # Randomly choose samples to prune\n",
        "        indices_to_prune = random.sample(range(len(values_X)), num_samples_to_prune)\n",
        "\n",
        "        # Prune the samples from clustered_X and clustered_y\n",
        "        clustered_X_new[label] = [values_X[i] for i in range(len(values_X)) if i not in indices_to_prune]\n",
        "        clustered_y_new[label] = [clustered_y[label][i] for i in range(len(clustered_y[label])) if i not in indices_to_prune]\n",
        "\n",
        "    iter = 0\n",
        "    while(prune_samps > 0):\n",
        "        if(iter>=100):\n",
        "          break\n",
        "        for label, values_X in clustered_X_new.items():\n",
        "          if(prune_samps <=0 or len(values_X) <= 0):\n",
        "            break\n",
        "          # print(len(values_X))\n",
        "          index_to_prune = random.sample(range(len(values_X)), 1)\n",
        "          clustered_X_new[label] = [values_X[i] for i in range(len(values_X)) if i not in index_to_prune]\n",
        "          clustered_y_new[label] = [clustered_y_new[label][i] for i in range(len(clustered_y_new[label])) if i not in index_to_prune]\n",
        "\n",
        "          prune_samps -= 1\n",
        "        iter += 1\n",
        "\n",
        "    for label in clustered_X_new:\n",
        "        pruning_ratios_X_maj[pruning_ratio].extend(clustered_X_new[label])\n",
        "        pruning_ratios_y_maj[pruning_ratio].extend(clustered_y_new[label])\n",
        "\n",
        "  return pruning_ratios_X_maj, pruning_ratios_y_maj\n",
        "\n",
        "def combine_data(pruning_ratios, pruning_ratios_X_maj, pruning_ratios_y_maj, X_remaining, y_remaining):\n",
        "\n",
        "  pruning_ratios_X, pruning_ratios_y = defaultdict(list), defaultdict(list)\n",
        "  for pruning_ratio in pruning_ratios:\n",
        "    pruning_ratios_X[pruning_ratio].extend(pruning_ratios_X_maj[pruning_ratio])\n",
        "    pruning_ratios_X[pruning_ratio].extend(X_remaining)\n",
        "\n",
        "    pruning_ratios_y[pruning_ratio].extend(pruning_ratios_y_maj[pruning_ratio])\n",
        "    pruning_ratios_y[pruning_ratio].extend(y_remaining)\n",
        "\n",
        "  return pruning_ratios_X, pruning_ratios_y\n",
        "\n",
        "def do_intelligent_pruning(X, y, ratio, per_cluster_pruning_ratio=0.7, seed=42):\n",
        "\n",
        "  X_maj, y_maj, X_remaining, y_remaining, min_class_samples = find_majority_data(X, y)\n",
        "  kmeans = KMeans(n_clusters=3, random_state = 42)\n",
        "  kmeans.fit(X_maj)\n",
        "  labels = kmeans.labels_\n",
        "  clustered_X, clustered_y = do_clustering(X_maj, y_maj, labels)\n",
        "\n",
        "  pruning_best = len(X_maj)-min_class_samples\n",
        "  pruning_samps = [int(pruning_best * ratio)]\n",
        "  pruning_ratios = [ratio]\n",
        "\n",
        "  pruning_ratios_X_maj, pruning_ratios_y_maj = intelligent_prune_data(pruning_samps, pruning_ratios, clustered_X, clustered_y, \\\n",
        "                                                                      per_cluster_pruning_ratio=per_cluster_pruning_ratio, seed=seed)\n",
        "\n",
        "  pruning_ratios_X, pruning_ratios_y = combine_data(pruning_ratios, pruning_ratios_X_maj, pruning_ratios_y_maj, X_remaining, y_remaining)\n",
        "\n",
        "  return list(pruning_ratios_X.values()), list(pruning_ratios_y.values())"
      ],
      "metadata": {
        "id": "w9_Pj009Lxp9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Pruning"
      ],
      "metadata": {
        "id": "yky--qnU6rg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "inputs:\n",
        "X: np.array\n",
        "y: np.array\n",
        "percentage: from 0% upto 100%, enter int value\n",
        "\"\"\"\n",
        "def random_prune_data(X, y, ratio, seed = 42):\n",
        "  # preprocessed_X, scaler, imputer = preprocess_data_train(X)\n",
        "  # preprocessed_X_test = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "  # X_train, y_train = preprocessed_X_train.to_numpy(), y_train.to_numpy()\n",
        "  # X_test, y_test = preprocessed_X_test.to_numpy(), y_test.to_numpy()\n",
        "  np.random.seed(seed)\n",
        "  labels_count = {}\n",
        "  labels = np.unique(y)\n",
        "  for label in labels:\n",
        "    labels_count[label] = np.count_nonzero(y == label)\n",
        "  max_label = min_label = labels[0]\n",
        "  for label in labels_count:\n",
        "    if labels_count[label] > labels_count[max_label]:\n",
        "      max_label = label\n",
        "    if labels_count[label] < labels_count[min_label]:\n",
        "      min_label = label\n",
        "\n",
        "  # print(\"Max\", max_label, labels_count[max_label])\n",
        "  # print(\"Min\", min_label, labels_count[min_label])\n",
        "\n",
        "  prune_counts = {}\n",
        "  prune_indexes = {}\n",
        "  for label in labels_count:\n",
        "    prune_counts[label] = labels_count[label] - labels_count[min_label]\n",
        "    prune_indexes[label] = np.where(y == label)[0]\n",
        "\n",
        "  prune_amount = int(ratio * sum(map(lambda x: x[1], prune_counts.items())))\n",
        "  prune_it = {}\n",
        "\n",
        "  while prune_amount > 0:\n",
        "    for label in labels:\n",
        "      if (len(prune_indexes[label]) - labels_count[min_label]) > 0 and prune_amount > 0:\n",
        "        random_index = np.random.choice(len(prune_indexes[label]))\n",
        "        random_item = prune_indexes[label][random_index]\n",
        "        prune_indexes[label] = np.delete(prune_indexes[label], random_index)\n",
        "        if prune_it.get(label, None) is None:\n",
        "          prune_it[label] = np.array([])\n",
        "        prune_it[label] = np.append(prune_it[label], [random_item])\n",
        "        prune_amount -= 1\n",
        "\n",
        "\n",
        "\n",
        "  formatted_indexes = np.array([])\n",
        "  for label in prune_indexes:\n",
        "    formatted_indexes = np.append(formatted_indexes, prune_indexes[label])\n",
        "  formatted_indexes = np.sort(formatted_indexes)\n",
        "  new_arr = np.array([np.int64(i) for i in formatted_indexes])\n",
        "\n",
        "  return X[new_arr], y[new_arr]"
      ],
      "metadata": {
        "id": "BtB6jqhZtRD0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratios = [ratio for ratio in np.arange(0.2, 1.1, 0.2)]"
      ],
      "metadata": {
        "id": "z0A-h4iX3J8p"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Intelligent Pruning"
      ],
      "metadata": {
        "id": "UY6hAjLw9fy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_intelligent_pruning = dict()\n",
        "per_cluster_pruning_ratios = [0.5, 0.7, 0.9, 1]\n",
        "\n",
        "for per_cluster_pruning_ratio in per_cluster_pruning_ratios:\n",
        "  print(f'For per-cluster pruning ratio {per_cluster_pruning_ratio}')\n",
        "  for ratio in ratios:\n",
        "    X_train_copy, y_train_copy = X_train.copy(), y_train.copy()\n",
        "\n",
        "    intelligent_pruned_X_train, intelligent_pruned_y_train = do_intelligent_pruning(X_train_copy.to_numpy(), y_train_copy.to_numpy(), ratio, per_cluster_pruning_ratio=per_cluster_pruning_ratio)\n",
        "\n",
        "    preprocessed_intelligent_pruned_X_train, scaler, imputer = preprocess_data_train((np.array(intelligent_pruned_X_train))[0])\n",
        "    preprocessed_X_test = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    intelligent_pruned_X_train, intelligent_pruned_y_train = preprocessed_intelligent_pruned_X_train, (np.array(intelligent_pruned_y_train))[0]\n",
        "    intelligent_pruned_X_test, intelligent_pruned_y_test = preprocessed_X_test, y_test.to_numpy()\n",
        "    print(f\"Train data pruned intelligently at {ratio * 100}% :\")\n",
        "    results = evaluate_models(intelligent_pruned_X_train, intelligent_pruned_X_test, intelligent_pruned_y_train, intelligent_pruned_y_test)\n",
        "    print(results)\n",
        "    results_intelligent_pruning[ratio] = results\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRV_KrPy9is0",
        "outputId": "13874e97-df16-489c-d965-5de689f69538"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For per-cluster pruning ratio 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 20.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8741035856573706, 'Precision': 0.6493506493506493, 'Recall': 0.27624309392265195, 'F1 Score': 0.3875968992248062, 'ROC AUC': 0.7310745187608672, 'Confusion Matrix': array([[1047,   27],\n",
            "       [ 131,   50]])}, 'SVM': {'Accuracy': 0.8916334661354581, 'Precision': 0.7472527472527473, 'Recall': 0.3756906077348066, 'F1 Score': 0.5, 'ROC AUC': 0.7663585295842464, 'Confusion Matrix': array([[1051,   23],\n",
            "       [ 113,   68]])}, 'Decision Tree': {'Accuracy': 0.8302788844621514, 'Precision': 0.42592592592592593, 'Recall': 0.5082872928176796, 'F1 Score': 0.4634760705289673, 'ROC AUC': 0.6992422605635977, 'Confusion Matrix': array([[950, 124],\n",
            "       [ 89,  92]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 40.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8741035856573706, 'Precision': 0.6385542168674698, 'Recall': 0.292817679558011, 'F1 Score': 0.4015151515151515, 'ROC AUC': 0.7421088099426937, 'Confusion Matrix': array([[1044,   30],\n",
            "       [ 128,   53]])}, 'SVM': {'Accuracy': 0.8900398406374502, 'Precision': 0.7311827956989247, 'Recall': 0.3756906077348066, 'F1 Score': 0.49635036496350365, 'ROC AUC': 0.7660498780826569, 'Confusion Matrix': array([[1049,   25],\n",
            "       [ 113,   68]])}, 'Decision Tree': {'Accuracy': 0.8294820717131474, 'Precision': 0.4225352112676056, 'Recall': 0.4972375690607735, 'F1 Score': 0.4568527918781726, 'ROC AUC': 0.6897177896437132, 'Confusion Matrix': array([[951, 123],\n",
            "       [ 91,  90]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 60.00000000000001% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8733067729083666, 'Precision': 0.6170212765957447, 'Recall': 0.32044198895027626, 'F1 Score': 0.4218181818181818, 'ROC AUC': 0.748966017469675, 'Confusion Matrix': array([[1038,   36],\n",
            "       [ 123,   58]])}, 'SVM': {'Accuracy': 0.8900398406374502, 'Precision': 0.7311827956989247, 'Recall': 0.3756906077348066, 'F1 Score': 0.49635036496350365, 'ROC AUC': 0.7667289113861538, 'Confusion Matrix': array([[1049,   25],\n",
            "       [ 113,   68]])}, 'Decision Tree': {'Accuracy': 0.8199203187250996, 'Precision': 0.40425531914893614, 'Recall': 0.5248618784530387, 'F1 Score': 0.4567307692307693, 'ROC AUC': 0.6992139675092852, 'Confusion Matrix': array([[934, 140],\n",
            "       [ 86,  95]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 80.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8733067729083666, 'Precision': 0.6195652173913043, 'Recall': 0.3149171270718232, 'F1 Score': 0.4175824175824176, 'ROC AUC': 0.7354470817000525, 'Confusion Matrix': array([[1039,   35],\n",
            "       [ 124,   57]])}, 'SVM': {'Accuracy': 0.8908366533864542, 'Precision': 0.7340425531914894, 'Recall': 0.3812154696132597, 'F1 Score': 0.5018181818181818, 'ROC AUC': 0.769445044600142, 'Confusion Matrix': array([[1049,   25],\n",
            "       [ 112,   69]])}, 'Decision Tree': {'Accuracy': 0.8310756972111554, 'Precision': 0.4351464435146444, 'Recall': 0.574585635359116, 'F1 Score': 0.4952380952380952, 'ROC AUC': 0.7248783398664568, 'Confusion Matrix': array([[939, 135],\n",
            "       [ 77, 104]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 100.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8709163346613545, 'Precision': 0.5922330097087378, 'Recall': 0.3370165745856354, 'F1 Score': 0.42957746478873243, 'ROC AUC': 0.7410388180705165, 'Confusion Matrix': array([[1032,   42],\n",
            "       [ 120,   61]])}, 'SVM': {'Accuracy': 0.8892430278884462, 'Precision': 0.7142857142857143, 'Recall': 0.3867403314917127, 'F1 Score': 0.5017921146953406, 'ROC AUC': 0.7693730259164379, 'Confusion Matrix': array([[1046,   28],\n",
            "       [ 111,   70]])}, 'Decision Tree': {'Accuracy': 0.8175298804780876, 'Precision': 0.40977443609022557, 'Recall': 0.6022099447513812, 'F1 Score': 0.4876957494407159, 'ROC AUC': 0.7263470065948539, 'Confusion Matrix': array([[917, 157],\n",
            "       [ 72, 109]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 20.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8725099601593626, 'Precision': 0.6363636363636364, 'Recall': 0.27071823204419887, 'F1 Score': 0.37984496124031003, 'ROC AUC': 0.742407173060897, 'Confusion Matrix': array([[1046,   28],\n",
            "       [ 132,   49]])}, 'SVM': {'Accuracy': 0.8916334661354581, 'Precision': 0.7472527472527473, 'Recall': 0.3756906077348066, 'F1 Score': 0.5, 'ROC AUC': 0.7654068541210122, 'Confusion Matrix': array([[1051,   23],\n",
            "       [ 113,   68]])}, 'Decision Tree': {'Accuracy': 0.8398406374501992, 'Precision': 0.4523809523809524, 'Recall': 0.5248618784530387, 'F1 Score': 0.4859335038363171, 'ROC AUC': 0.706680761751906, 'Confusion Matrix': array([[959, 115],\n",
            "       [ 86,  95]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 40.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8749003984063745, 'Precision': 0.6363636363636364, 'Recall': 0.30939226519337015, 'F1 Score': 0.4163568773234201, 'ROC AUC': 0.7434462997829151, 'Confusion Matrix': array([[1042,   32],\n",
            "       [ 125,   56]])}, 'SVM': {'Accuracy': 0.8900398406374502, 'Precision': 0.7311827956989247, 'Recall': 0.3756906077348066, 'F1 Score': 0.49635036496350365, 'ROC AUC': 0.7684830807535212, 'Confusion Matrix': array([[1049,   25],\n",
            "       [ 113,   68]])}, 'Decision Tree': {'Accuracy': 0.8231075697211155, 'Precision': 0.41350210970464135, 'Recall': 0.5414364640883977, 'F1 Score': 0.4688995215311004, 'ROC AUC': 0.7045124849532393, 'Confusion Matrix': array([[935, 139],\n",
            "       [ 83,  98]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 60.00000000000001% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8741035856573706, 'Precision': 0.6263736263736264, 'Recall': 0.3149171270718232, 'F1 Score': 0.4191176470588235, 'ROC AUC': 0.736496496805457, 'Confusion Matrix': array([[1040,   34],\n",
            "       [ 124,   57]])}, 'SVM': {'Accuracy': 0.8892430278884462, 'Precision': 0.71875, 'Recall': 0.3812154696132597, 'F1 Score': 0.4981949458483755, 'ROC AUC': 0.7685911087790777, 'Confusion Matrix': array([[1047,   27],\n",
            "       [ 112,   69]])}, 'Decision Tree': {'Accuracy': 0.8143426294820717, 'Precision': 0.3992248062015504, 'Recall': 0.569060773480663, 'F1 Score': 0.46924829157175396, 'ROC AUC': 0.7103640030042079, 'Confusion Matrix': array([[919, 155],\n",
            "       [ 78, 103]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 80.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8741035856573706, 'Precision': 0.6017699115044248, 'Recall': 0.3756906077348066, 'F1 Score': 0.46258503401360546, 'ROC AUC': 0.7442076401535028, 'Confusion Matrix': array([[1029,   45],\n",
            "       [ 113,   68]])}, 'SVM': {'Accuracy': 0.8868525896414342, 'Precision': 0.693069306930693, 'Recall': 0.3867403314917127, 'F1 Score': 0.4964539007092199, 'ROC AUC': 0.7709420043828513, 'Confusion Matrix': array([[1043,   31],\n",
            "       [ 111,   70]])}, 'Decision Tree': {'Accuracy': 0.80398406374502, 'Precision': 0.379182156133829, 'Recall': 0.56353591160221, 'F1 Score': 0.45333333333333337, 'ROC AUC': 0.705842258505921, 'Confusion Matrix': array([[907, 167],\n",
            "       [ 79, 102]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 100.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8685258964143426, 'Precision': 0.5579710144927537, 'Recall': 0.425414364640884, 'F1 Score': 0.4827586206896552, 'ROC AUC': 0.7493878411885141, 'Confusion Matrix': array([[1013,   61],\n",
            "       [ 104,   77]])}, 'SVM': {'Accuracy': 0.8868525896414342, 'Precision': 0.6857142857142857, 'Recall': 0.39779005524861877, 'F1 Score': 0.5034965034965034, 'ROC AUC': 0.7784525242548639, 'Confusion Matrix': array([[1041,   33],\n",
            "       [ 109,   72]])}, 'Decision Tree': {'Accuracy': 0.7768924302788844, 'Precision': 0.33554817275747506, 'Recall': 0.5580110497237569, 'F1 Score': 0.4190871369294606, 'ROC AUC': 0.6838379785384323, 'Confusion Matrix': array([[874, 200],\n",
            "       [ 80, 101]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 20.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8764940239043825, 'Precision': 0.7407407407407407, 'Recall': 0.22099447513812154, 'F1 Score': 0.3404255319148936, 'ROC AUC': 0.7319335987736246, 'Confusion Matrix': array([[1060,   14],\n",
            "       [ 141,   40]])}, 'SVM': {'Accuracy': 0.902788844621514, 'Precision': 0.927536231884058, 'Recall': 0.35359116022099446, 'F1 Score': 0.5119999999999999, 'ROC AUC': 0.7688225974052696, 'Confusion Matrix': array([[1069,    5],\n",
            "       [ 117,   64]])}, 'Decision Tree': {'Accuracy': 0.8390438247011952, 'Precision': 0.4467005076142132, 'Recall': 0.4861878453038674, 'F1 Score': 0.4656084656084656, 'ROC AUC': 0.6921998621356626, 'Confusion Matrix': array([[965, 109],\n",
            "       [ 93,  88]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 40.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8725099601593626, 'Precision': 0.6153846153846154, 'Recall': 0.30939226519337015, 'F1 Score': 0.4117647058823529, 'ROC AUC': 0.7436366348755619, 'Confusion Matrix': array([[1039,   35],\n",
            "       [ 125,   56]])}, 'SVM': {'Accuracy': 0.8908366533864542, 'Precision': 0.7340425531914894, 'Recall': 0.3812154696132597, 'F1 Score': 0.5018181818181818, 'ROC AUC': 0.7681229873350002, 'Confusion Matrix': array([[1049,   25],\n",
            "       [ 112,   69]])}, 'Decision Tree': {'Accuracy': 0.8302788844621514, 'Precision': 0.42857142857142855, 'Recall': 0.5303867403314917, 'F1 Score': 0.47407407407407404, 'ROC AUC': 0.7091576900521621, 'Confusion Matrix': array([[946, 128],\n",
            "       [ 85,  96]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 60.00000000000001% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8693227091633466, 'Precision': 0.5714285714285714, 'Recall': 0.3756906077348066, 'F1 Score': 0.4533333333333333, 'ROC AUC': 0.7452621994506003, 'Confusion Matrix': array([[1023,   51],\n",
            "       [ 113,   68]])}, 'SVM': {'Accuracy': 0.8884462151394422, 'Precision': 0.7070707070707071, 'Recall': 0.3867403314917127, 'F1 Score': 0.5, 'ROC AUC': 0.7708082553988291, 'Confusion Matrix': array([[1045,   29],\n",
            "       [ 111,   70]])}, 'Decision Tree': {'Accuracy': 0.8103585657370518, 'Precision': 0.38735177865612647, 'Recall': 0.5414364640883977, 'F1 Score': 0.4516129032258064, 'ROC AUC': 0.6966367274710125, 'Confusion Matrix': array([[919, 155],\n",
            "       [ 83,  98]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 80.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8701195219123506, 'Precision': 0.5652173913043478, 'Recall': 0.430939226519337, 'F1 Score': 0.4890282131661442, 'ROC AUC': 0.7513272014568352, 'Confusion Matrix': array([[1014,   60],\n",
            "       [ 103,   78]])}, 'SVM': {'Accuracy': 0.8876494023904382, 'Precision': 0.6886792452830188, 'Recall': 0.40331491712707185, 'F1 Score': 0.5087108013937283, 'ROC AUC': 0.779815735053551, 'Confusion Matrix': array([[1041,   33],\n",
            "       [ 108,   73]])}, 'Decision Tree': {'Accuracy': 0.7752988047808765, 'Precision': 0.3465045592705167, 'Recall': 0.6298342541436464, 'F1 Score': 0.44705882352941173, 'ROC AUC': 0.7153101433171806, 'Confusion Matrix': array([[859, 215],\n",
            "       [ 67, 114]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 100.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.848605577689243, 'Precision': 0.4756756756756757, 'Recall': 0.4861878453038674, 'F1 Score': 0.4808743169398907, 'ROC AUC': 0.7437086535592661, 'Confusion Matrix': array([[977,  97],\n",
            "       [ 93,  88]])}, 'SVM': {'Accuracy': 0.8581673306772908, 'Precision': 0.5087719298245614, 'Recall': 0.48066298342541436, 'F1 Score': 0.4943181818181818, 'ROC AUC': 0.768575676203998, 'Confusion Matrix': array([[990,  84],\n",
            "       [ 94,  87]])}, 'Decision Tree': {'Accuracy': 0.69800796812749, 'Precision': 0.2708333333333333, 'Recall': 0.6464088397790055, 'F1 Score': 0.3817292006525286, 'ROC AUC': 0.6749102338549544, 'Confusion Matrix': array([[759, 315],\n",
            "       [ 64, 117]])}}\n",
            "_______________________________________________________________________________\n",
            "For per-cluster pruning ratio 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 20.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8749003984063745, 'Precision': 0.7727272727272727, 'Recall': 0.1878453038674033, 'F1 Score': 0.3022222222222222, 'ROC AUC': 0.7232141938537197, 'Confusion Matrix': array([[1064,   10],\n",
            "       [ 147,   34]])}, 'SVM': {'Accuracy': 0.9035856573705179, 'Precision': 0.9411764705882353, 'Recall': 0.35359116022099446, 'F1 Score': 0.5140562248995983, 'ROC AUC': 0.7572378777122752, 'Confusion Matrix': array([[1070,    4],\n",
            "       [ 117,   64]])}, 'Decision Tree': {'Accuracy': 0.8541832669322709, 'Precision': 0.49444444444444446, 'Recall': 0.49171270718232046, 'F1 Score': 0.4930747922437673, 'ROC AUC': 0.7064184079755549, 'Confusion Matrix': array([[983,  91],\n",
            "       [ 92,  89]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 40.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8709163346613545, 'Precision': 0.6610169491525424, 'Recall': 0.2154696132596685, 'F1 Score': 0.325, 'ROC AUC': 0.7252410053808245, 'Confusion Matrix': array([[1054,   20],\n",
            "       [ 142,   39]])}, 'SVM': {'Accuracy': 0.9035856573705179, 'Precision': 0.9411764705882353, 'Recall': 0.35359116022099446, 'F1 Score': 0.5140562248995983, 'ROC AUC': 0.7597122339166846, 'Confusion Matrix': array([[1070,    4],\n",
            "       [ 117,   64]])}, 'Decision Tree': {'Accuracy': 0.8199203187250996, 'Precision': 0.4066390041493776, 'Recall': 0.5414364640883977, 'F1 Score': 0.4644549763033175, 'ROC AUC': 0.7072260460713807, 'Confusion Matrix': array([[931, 143],\n",
            "       [ 83,  98]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 60.00000000000001% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8756972111553785, 'Precision': 0.6666666666666666, 'Recall': 0.27624309392265195, 'F1 Score': 0.390625, 'ROC AUC': 0.725904606109242, 'Confusion Matrix': array([[1049,   25],\n",
            "       [ 131,   50]])}, 'SVM': {'Accuracy': 0.9051792828685259, 'Precision': 0.9078947368421053, 'Recall': 0.3812154696132597, 'F1 Score': 0.5369649805447472, 'ROC AUC': 0.7678812103254218, 'Confusion Matrix': array([[1067,    7],\n",
            "       [ 112,   69]])}, 'Decision Tree': {'Accuracy': 0.8167330677290837, 'Precision': 0.4075471698113208, 'Recall': 0.5966850828729282, 'F1 Score': 0.48430493273542596, 'ROC AUC': 0.7228103748058068, 'Confusion Matrix': array([[917, 157],\n",
            "       [ 73, 108]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 80.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8788844621513944, 'Precision': 0.6494845360824743, 'Recall': 0.34806629834254144, 'F1 Score': 0.45323741007194246, 'ROC AUC': 0.731136249061185, 'Confusion Matrix': array([[1040,   34],\n",
            "       [ 118,   63]])}, 'SVM': {'Accuracy': 0.9043824701195219, 'Precision': 0.8674698795180723, 'Recall': 0.39779005524861877, 'F1 Score': 0.5454545454545454, 'ROC AUC': 0.7779792586190931, 'Confusion Matrix': array([[1063,   11],\n",
            "       [ 109,   72]])}, 'Decision Tree': {'Accuracy': 0.7928286852589641, 'Precision': 0.3713355048859935, 'Recall': 0.6298342541436464, 'F1 Score': 0.4672131147540983, 'ROC AUC': 0.7236874594894903, 'Confusion Matrix': array([[881, 193],\n",
            "       [ 67, 114]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned intelligently at 100.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.6932270916334662, 'Precision': 0.2671232876712329, 'Recall': 0.6464088397790055, 'F1 Score': 0.37802907915993544, 'ROC AUC': 0.7359769334444478, 'Confusion Matrix': array([[753, 321],\n",
            "       [ 64, 117]])}, 'SVM': {'Accuracy': 0.8215139442231075, 'Precision': 0.40772532188841204, 'Recall': 0.5248618784530387, 'F1 Score': 0.45893719806763283, 'ROC AUC': 0.7753351440888094, 'Confusion Matrix': array([[936, 138],\n",
            "       [ 86,  95]])}, 'Decision Tree': {'Accuracy': 0.69800796812749, 'Precision': 0.28, 'Recall': 0.6961325966850829, 'F1 Score': 0.3993660855784469, 'ROC AUC': 0.6963795178863544, 'Confusion Matrix': array([[750, 324],\n",
            "       [ 55, 126]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calling Random Pruning"
      ],
      "metadata": {
        "id": "uGrS3yXb-RYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_random_pruning = dict()\n",
        "for ratio in ratios:\n",
        "  random_pruned_X_train, random_pruned_y_train = random_prune_data(X_train.to_numpy(), y_train.to_numpy(), ratio)\n",
        "  preprocessed_random_pruned_X_train, scaler, imputer = preprocess_data_train(random_pruned_X_train)\n",
        "  preprocessed_X_test = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "  random_pruned_X_train, random_pruned_y_train = preprocessed_random_pruned_X_train, random_pruned_y_train\n",
        "  random_pruned_X_test, random_pruned_y_test = preprocessed_X_test, y_test.to_numpy()\n",
        "\n",
        "  print(f\"Train data pruned randomly at {ratio * 100}% :\")\n",
        "  results = evaluate_models(random_pruned_X_train, random_pruned_X_test, random_pruned_y_train, random_pruned_y_test)\n",
        "  print(results)\n",
        "  results_random_pruning[ratio] = results\n",
        "  print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "4od9tUcU-QI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122c2f9c-74ed-4922-fff1-d1dc58025d35"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned randomly at 20.0% :\n",
            "{'Logistic Regression': {'Accuracy': 0.8764940239043825, 'Precision': 0.782608695652174, 'Recall': 0.19889502762430938, 'F1 Score': 0.3171806167400881, 'ROC AUC': 0.7281989156043911, 'Confusion Matrix': array([[1064,   10],\n",
            "       [ 145,   36]])}, 'SVM': {'Accuracy': 0.9035856573705179, 'Precision': 0.9411764705882353, 'Recall': 0.35359116022099446, 'F1 Score': 0.5140562248995983, 'ROC AUC': 0.752649258721977, 'Confusion Matrix': array([[1070,    4],\n",
            "       [ 117,   64]])}, 'Decision Tree': {'Accuracy': 0.8350597609561753, 'Precision': 0.4386792452830189, 'Recall': 0.5138121546961326, 'F1 Score': 0.4732824427480916, 'ROC AUC': 0.7041549636305647, 'Confusion Matrix': array([[955, 119],\n",
            "       [ 88,  93]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data pruned randomly at 40.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8772908366533865, 'Precision': 0.7647058823529411, 'Recall': 0.2154696132596685, 'F1 Score': 0.33620689655172414, 'ROC AUC': 0.7285024229142875, 'Confusion Matrix': array([[1062,   12],\n",
            "       [ 142,   39]])}, 'SVM': {'Accuracy': 0.902788844621514, 'Precision': 0.927536231884058, 'Recall': 0.35359116022099446, 'F1 Score': 0.5119999999999999, 'ROC AUC': 0.7539198740701873, 'Confusion Matrix': array([[1069,    5],\n",
            "       [ 117,   64]])}, 'Decision Tree': {'Accuracy': 0.8159362549800797, 'Precision': 0.38839285714285715, 'Recall': 0.48066298342541436, 'F1 Score': 0.4296296296296296, 'ROC AUC': 0.6840154531518463, 'Confusion Matrix': array([[937, 137],\n",
            "       [ 94,  87]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 60.00000000000001% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8749003984063745, 'Precision': 0.6764705882352942, 'Recall': 0.2541436464088398, 'F1 Score': 0.3694779116465864, 'ROC AUC': 0.7332865211889255, 'Confusion Matrix': array([[1052,   22],\n",
            "       [ 135,   46]])}, 'SVM': {'Accuracy': 0.9043824701195219, 'Precision': 0.9178082191780822, 'Recall': 0.3701657458563536, 'F1 Score': 0.5275590551181102, 'ROC AUC': 0.763344033252055, 'Confusion Matrix': array([[1068,    6],\n",
            "       [ 114,   67]])}, 'Decision Tree': {'Accuracy': 0.8063745019920319, 'Precision': 0.376984126984127, 'Recall': 0.5248618784530387, 'F1 Score': 0.43879907621247116, 'ROC AUC': 0.6950883257713715, 'Confusion Matrix': array([[917, 157],\n",
            "       [ 86,  95]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 80.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8749003984063745, 'Precision': 0.6176470588235294, 'Recall': 0.34806629834254144, 'F1 Score': 0.44522968197879864, 'ROC AUC': 0.7312854306202867, 'Confusion Matrix': array([[1035,   39],\n",
            "       [ 118,   63]])}, 'SVM': {'Accuracy': 0.899601593625498, 'Precision': 0.8160919540229885, 'Recall': 0.39226519337016574, 'F1 Score': 0.5298507462686567, 'ROC AUC': 0.7762405218268054, 'Confusion Matrix': array([[1058,   16],\n",
            "       [ 110,   71]])}, 'Decision Tree': {'Accuracy': 0.7952191235059761, 'Precision': 0.37662337662337664, 'Recall': 0.6408839779005525, 'F1 Score': 0.474437627811861, 'ROC AUC': 0.7308173091762092, 'Confusion Matrix': array([[882, 192],\n",
            "       [ 65, 116]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data pruned randomly at 100.0% :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7952191235059761, 'Precision': 0.36524822695035464, 'Recall': 0.569060773480663, 'F1 Score': 0.4449244060475162, 'ROC AUC': 0.752129695360968, 'Confusion Matrix': array([[895, 179],\n",
            "       [ 78, 103]])}, 'SVM': {'Accuracy': 0.8589641434262948, 'Precision': 0.5106382978723404, 'Recall': 0.5303867403314917, 'F1 Score': 0.5203252032520325, 'ROC AUC': 0.7779278167021615, 'Confusion Matrix': array([[982,  92],\n",
            "       [ 85,  96]])}, 'Decision Tree': {'Accuracy': 0.7043824701195219, 'Precision': 0.2850678733031674, 'Recall': 0.6961325966850829, 'F1 Score': 0.4044943820224719, 'ROC AUC': 0.6995380515859543, 'Confusion Matrix': array([[758, 316],\n",
            "       [ 55, 126]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SDV-Oversampling"
      ],
      "metadata": {
        "id": "f_VUTRHBBVDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sd1, train_df = do_sdv(X_train, y_train)\n",
        "results_syn_sdv = dict()\n",
        "\n",
        "# Add synthetic data at different percentages to the main DataFrame\n",
        "for ratio in ratios:\n",
        "    combined_df = add_synthetic_data(train_df, sd1, ratio)\n",
        "    y_train_sdv = combined_df.iloc[:, -1]\n",
        "    X_train_sdv = combined_df.iloc[:, :-1]\n",
        "\n",
        "    preprocessed_X_train_sdv, scaler, imputer = preprocess_data_train(X_train_sdv)\n",
        "    preprocessed_X_test_sdv = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_sdv, y_train_sdv = preprocessed_X_train_sdv, y_train_sdv.to_numpy()\n",
        "    X_test_sdv, y_test_sdv = preprocessed_X_test_sdv, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    results = evaluate_models(X_train_sdv, X_test_sdv, y_train_sdv, y_test_sdv)\n",
        "    results_syn_sdv[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "g4V6WxpY9kbd",
        "outputId": "5a6c5009-ec79-44f3-e52f-6c2638bc840f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"columns\": {\n",
            "        \"CC\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"CCL\": {\n",
            "            \"sdtype\": \"categorical\"\n",
            "        },\n",
            "        \"CCO\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"CI\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"CLC\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"CLLC\": {\n",
            "            \"sdtype\": \"categorical\"\n",
            "        },\n",
            "        \"McCC\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"NL\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"NLE\": {\n",
            "            \"sdtype\": \"categorical\"\n",
            "        },\n",
            "        \"CD\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"CLOC\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"DLOC\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"TCD\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"TCLOC\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"LLOC\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"LOC\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"NOS\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"NUMPAR\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"TLLOC\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"TLOC\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"TNOS\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"HOR_D\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"HOR_T\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"HON_D\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"HON_T\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"HLEN\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"HVOC\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"HDIFF\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"HVOL\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"HEFF\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"HBUGS\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"HTIME\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"CYCL\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"PARAMS\": {\n",
            "            \"sdtype\": \"categorical\"\n",
            "        },\n",
            "        \"CYCL_DENS\": {\n",
            "            \"sdtype\": \"numerical\"\n",
            "        },\n",
            "        \"Vuln\": {\n",
            "            \"sdtype\": \"categorical\"\n",
            "        }\n",
            "    },\n",
            "    \"METADATA_SPEC_VERSION\": \"SINGLE_TABLE_V1\"\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sdv/single_table/base.py:80: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8677290836653386, 'Precision': 0.6415094339622641, 'Recall': 0.1878453038674033, 'F1 Score': 0.2905982905982906, 'ROC AUC': 0.721156517176456, 'Confusion Matrix': array([[1055,   19],\n",
            "       [ 147,   34]])}, 'SVM': {'Accuracy': 0.9043824701195219, 'Precision': 0.9178082191780822, 'Recall': 0.3701657458563536, 'F1 Score': 0.5275590551181102, 'ROC AUC': 0.7535494922682799, 'Confusion Matrix': array([[1068,    6],\n",
            "       [ 114,   67]])}, 'Decision Tree': {'Accuracy': 0.853386454183267, 'Precision': 0.4918032786885246, 'Recall': 0.4972375690607735, 'F1 Score': 0.4945054945054945, 'ROC AUC': 0.7130749920265028, 'Confusion Matrix': array([[981,  93],\n",
            "       [ 91,  90]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8693227091633466, 'Precision': 0.6491228070175439, 'Recall': 0.20441988950276244, 'F1 Score': 0.3109243697478991, 'ROC AUC': 0.7186049980966491, 'Confusion Matrix': array([[1054,   20],\n",
            "       [ 144,   37]])}, 'SVM': {'Accuracy': 0.9043824701195219, 'Precision': 0.9178082191780822, 'Recall': 0.3701657458563536, 'F1 Score': 0.5275590551181102, 'ROC AUC': 0.7516975832587427, 'Confusion Matrix': array([[1068,    6],\n",
            "       [ 114,   67]])}, 'Decision Tree': {'Accuracy': 0.8605577689243028, 'Precision': 0.5176470588235295, 'Recall': 0.4861878453038674, 'F1 Score': 0.5014245014245013, 'ROC AUC': 0.712254493451444, 'Confusion Matrix': array([[992,  82],\n",
            "       [ 93,  88]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8701195219123506, 'Precision': 0.65, 'Recall': 0.2154696132596685, 'F1 Score': 0.3236514522821577, 'ROC AUC': 0.7183117791701391, 'Confusion Matrix': array([[1053,   21],\n",
            "       [ 142,   39]])}, 'SVM': {'Accuracy': 0.9043824701195219, 'Precision': 0.9178082191780822, 'Recall': 0.3701657458563536, 'F1 Score': 0.5275590551181102, 'ROC AUC': 0.7559775507474511, 'Confusion Matrix': array([[1068,    6],\n",
            "       [ 114,   67]])}, 'Decision Tree': {'Accuracy': 0.8581673306772908, 'Precision': 0.5084745762711864, 'Recall': 0.4972375690607735, 'F1 Score': 0.5027932960893854, 'ROC AUC': 0.7108527012150581, 'Confusion Matrix': array([[987,  87],\n",
            "       [ 91,  90]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8701195219123506, 'Precision': 0.65, 'Recall': 0.2154696132596685, 'F1 Score': 0.3236514522821577, 'ROC AUC': 0.7185947097132628, 'Confusion Matrix': array([[1053,   21],\n",
            "       [ 142,   39]])}, 'SVM': {'Accuracy': 0.9043824701195219, 'Precision': 0.9178082191780822, 'Recall': 0.3701657458563536, 'F1 Score': 0.5275590551181102, 'ROC AUC': 0.7566771608177207, 'Confusion Matrix': array([[1068,    6],\n",
            "       [ 114,   67]])}, 'Decision Tree': {'Accuracy': 0.8645418326693227, 'Precision': 0.5321637426900585, 'Recall': 0.5027624309392266, 'F1 Score': 0.5170454545454546, 'ROC AUC': 0.7232167659495663, 'Confusion Matrix': array([[994,  80],\n",
            "       [ 90,  91]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8709163346613545, 'Precision': 0.6557377049180327, 'Recall': 0.22099447513812154, 'F1 Score': 0.3305785123966942, 'ROC AUC': 0.7184661049209338, 'Confusion Matrix': array([[1053,   21],\n",
            "       [ 141,   40]])}, 'SVM': {'Accuracy': 0.9043824701195219, 'Precision': 0.9178082191780822, 'Recall': 0.3701657458563536, 'F1 Score': 0.5275590551181102, 'ROC AUC': 0.7569240820189924, 'Confusion Matrix': array([[1068,    6],\n",
            "       [ 114,   67]])}, 'Decision Tree': {'Accuracy': 0.8430278884462151, 'Precision': 0.4583333333333333, 'Recall': 0.4861878453038674, 'F1 Score': 0.4718498659517426, 'ROC AUC': 0.6982314268958919, 'Confusion Matrix': array([[970, 104],\n",
            "       [ 93,  88]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SMOTE-Oversampling"
      ],
      "metadata": {
        "id": "l78jR_BuCw1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_smote = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_smote, y_train_smote = smote_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "    preprocessed_X_train_smote, scaler, imputer = preprocess_data_train((np.array(X_train_smote))[0])\n",
        "    preprocessed_X_test_smote = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_smote, y_train_smote = preprocessed_X_train_smote, (np.array(y_train_smote))[0]\n",
        "    X_test_smote, y_test_smote = preprocessed_X_test_smote, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_smote), len(y_train_smote))\n",
        "    results = evaluate_models(X_train_smote, X_test_smote, y_train_smote, y_test_smote)\n",
        "    results_smote[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "X7S78dnHC0bw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d55c8f-d549-4ef7-837a-7d8aeba6a92a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "5730 5730\n",
            "{'Logistic Regression': {'Accuracy': 0.8788844621513944, 'Precision': 0.704225352112676, 'Recall': 0.27624309392265195, 'F1 Score': 0.39682539682539686, 'ROC AUC': 0.7321702315915101, 'Confusion Matrix': array([[1053,   21],\n",
            "       [ 131,   50]])}, 'SVM': {'Accuracy': 0.9035856573705179, 'Precision': 0.9285714285714286, 'Recall': 0.35911602209944754, 'F1 Score': 0.5179282868525897, 'ROC AUC': 0.7707671018652837, 'Confusion Matrix': array([[1069,    5],\n",
            "       [ 116,   65]])}, 'Decision Tree': {'Accuracy': 0.8653386454183267, 'Precision': 0.532967032967033, 'Recall': 0.5359116022099447, 'F1 Score': 0.5344352617079889, 'ROC AUC': 0.7319593197320905, 'Confusion Matrix': array([[989,  85],\n",
            "       [ 84,  97]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "6444 6444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8812749003984064, 'Precision': 0.6538461538461539, 'Recall': 0.3756906077348066, 'F1 Score': 0.47719298245614034, 'ROC AUC': 0.735303044332644, 'Confusion Matrix': array([[1038,   36],\n",
            "       [ 113,   68]])}, 'SVM': {'Accuracy': 0.9035856573705179, 'Precision': 0.8191489361702128, 'Recall': 0.425414364640884, 'F1 Score': 0.56, 'ROC AUC': 0.7798105908618579, 'Confusion Matrix': array([[1057,   17],\n",
            "       [ 104,   77]])}, 'Decision Tree': {'Accuracy': 0.8454183266932271, 'Precision': 0.4688995215311005, 'Recall': 0.5414364640883977, 'F1 Score': 0.5025641025641026, 'ROC AUC': 0.7204517629144932, 'Confusion Matrix': array([[963, 111],\n",
            "       [ 83,  98]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "7158 7158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8772908366533865, 'Precision': 0.5957446808510638, 'Recall': 0.46408839779005523, 'F1 Score': 0.5217391304347826, 'ROC AUC': 0.7391406113357407, 'Confusion Matrix': array([[1017,   57],\n",
            "       [  97,   84]])}, 'SVM': {'Accuracy': 0.8868525896414342, 'Precision': 0.6444444444444445, 'Recall': 0.48066298342541436, 'F1 Score': 0.550632911392405, 'ROC AUC': 0.787243947858473, 'Confusion Matrix': array([[1026,   48],\n",
            "       [  94,   87]])}, 'Decision Tree': {'Accuracy': 0.846215139442231, 'Precision': 0.47115384615384615, 'Recall': 0.5414364640883977, 'F1 Score': 0.5038560411311054, 'ROC AUC': 0.7270774818152824, 'Confusion Matrix': array([[964, 110],\n",
            "       [ 83,  98]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "7872 7872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8366533864541833, 'Precision': 0.4405940594059406, 'Recall': 0.49171270718232046, 'F1 Score': 0.4647519582245431, 'ROC AUC': 0.7410902599874483, 'Confusion Matrix': array([[961, 113],\n",
            "       [ 92,  89]])}, 'SVM': {'Accuracy': 0.8709163346613545, 'Precision': 0.5549132947976878, 'Recall': 0.5303867403314917, 'F1 Score': 0.5423728813559321, 'ROC AUC': 0.7866112122802145, 'Confusion Matrix': array([[997,  77],\n",
            "       [ 85,  96]])}, 'Decision Tree': {'Accuracy': 0.851792828685259, 'Precision': 0.4873096446700508, 'Recall': 0.5303867403314917, 'F1 Score': 0.5079365079365079, 'ROC AUC': 0.7230572960070785, 'Confusion Matrix': array([[973, 101],\n",
            "       [ 85,  96]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "8586 8586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7816733067729084, 'Precision': 0.33797909407665505, 'Recall': 0.5359116022099447, 'F1 Score': 0.4145299145299145, 'ROC AUC': 0.7461984423387553, 'Confusion Matrix': array([[884, 190],\n",
            "       [ 84,  97]])}, 'SVM': {'Accuracy': 0.8406374501992032, 'Precision': 0.45622119815668205, 'Recall': 0.5469613259668509, 'F1 Score': 0.49748743718592975, 'ROC AUC': 0.7847541590789837, 'Confusion Matrix': array([[956, 118],\n",
            "       [ 82,  99]])}, 'Decision Tree': {'Accuracy': 0.847808764940239, 'Precision': 0.4752475247524752, 'Recall': 0.5303867403314917, 'F1 Score': 0.5013054830287206, 'ROC AUC': 0.7206909678282252, 'Confusion Matrix': array([[968, 106],\n",
            "       [ 85,  96]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Random-Oversampling"
      ],
      "metadata": {
        "id": "KKwGBPjpKrJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_random = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_random, y_train_random = random_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "\n",
        "    preprocessed_X_train_random, scaler, imputer = preprocess_data_train((np.array(X_train_random)[0]))\n",
        "    preprocessed_X_test_random = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_random, y_train_random = preprocessed_X_train_random, (np.array(y_train_random))[0]\n",
        "    X_test_random, y_test_random = preprocessed_X_test_random, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_random), len(y_train_random))\n",
        "    results = evaluate_models(X_train_random, X_test_random, y_train_random, y_test_random)\n",
        "    results_random[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "LC2kVR1tKtFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6eba2a1-176b-4f18-a773-bd8e2841f2ac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "5730 5730\n",
            "{'Logistic Regression': {'Accuracy': 0.8749003984063745, 'Precision': 0.6621621621621622, 'Recall': 0.27071823204419887, 'F1 Score': 0.38431372549019605, 'ROC AUC': 0.7376076422111794, 'Confusion Matrix': array([[1049,   25],\n",
            "       [ 132,   49]])}, 'SVM': {'Accuracy': 0.902788844621514, 'Precision': 0.9154929577464789, 'Recall': 0.35911602209944754, 'F1 Score': 0.5158730158730159, 'ROC AUC': 0.7693524491496652, 'Confusion Matrix': array([[1068,    6],\n",
            "       [ 116,   65]])}, 'Decision Tree': {'Accuracy': 0.850199203187251, 'Precision': 0.48148148148148145, 'Recall': 0.5027624309392266, 'F1 Score': 0.49189189189189186, 'ROC AUC': 0.7054873092790931, 'Confusion Matrix': array([[976,  98],\n",
            "       [ 90,  91]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "6444 6444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8796812749003984, 'Precision': 0.6442307692307693, 'Recall': 0.3701657458563536, 'F1 Score': 0.4701754385964913, 'ROC AUC': 0.7468774756422523, 'Confusion Matrix': array([[1037,   37],\n",
            "       [ 114,   67]])}, 'SVM': {'Accuracy': 0.9059760956175299, 'Precision': 0.8387096774193549, 'Recall': 0.430939226519337, 'F1 Score': 0.5693430656934306, 'ROC AUC': 0.7860299186188874, 'Confusion Matrix': array([[1059,   15],\n",
            "       [ 103,   78]])}, 'Decision Tree': {'Accuracy': 0.850199203187251, 'Precision': 0.48258706467661694, 'Recall': 0.5359116022099447, 'F1 Score': 0.5078534031413613, 'ROC AUC': 0.7203128697387778, 'Confusion Matrix': array([[970, 104],\n",
            "       [ 84,  97]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "7158 7158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8725099601593626, 'Precision': 0.574468085106383, 'Recall': 0.44751381215469616, 'F1 Score': 0.5031055900621119, 'ROC AUC': 0.7520885418274226, 'Confusion Matrix': array([[1014,   60],\n",
            "       [ 100,   81]])}, 'SVM': {'Accuracy': 0.8972111553784861, 'Precision': 0.7131147540983607, 'Recall': 0.48066298342541436, 'F1 Score': 0.5742574257425743, 'ROC AUC': 0.7916628085228968, 'Confusion Matrix': array([[1039,   35],\n",
            "       [  94,   87]])}, 'Decision Tree': {'Accuracy': 0.847808764940239, 'Precision': 0.47572815533980584, 'Recall': 0.5414364640883977, 'F1 Score': 0.5064599483204134, 'ROC AUC': 0.7231498914575553, 'Confusion Matrix': array([[966, 108],\n",
            "       [ 83,  98]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "7872 7872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8382470119521912, 'Precision': 0.445, 'Recall': 0.49171270718232046, 'F1 Score': 0.4671916010498688, 'ROC AUC': 0.7530402172906572, 'Confusion Matrix': array([[963, 111],\n",
            "       [ 92,  89]])}, 'SVM': {'Accuracy': 0.8852589641434263, 'Precision': 0.6178343949044586, 'Recall': 0.5359116022099447, 'F1 Score': 0.57396449704142, 'ROC AUC': 0.790603105034106, 'Confusion Matrix': array([[1014,   60],\n",
            "       [  84,   97]])}, 'Decision Tree': {'Accuracy': 0.8454183266932271, 'Precision': 0.4688995215311005, 'Recall': 0.5414364640883977, 'F1 Score': 0.5025641025641026, 'ROC AUC': 0.7206909678282251, 'Confusion Matrix': array([[963, 111],\n",
            "       [ 83,  98]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "8586 8586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7840637450199203, 'Precision': 0.3469387755102041, 'Recall': 0.56353591160221, 'F1 Score': 0.42947368421052634, 'ROC AUC': 0.7552059219934772, 'Confusion Matrix': array([[882, 192],\n",
            "       [ 79, 102]])}, 'SVM': {'Accuracy': 0.8701195219123506, 'Precision': 0.5489130434782609, 'Recall': 0.5580110497237569, 'F1 Score': 0.5534246575342465, 'ROC AUC': 0.7931494799222198, 'Confusion Matrix': array([[991,  83],\n",
            "       [ 80, 101]])}, 'Decision Tree': {'Accuracy': 0.8430278884462151, 'Precision': 0.46, 'Recall': 0.5082872928176796, 'F1 Score': 0.4829396325459318, 'ROC AUC': 0.7061431937199708, 'Confusion Matrix': array([[966, 108],\n",
            "       [ 89,  92]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling SVM-SMOTE Over-Sampling"
      ],
      "metadata": {
        "id": "28Pi8n0HM4vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_svm_smote = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_svm_smote, y_train_svm_smote = svm_smote_oversampling(X_train.to_numpy(), y_train.to_numpy(), [ratio])\n",
        "\n",
        "    preprocessed_X_train_svm_smote, scaler, imputer = preprocess_data_train((np.array(X_train_svm_smote))[0])\n",
        "    preprocessed_X_test_svm_smote = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_svm_smote, y_train_svm_smote = preprocessed_X_train_svm_smote, (np.array(y_train_svm_smote))[0]\n",
        "    X_test_svm_smote, y_test_svm_smote = preprocessed_X_test_svm_smote, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_svm_smote), len(y_train_svm_smote))\n",
        "    results = evaluate_models(X_train_svm_smote, X_test_svm_smote, y_train_svm_smote, y_test_svm_smote)\n",
        "    results_svm_smote[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "8vkEOubrM81F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20aeba3-fb59-4f80-d289-6f6f6b0f2dd2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "5730 5730\n",
            "{'Logistic Regression': {'Accuracy': 0.8749003984063745, 'Precision': 0.6578947368421053, 'Recall': 0.27624309392265195, 'F1 Score': 0.3891050583657588, 'ROC AUC': 0.7371909626840334, 'Confusion Matrix': array([[1048,   26],\n",
            "       [ 131,   50]])}, 'SVM': {'Accuracy': 0.9067729083665339, 'Precision': 0.9, 'Recall': 0.39779005524861877, 'F1 Score': 0.5517241379310345, 'ROC AUC': 0.7779844028107864, 'Confusion Matrix': array([[1066,    8],\n",
            "       [ 109,   72]])}, 'Decision Tree': {'Accuracy': 0.8430278884462151, 'Precision': 0.4587628865979381, 'Recall': 0.49171270718232046, 'F1 Score': 0.4746666666666667, 'ROC AUC': 0.7000653312345032, 'Confusion Matrix': array([[969, 105],\n",
            "       [ 92,  89]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "6444 6444\n",
            "{'Logistic Regression': {'Accuracy': 0.8796812749003984, 'Precision': 0.6442307692307693, 'Recall': 0.3701657458563536, 'F1 Score': 0.4701754385964913, 'ROC AUC': 0.7419081864666606, 'Confusion Matrix': array([[1037,   37],\n",
            "       [ 114,   67]])}, 'SVM': {'Accuracy': 0.8988047808764941, 'Precision': 0.75, 'Recall': 0.44751381215469616, 'F1 Score': 0.560553633217993, 'ROC AUC': 0.7862562630533864, 'Confusion Matrix': array([[1047,   27],\n",
            "       [ 100,   81]])}, 'Decision Tree': {'Accuracy': 0.8549800796812749, 'Precision': 0.4973821989528796, 'Recall': 0.5248618784530387, 'F1 Score': 0.510752688172043, 'ROC AUC': 0.7191477103202774, 'Confusion Matrix': array([[978,  96],\n",
            "       [ 86,  95]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "7158 7158\n",
            "{'Logistic Regression': {'Accuracy': 0.8741035856573706, 'Precision': 0.5815602836879432, 'Recall': 0.4530386740331492, 'F1 Score': 0.5093167701863354, 'ROC AUC': 0.7502726421597374, 'Confusion Matrix': array([[1015,   59],\n",
            "       [  99,   82]])}, 'SVM': {'Accuracy': 0.8916334661354581, 'Precision': 0.6691729323308271, 'Recall': 0.49171270718232046, 'F1 Score': 0.5668789808917198, 'ROC AUC': 0.7897183040628826, 'Confusion Matrix': array([[1030,   44],\n",
            "       [  92,   89]])}, 'Decision Tree': {'Accuracy': 0.8597609561752988, 'Precision': 0.5128205128205128, 'Recall': 0.5524861878453039, 'F1 Score': 0.5319148936170214, 'ROC AUC': 0.7351770116361617, 'Confusion Matrix': array([[979,  95],\n",
            "       [ 81, 100]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "7872 7872\n",
            "{'Logistic Regression': {'Accuracy': 0.8358565737051793, 'Precision': 0.43781094527363185, 'Recall': 0.4861878453038674, 'F1 Score': 0.4607329842931937, 'ROC AUC': 0.7496193298147062, 'Confusion Matrix': array([[961, 113],\n",
            "       [ 93,  88]])}, 'SVM': {'Accuracy': 0.8780876494023905, 'Precision': 0.5813953488372093, 'Recall': 0.5524861878453039, 'F1 Score': 0.56657223796034, 'ROC AUC': 0.7939159644845006, 'Confusion Matrix': array([[1002,   72],\n",
            "       [  81,  100]])}, 'Decision Tree': {'Accuracy': 0.8382470119521912, 'Precision': 0.44554455445544555, 'Recall': 0.4972375690607735, 'F1 Score': 0.4699738903394256, 'ROC AUC': 0.6993194234389951, 'Confusion Matrix': array([[962, 112],\n",
            "       [ 91,  90]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "8586 8586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.7936254980079681, 'Precision': 0.3617021276595745, 'Recall': 0.56353591160221, 'F1 Score': 0.44060475161987045, 'ROC AUC': 0.754007325328971, 'Confusion Matrix': array([[894, 180],\n",
            "       [ 79, 102]])}, 'SVM': {'Accuracy': 0.850996015936255, 'Precision': 0.4857142857142857, 'Recall': 0.56353591160221, 'F1 Score': 0.5217391304347826, 'ROC AUC': 0.79176569235676, 'Confusion Matrix': array([[966, 108],\n",
            "       [ 79, 102]])}, 'Decision Tree': {'Accuracy': 0.8438247011952191, 'Precision': 0.4634146341463415, 'Recall': 0.5248618784530387, 'F1 Score': 0.49222797927461137, 'ROC AUC': 0.7135251087996543, 'Confusion Matrix': array([[964, 110],\n",
            "       [ 86,  95]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No-Sampling Results"
      ],
      "metadata": {
        "id": "v7igNZJnja1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_no_sampling = dict()\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    X_train_no_sampling, y_train_no_sampling = X_train.to_numpy(), y_train.to_numpy()\n",
        "\n",
        "    preprocessed_X_train_no_sampling, scaler, imputer = preprocess_data_train(X_train_no_sampling)\n",
        "    preprocessed_X_test_no_sampling = preprocess_data_test(X_test, scaler, imputer)\n",
        "\n",
        "    X_train_no_sampling, y_train_no_sampling = preprocessed_X_train_no_sampling, y_train_no_sampling\n",
        "    X_test_no_sampling, y_test_no_sampling = preprocessed_X_test_no_sampling, y_test.to_numpy()\n",
        "\n",
        "    print(f\"Train data combined with {ratio * 100}% synthetic data of minority class:\")\n",
        "    print(len(X_train_no_sampling), len(y_train_no_sampling))\n",
        "    results = evaluate_models(X_train_no_sampling, X_test_no_sampling, y_train_no_sampling, y_test_no_sampling)\n",
        "    results_no_sampling[ratio] = results\n",
        "    print(results)\n",
        "    print(\"_______________________________________________________________________________\")"
      ],
      "metadata": {
        "id": "pkbztvKijXEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df40dcf5-b623-4d0e-bbe7-25de7d818878"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data combined with 20.0% synthetic data of minority class:\n",
            "5016 5016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8756972111553785, 'Precision': 0.8205128205128205, 'Recall': 0.17679558011049723, 'F1 Score': 0.2909090909090909, 'ROC AUC': 0.7235742872722409, 'Confusion Matrix': array([[1067,    7],\n",
            "       [ 149,   32]])}, 'SVM': {'Accuracy': 0.902788844621514, 'Precision': 0.9538461538461539, 'Recall': 0.3425414364640884, 'F1 Score': 0.5040650406504066, 'ROC AUC': 0.7590023354630289, 'Confusion Matrix': array([[1071,    3],\n",
            "       [ 119,   62]])}, 'Decision Tree': {'Accuracy': 0.8494023904382471, 'Precision': 0.4789473684210526, 'Recall': 0.5027624309392266, 'F1 Score': 0.49056603773584906, 'ROC AUC': 0.7075295533812771, 'Confusion Matrix': array([[975,  99],\n",
            "       [ 90,  91]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 40.0% synthetic data of minority class:\n",
            "5016 5016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8756972111553785, 'Precision': 0.8205128205128205, 'Recall': 0.17679558011049723, 'F1 Score': 0.2909090909090909, 'ROC AUC': 0.7235742872722409, 'Confusion Matrix': array([[1067,    7],\n",
            "       [ 149,   32]])}, 'SVM': {'Accuracy': 0.902788844621514, 'Precision': 0.9538461538461539, 'Recall': 0.3425414364640884, 'F1 Score': 0.5040650406504066, 'ROC AUC': 0.7590023354630289, 'Confusion Matrix': array([[1071,    3],\n",
            "       [ 119,   62]])}, 'Decision Tree': {'Accuracy': 0.8494023904382471, 'Precision': 0.4789473684210526, 'Recall': 0.5027624309392266, 'F1 Score': 0.49056603773584906, 'ROC AUC': 0.7075295533812771, 'Confusion Matrix': array([[975,  99],\n",
            "       [ 90,  91]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 60.00000000000001% synthetic data of minority class:\n",
            "5016 5016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8756972111553785, 'Precision': 0.8205128205128205, 'Recall': 0.17679558011049723, 'F1 Score': 0.2909090909090909, 'ROC AUC': 0.7235742872722409, 'Confusion Matrix': array([[1067,    7],\n",
            "       [ 149,   32]])}, 'SVM': {'Accuracy': 0.902788844621514, 'Precision': 0.9538461538461539, 'Recall': 0.3425414364640884, 'F1 Score': 0.5040650406504066, 'ROC AUC': 0.7590023354630289, 'Confusion Matrix': array([[1071,    3],\n",
            "       [ 119,   62]])}, 'Decision Tree': {'Accuracy': 0.8494023904382471, 'Precision': 0.4789473684210526, 'Recall': 0.5027624309392266, 'F1 Score': 0.49056603773584906, 'ROC AUC': 0.7075295533812771, 'Confusion Matrix': array([[975,  99],\n",
            "       [ 90,  91]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 80.0% synthetic data of minority class:\n",
            "5016 5016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8756972111553785, 'Precision': 0.8205128205128205, 'Recall': 0.17679558011049723, 'F1 Score': 0.2909090909090909, 'ROC AUC': 0.7235742872722409, 'Confusion Matrix': array([[1067,    7],\n",
            "       [ 149,   32]])}, 'SVM': {'Accuracy': 0.902788844621514, 'Precision': 0.9538461538461539, 'Recall': 0.3425414364640884, 'F1 Score': 0.5040650406504066, 'ROC AUC': 0.7590023354630289, 'Confusion Matrix': array([[1071,    3],\n",
            "       [ 119,   62]])}, 'Decision Tree': {'Accuracy': 0.8494023904382471, 'Precision': 0.4789473684210526, 'Recall': 0.5027624309392266, 'F1 Score': 0.49056603773584906, 'ROC AUC': 0.7075295533812771, 'Confusion Matrix': array([[975,  99],\n",
            "       [ 90,  91]])}}\n",
            "_______________________________________________________________________________\n",
            "Train data combined with 100.0% synthetic data of minority class:\n",
            "5016 5016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Logistic Regression': {'Accuracy': 0.8756972111553785, 'Precision': 0.8205128205128205, 'Recall': 0.17679558011049723, 'F1 Score': 0.2909090909090909, 'ROC AUC': 0.7235742872722409, 'Confusion Matrix': array([[1067,    7],\n",
            "       [ 149,   32]])}, 'SVM': {'Accuracy': 0.902788844621514, 'Precision': 0.9538461538461539, 'Recall': 0.3425414364640884, 'F1 Score': 0.5040650406504066, 'ROC AUC': 0.7590023354630289, 'Confusion Matrix': array([[1071,    3],\n",
            "       [ 119,   62]])}, 'Decision Tree': {'Accuracy': 0.8494023904382471, 'Precision': 0.4789473684210526, 'Recall': 0.5027624309392266, 'F1 Score': 0.49056603773584906, 'ROC AUC': 0.7075295533812771, 'Confusion Matrix': array([[975,  99],\n",
            "       [ 90,  91]])}}\n",
            "_______________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}